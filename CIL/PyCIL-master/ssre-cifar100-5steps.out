2023-03-22 09:13:10,028 [trainer.py] => config: ./exps/ssre.json
2023-03-22 09:13:10,028 [trainer.py] => prefix: ssre
2023-03-22 09:13:10,029 [trainer.py] => dataset: cifar100
2023-03-22 09:13:10,029 [trainer.py] => memory_size: 0
2023-03-22 09:13:10,032 [trainer.py] => shuffle: True
2023-03-22 09:13:10,032 [trainer.py] => init_cls: 50
2023-03-22 09:13:10,032 [trainer.py] => increment: 10
2023-03-22 09:13:10,033 [trainer.py] => model_name: ssre
2023-03-22 09:13:10,033 [trainer.py] => convnet_type: resnet18_rep
2023-03-22 09:13:10,033 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1), device(type='cuda', index=2), device(type='cuda', index=3)]
2023-03-22 09:13:10,033 [trainer.py] => seed: 1993
2023-03-22 09:13:10,033 [trainer.py] => lambda_fkd: 1
2023-03-22 09:13:10,033 [trainer.py] => lambda_proto: 10
2023-03-22 09:13:10,033 [trainer.py] => temp: 0.1
2023-03-22 09:13:10,034 [trainer.py] => mode: parallel_adapters
2023-03-22 09:13:10,034 [trainer.py] => epochs: 101
2023-03-22 09:13:10,034 [trainer.py] => lr: 0.001
2023-03-22 09:13:10,034 [trainer.py] => batch_size: 128
2023-03-22 09:13:10,034 [trainer.py] => weight_decay: 0.0005
2023-03-22 09:13:10,034 [trainer.py] => step_size: 45
2023-03-22 09:13:10,034 [trainer.py] => gamma: 0.1
2023-03-22 09:13:10,034 [trainer.py] => threshold: 0.8
2023-03-22 09:13:10,034 [trainer.py] => num_workers: 8
2023-03-22 09:13:10,035 [trainer.py] => T: 2
Files already downloaded and verified
Files already downloaded and verified
2023-03-22 09:13:12,254 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
use cifar
2023-03-22 09:13:12,683 [trainer.py] => All params: 12396224
2023-03-22 09:13:12,683 [trainer.py] => Trainable params: 12396224
2023-03-22 09:13:12,684 [ssre.py] => Model Expansion!
2023-03-22 09:13:12,684 [ssre.py] => Learning on 0-50
2023-03-22 09:13:12,684 [ssre.py] => All params: 12421874
2023-03-22 09:13:12,684 [ssre.py] => Trainable params: 12421874
2023-03-22 09:14:06,035 [ssre.py] => Task 0, Epoch 1/101 => Loss 4.350, Loss_clf 4.350, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 14.40, Test_accy 23.06
2023-03-22 09:14:34,401 [ssre.py] => Task 0, Epoch 2/101 => Loss 2.949, Loss_clf 2.949, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 24.89
2023-03-22 09:15:01,336 [ssre.py] => Task 0, Epoch 3/101 => Loss 2.518, Loss_clf 2.518, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 32.84
2023-03-22 09:15:28,298 [ssre.py] => Task 0, Epoch 4/101 => Loss 2.199, Loss_clf 2.199, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 39.30
2023-03-22 09:15:56,227 [ssre.py] => Task 0, Epoch 5/101 => Loss 1.997, Loss_clf 1.997, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 44.74
2023-03-22 09:16:26,995 [ssre.py] => Task 0, Epoch 6/101 => Loss 1.816, Loss_clf 1.816, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 49.00, Test_accy 49.92
2023-03-22 09:16:54,840 [ssre.py] => Task 0, Epoch 7/101 => Loss 1.694, Loss_clf 1.694, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 52.48
2023-03-22 09:17:23,323 [ssre.py] => Task 0, Epoch 8/101 => Loss 1.601, Loss_clf 1.601, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 54.32
2023-03-22 09:17:50,199 [ssre.py] => Task 0, Epoch 9/101 => Loss 1.507, Loss_clf 1.507, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 56.57
2023-03-22 09:18:18,042 [ssre.py] => Task 0, Epoch 10/101 => Loss 1.446, Loss_clf 1.446, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 58.31
2023-03-22 09:18:48,776 [ssre.py] => Task 0, Epoch 11/101 => Loss 1.394, Loss_clf 1.394, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 59.57, Test_accy 55.44
2023-03-22 09:19:17,664 [ssre.py] => Task 0, Epoch 12/101 => Loss 1.324, Loss_clf 1.324, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 61.28
2023-03-22 09:19:47,342 [ssre.py] => Task 0, Epoch 13/101 => Loss 1.297, Loss_clf 1.297, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 61.90
2023-03-22 09:20:15,406 [ssre.py] => Task 0, Epoch 14/101 => Loss 1.248, Loss_clf 1.248, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 63.54
2023-03-22 09:20:42,443 [ssre.py] => Task 0, Epoch 15/101 => Loss 1.218, Loss_clf 1.218, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 64.02
2023-03-22 09:21:12,296 [ssre.py] => Task 0, Epoch 16/101 => Loss 1.172, Loss_clf 1.172, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 65.41, Test_accy 62.86
2023-03-22 09:21:41,022 [ssre.py] => Task 0, Epoch 17/101 => Loss 1.127, Loss_clf 1.127, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 66.33
2023-03-22 09:22:08,190 [ssre.py] => Task 0, Epoch 18/101 => Loss 1.089, Loss_clf 1.089, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 67.28
2023-03-22 09:22:36,956 [ssre.py] => Task 0, Epoch 19/101 => Loss 1.060, Loss_clf 1.060, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 67.88
2023-03-22 09:23:03,684 [ssre.py] => Task 0, Epoch 20/101 => Loss 1.025, Loss_clf 1.025, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 69.34
2023-03-22 09:23:34,114 [ssre.py] => Task 0, Epoch 21/101 => Loss 1.002, Loss_clf 1.002, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 69.71, Test_accy 65.94
2023-03-22 09:24:01,562 [ssre.py] => Task 0, Epoch 22/101 => Loss 0.986, Loss_clf 0.986, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 69.64
2023-03-22 09:24:27,881 [ssre.py] => Task 0, Epoch 23/101 => Loss 0.952, Loss_clf 0.952, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 71.27
2023-03-22 09:24:55,443 [ssre.py] => Task 0, Epoch 24/101 => Loss 0.936, Loss_clf 0.936, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 71.31
2023-03-22 09:25:22,384 [ssre.py] => Task 0, Epoch 25/101 => Loss 0.917, Loss_clf 0.917, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 72.21
2023-03-22 09:25:52,850 [ssre.py] => Task 0, Epoch 26/101 => Loss 0.896, Loss_clf 0.896, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 72.75, Test_accy 65.78
2023-03-22 09:26:21,078 [ssre.py] => Task 0, Epoch 27/101 => Loss 0.884, Loss_clf 0.884, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 72.89
2023-03-22 09:26:48,786 [ssre.py] => Task 0, Epoch 28/101 => Loss 0.862, Loss_clf 0.862, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 73.67
2023-03-22 09:27:16,487 [ssre.py] => Task 0, Epoch 29/101 => Loss 0.844, Loss_clf 0.844, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 74.19
2023-03-22 09:27:43,729 [ssre.py] => Task 0, Epoch 30/101 => Loss 0.833, Loss_clf 0.833, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 74.35
2023-03-22 09:28:15,732 [ssre.py] => Task 0, Epoch 31/101 => Loss 0.823, Loss_clf 0.823, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 74.85, Test_accy 66.30
2023-03-22 09:28:42,833 [ssre.py] => Task 0, Epoch 32/101 => Loss 0.806, Loss_clf 0.806, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 74.91
2023-03-22 09:29:11,701 [ssre.py] => Task 0, Epoch 33/101 => Loss 0.795, Loss_clf 0.795, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 75.30
2023-03-22 09:29:39,420 [ssre.py] => Task 0, Epoch 34/101 => Loss 0.773, Loss_clf 0.773, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 76.09
2023-03-22 09:30:07,580 [ssre.py] => Task 0, Epoch 35/101 => Loss 0.775, Loss_clf 0.775, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 75.91
2023-03-22 09:30:37,363 [ssre.py] => Task 0, Epoch 36/101 => Loss 0.758, Loss_clf 0.758, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 76.47, Test_accy 68.64
2023-03-22 09:31:05,558 [ssre.py] => Task 0, Epoch 37/101 => Loss 0.754, Loss_clf 0.754, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 76.77
2023-03-22 09:31:33,139 [ssre.py] => Task 0, Epoch 38/101 => Loss 0.752, Loss_clf 0.752, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 76.65
2023-03-22 09:32:03,152 [ssre.py] => Task 0, Epoch 39/101 => Loss 0.733, Loss_clf 0.733, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 77.36
2023-03-22 09:32:31,437 [ssre.py] => Task 0, Epoch 40/101 => Loss 0.729, Loss_clf 0.729, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 77.27
2023-03-22 09:33:00,894 [ssre.py] => Task 0, Epoch 41/101 => Loss 0.715, Loss_clf 0.715, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 77.72, Test_accy 68.90
2023-03-22 09:33:28,892 [ssre.py] => Task 0, Epoch 42/101 => Loss 0.712, Loss_clf 0.712, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 77.65
2023-03-22 09:33:58,415 [ssre.py] => Task 0, Epoch 43/101 => Loss 0.701, Loss_clf 0.701, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 78.18
2023-03-22 09:34:25,881 [ssre.py] => Task 0, Epoch 44/101 => Loss 0.695, Loss_clf 0.695, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 78.53
2023-03-22 09:34:53,396 [ssre.py] => Task 0, Epoch 45/101 => Loss 0.688, Loss_clf 0.688, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 78.51
2023-03-22 09:35:25,049 [ssre.py] => Task 0, Epoch 46/101 => Loss 0.470, Loss_clf 0.470, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 85.23, Test_accy 76.68
2023-03-22 09:35:54,070 [ssre.py] => Task 0, Epoch 47/101 => Loss 0.398, Loss_clf 0.398, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 87.59
2023-03-22 09:36:22,551 [ssre.py] => Task 0, Epoch 48/101 => Loss 0.362, Loss_clf 0.362, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 88.74
2023-03-22 09:36:49,486 [ssre.py] => Task 0, Epoch 49/101 => Loss 0.340, Loss_clf 0.340, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 89.46
2023-03-22 09:37:16,902 [ssre.py] => Task 0, Epoch 50/101 => Loss 0.325, Loss_clf 0.325, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 89.52
2023-03-22 09:37:47,170 [ssre.py] => Task 0, Epoch 51/101 => Loss 0.305, Loss_clf 0.305, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 90.35, Test_accy 77.62
2023-03-22 09:38:15,056 [ssre.py] => Task 0, Epoch 52/101 => Loss 0.286, Loss_clf 0.286, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 90.91
2023-03-22 09:38:44,105 [ssre.py] => Task 0, Epoch 53/101 => Loss 0.279, Loss_clf 0.279, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 90.97
2023-03-22 09:39:13,753 [ssre.py] => Task 0, Epoch 54/101 => Loss 0.268, Loss_clf 0.268, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 91.46
2023-03-22 09:39:41,840 [ssre.py] => Task 0, Epoch 55/101 => Loss 0.249, Loss_clf 0.249, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 92.17
2023-03-22 09:40:11,728 [ssre.py] => Task 0, Epoch 56/101 => Loss 0.243, Loss_clf 0.243, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 92.39, Test_accy 77.96
2023-03-22 09:40:39,382 [ssre.py] => Task 0, Epoch 57/101 => Loss 0.232, Loss_clf 0.232, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 92.71
2023-03-22 09:41:08,073 [ssre.py] => Task 0, Epoch 58/101 => Loss 0.227, Loss_clf 0.227, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 92.84
2023-03-22 09:41:35,247 [ssre.py] => Task 0, Epoch 59/101 => Loss 0.218, Loss_clf 0.218, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 93.05
2023-03-22 09:42:03,885 [ssre.py] => Task 0, Epoch 60/101 => Loss 0.204, Loss_clf 0.204, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 93.67
2023-03-22 09:42:35,747 [ssre.py] => Task 0, Epoch 61/101 => Loss 0.202, Loss_clf 0.202, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 93.66, Test_accy 78.68
2023-03-22 09:43:04,669 [ssre.py] => Task 0, Epoch 62/101 => Loss 0.194, Loss_clf 0.194, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 93.96
2023-03-22 09:43:32,170 [ssre.py] => Task 0, Epoch 63/101 => Loss 0.187, Loss_clf 0.187, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 94.23
2023-03-22 09:44:00,714 [ssre.py] => Task 0, Epoch 64/101 => Loss 0.180, Loss_clf 0.180, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 94.45
2023-03-22 09:44:28,362 [ssre.py] => Task 0, Epoch 65/101 => Loss 0.171, Loss_clf 0.171, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 94.60
2023-03-22 09:44:57,665 [ssre.py] => Task 0, Epoch 66/101 => Loss 0.165, Loss_clf 0.165, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 94.95, Test_accy 78.00
2023-03-22 09:45:24,667 [ssre.py] => Task 0, Epoch 67/101 => Loss 0.166, Loss_clf 0.166, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 94.86
2023-03-22 09:45:53,336 [ssre.py] => Task 0, Epoch 68/101 => Loss 0.158, Loss_clf 0.158, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 95.07
2023-03-22 09:46:21,952 [ssre.py] => Task 0, Epoch 69/101 => Loss 0.152, Loss_clf 0.152, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 95.32
2023-03-22 09:46:49,473 [ssre.py] => Task 0, Epoch 70/101 => Loss 0.148, Loss_clf 0.148, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 95.37
2023-03-22 09:47:19,236 [ssre.py] => Task 0, Epoch 71/101 => Loss 0.143, Loss_clf 0.143, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 95.65, Test_accy 78.00
2023-03-22 09:47:45,650 [ssre.py] => Task 0, Epoch 72/101 => Loss 0.141, Loss_clf 0.141, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 95.54
2023-03-22 09:48:13,034 [ssre.py] => Task 0, Epoch 73/101 => Loss 0.137, Loss_clf 0.137, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 95.82
2023-03-22 09:48:40,928 [ssre.py] => Task 0, Epoch 74/101 => Loss 0.131, Loss_clf 0.131, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 96.00
2023-03-22 09:49:10,125 [ssre.py] => Task 0, Epoch 75/101 => Loss 0.127, Loss_clf 0.127, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 96.24
2023-03-22 09:49:39,585 [ssre.py] => Task 0, Epoch 76/101 => Loss 0.127, Loss_clf 0.127, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 96.14, Test_accy 78.22
2023-03-22 09:50:07,396 [ssre.py] => Task 0, Epoch 77/101 => Loss 0.121, Loss_clf 0.121, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 96.28
2023-03-22 09:50:35,493 [ssre.py] => Task 0, Epoch 78/101 => Loss 0.118, Loss_clf 0.118, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 96.40
2023-03-22 09:51:03,099 [ssre.py] => Task 0, Epoch 79/101 => Loss 0.111, Loss_clf 0.111, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 96.73
2023-03-22 09:51:30,314 [ssre.py] => Task 0, Epoch 80/101 => Loss 0.113, Loss_clf 0.113, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 96.55
2023-03-22 09:52:01,300 [ssre.py] => Task 0, Epoch 81/101 => Loss 0.110, Loss_clf 0.110, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 96.77, Test_accy 78.42
2023-03-22 09:52:29,974 [ssre.py] => Task 0, Epoch 82/101 => Loss 0.109, Loss_clf 0.109, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 96.74
2023-03-22 09:52:57,398 [ssre.py] => Task 0, Epoch 83/101 => Loss 0.108, Loss_clf 0.108, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 96.67
2023-03-22 09:53:25,473 [ssre.py] => Task 0, Epoch 84/101 => Loss 0.103, Loss_clf 0.103, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 97.07
2023-03-22 09:53:53,561 [ssre.py] => Task 0, Epoch 85/101 => Loss 0.104, Loss_clf 0.104, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 96.89
2023-03-22 09:54:22,635 [ssre.py] => Task 0, Epoch 86/101 => Loss 0.103, Loss_clf 0.103, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 96.94, Test_accy 77.24
2023-03-22 09:54:51,061 [ssre.py] => Task 0, Epoch 87/101 => Loss 0.100, Loss_clf 0.100, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 96.92
2023-03-22 09:55:19,302 [ssre.py] => Task 0, Epoch 88/101 => Loss 0.097, Loss_clf 0.097, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 97.10
2023-03-22 09:55:47,348 [ssre.py] => Task 0, Epoch 89/101 => Loss 0.091, Loss_clf 0.091, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 97.34
2023-03-22 09:56:15,656 [ssre.py] => Task 0, Epoch 90/101 => Loss 0.096, Loss_clf 0.096, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 97.04
2023-03-22 09:56:46,239 [ssre.py] => Task 0, Epoch 91/101 => Loss 0.076, Loss_clf 0.076, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 97.95, Test_accy 79.40
2023-03-22 09:57:14,611 [ssre.py] => Task 0, Epoch 92/101 => Loss 0.068, Loss_clf 0.068, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 98.18
2023-03-22 09:57:42,420 [ssre.py] => Task 0, Epoch 93/101 => Loss 0.062, Loss_clf 0.062, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 98.43
2023-03-22 09:58:10,092 [ssre.py] => Task 0, Epoch 94/101 => Loss 0.061, Loss_clf 0.061, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 98.50
2023-03-22 09:58:36,801 [ssre.py] => Task 0, Epoch 95/101 => Loss 0.058, Loss_clf 0.058, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 98.58
2023-03-22 09:59:07,242 [ssre.py] => Task 0, Epoch 96/101 => Loss 0.058, Loss_clf 0.058, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 98.52, Test_accy 79.36
2023-03-22 09:59:34,653 [ssre.py] => Task 0, Epoch 97/101 => Loss 0.056, Loss_clf 0.056, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 98.60
2023-03-22 10:00:01,729 [ssre.py] => Task 0, Epoch 98/101 => Loss 0.055, Loss_clf 0.055, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 98.65
2023-03-22 10:00:29,624 [ssre.py] => Task 0, Epoch 99/101 => Loss 0.053, Loss_clf 0.053, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 98.79
2023-03-22 10:00:56,883 [ssre.py] => Task 0, Epoch 100/101 => Loss 0.053, Loss_clf 0.053, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 98.70
2023-03-22 10:01:25,526 [ssre.py] => Task 0, Epoch 101/101 => Loss 0.052, Loss_clf 0.052, Loss_fkd 0.000, Loss_proto 0.000, Train_accy 98.77, Test_accy 79.40
2023-03-22 10:01:57,380 [ssre.py] => Model Compression!
2023-03-22 10:02:02,097 [trainer.py] => CNN: {'total': 79.4, '00-09': 81.5, '10-19': 75.5, '20-29': 81.2, '30-39': 77.1, '40-49': 81.7, 'old': 0, 'new': 79.4}
2023-03-22 10:02:02,097 [trainer.py] => NME: {'total': 73.28, '00-09': 75.6, '10-19': 67.1, '20-29': 76.8, '30-39': 68.4, '40-49': 78.5, 'old': 0, 'new': 73.28}
2023-03-22 10:02:02,097 [trainer.py] => CNN top1 curve: [79.4]
2023-03-22 10:02:02,097 [trainer.py] => CNN top5 curve: [95.74]
2023-03-22 10:02:02,097 [trainer.py] => NME top1 curve: [73.28]
2023-03-22 10:02:02,098 [trainer.py] => NME top5 curve: [94.32]

2023-03-22 10:02:02,098 [trainer.py] => All params: 12421874
2023-03-22 10:02:02,099 [trainer.py] => Trainable params: 12421874
2023-03-22 10:02:02,111 [ssre.py] => Model Expansion!
2023-03-22 10:02:02,113 [ssre.py] => Learning on 50-60
2023-03-22 10:02:02,113 [ssre.py] => All params: 12427004
2023-03-22 10:02:02,114 [ssre.py] => Trainable params: 1255228
2023-03-22 10:02:09,988 [ssre.py] => Task 1, Epoch 1/101 => Loss 13.977, Loss_clf 0.780, Loss_fkd 13.165, Loss_proto 0.032, Train_accy 15.16, Test_accy 60.90
2023-03-22 10:02:15,078 [ssre.py] => Task 1, Epoch 2/101 => Loss 6.115, Loss_clf 0.465, Loss_fkd 5.628, Loss_proto 0.022, Train_accy 39.58
2023-03-22 10:02:20,190 [ssre.py] => Task 1, Epoch 3/101 => Loss 5.120, Loss_clf 0.400, Loss_fkd 4.704, Loss_proto 0.016, Train_accy 46.00
2023-03-22 10:02:25,228 [ssre.py] => Task 1, Epoch 4/101 => Loss 5.110, Loss_clf 0.382, Loss_fkd 4.716, Loss_proto 0.013, Train_accy 49.40
2023-03-22 10:02:30,236 [ssre.py] => Task 1, Epoch 5/101 => Loss 7.840, Loss_clf 0.355, Loss_fkd 7.474, Loss_proto 0.011, Train_accy 53.00
2023-03-22 10:02:37,951 [ssre.py] => Task 1, Epoch 6/101 => Loss 7.336, Loss_clf 0.342, Loss_fkd 6.984, Loss_proto 0.011, Train_accy 55.10, Test_accy 65.13
2023-03-22 10:02:43,155 [ssre.py] => Task 1, Epoch 7/101 => Loss 6.235, Loss_clf 0.338, Loss_fkd 5.888, Loss_proto 0.009, Train_accy 55.64
2023-03-22 10:02:48,341 [ssre.py] => Task 1, Epoch 8/101 => Loss 5.723, Loss_clf 0.331, Loss_fkd 5.382, Loss_proto 0.009, Train_accy 56.46
2023-03-22 10:02:53,451 [ssre.py] => Task 1, Epoch 9/101 => Loss 7.056, Loss_clf 0.320, Loss_fkd 6.729, Loss_proto 0.008, Train_accy 56.84
2023-03-22 10:02:58,501 [ssre.py] => Task 1, Epoch 10/101 => Loss 6.640, Loss_clf 0.322, Loss_fkd 6.310, Loss_proto 0.008, Train_accy 56.78
2023-03-22 10:03:06,098 [ssre.py] => Task 1, Epoch 11/101 => Loss 7.922, Loss_clf 0.310, Loss_fkd 7.604, Loss_proto 0.008, Train_accy 59.16, Test_accy 66.23
2023-03-22 10:03:11,200 [ssre.py] => Task 1, Epoch 12/101 => Loss 7.401, Loss_clf 0.310, Loss_fkd 7.085, Loss_proto 0.007, Train_accy 58.78
2023-03-22 10:03:16,380 [ssre.py] => Task 1, Epoch 13/101 => Loss 6.668, Loss_clf 0.300, Loss_fkd 6.361, Loss_proto 0.007, Train_accy 58.76
2023-03-22 10:03:21,416 [ssre.py] => Task 1, Epoch 14/101 => Loss 4.849, Loss_clf 0.310, Loss_fkd 4.532, Loss_proto 0.007, Train_accy 58.36
2023-03-22 10:03:26,447 [ssre.py] => Task 1, Epoch 15/101 => Loss 7.085, Loss_clf 0.300, Loss_fkd 6.779, Loss_proto 0.007, Train_accy 59.56
2023-03-22 10:03:33,998 [ssre.py] => Task 1, Epoch 16/101 => Loss 4.799, Loss_clf 0.296, Loss_fkd 4.497, Loss_proto 0.006, Train_accy 61.00, Test_accy 66.42
2023-03-22 10:03:39,134 [ssre.py] => Task 1, Epoch 17/101 => Loss 5.114, Loss_clf 0.291, Loss_fkd 4.817, Loss_proto 0.006, Train_accy 60.64
2023-03-22 10:03:44,268 [ssre.py] => Task 1, Epoch 18/101 => Loss 5.717, Loss_clf 0.301, Loss_fkd 5.410, Loss_proto 0.006, Train_accy 60.80
2023-03-22 10:03:49,397 [ssre.py] => Task 1, Epoch 19/101 => Loss 5.223, Loss_clf 0.293, Loss_fkd 4.924, Loss_proto 0.006, Train_accy 60.96
2023-03-22 10:03:54,462 [ssre.py] => Task 1, Epoch 20/101 => Loss 4.950, Loss_clf 0.296, Loss_fkd 4.648, Loss_proto 0.005, Train_accy 61.12
2023-03-22 10:04:02,115 [ssre.py] => Task 1, Epoch 21/101 => Loss 5.982, Loss_clf 0.296, Loss_fkd 5.680, Loss_proto 0.006, Train_accy 59.66, Test_accy 67.12
2023-03-22 10:04:07,355 [ssre.py] => Task 1, Epoch 22/101 => Loss 5.639, Loss_clf 0.293, Loss_fkd 5.340, Loss_proto 0.006, Train_accy 61.42
2023-03-22 10:04:12,354 [ssre.py] => Task 1, Epoch 23/101 => Loss 5.332, Loss_clf 0.294, Loss_fkd 5.032, Loss_proto 0.006, Train_accy 61.36
2023-03-22 10:04:17,432 [ssre.py] => Task 1, Epoch 24/101 => Loss 4.911, Loss_clf 0.291, Loss_fkd 4.614, Loss_proto 0.006, Train_accy 61.02
2023-03-22 10:04:22,518 [ssre.py] => Task 1, Epoch 25/101 => Loss 4.739, Loss_clf 0.296, Loss_fkd 4.438, Loss_proto 0.006, Train_accy 60.00
2023-03-22 10:04:30,165 [ssre.py] => Task 1, Epoch 26/101 => Loss 6.165, Loss_clf 0.284, Loss_fkd 5.875, Loss_proto 0.005, Train_accy 62.28, Test_accy 67.75
2023-03-22 10:04:35,235 [ssre.py] => Task 1, Epoch 27/101 => Loss 6.123, Loss_clf 0.295, Loss_fkd 5.822, Loss_proto 0.006, Train_accy 61.02
2023-03-22 10:04:40,408 [ssre.py] => Task 1, Epoch 28/101 => Loss 5.057, Loss_clf 0.280, Loss_fkd 4.772, Loss_proto 0.005, Train_accy 61.66
2023-03-22 10:04:45,526 [ssre.py] => Task 1, Epoch 29/101 => Loss 6.866, Loss_clf 0.282, Loss_fkd 6.579, Loss_proto 0.005, Train_accy 62.52
2023-03-22 10:04:50,790 [ssre.py] => Task 1, Epoch 30/101 => Loss 5.551, Loss_clf 0.298, Loss_fkd 5.247, Loss_proto 0.005, Train_accy 60.82
2023-03-22 10:04:58,287 [ssre.py] => Task 1, Epoch 31/101 => Loss 5.004, Loss_clf 0.284, Loss_fkd 4.715, Loss_proto 0.005, Train_accy 63.08, Test_accy 67.82
2023-03-22 10:05:03,380 [ssre.py] => Task 1, Epoch 32/101 => Loss 4.713, Loss_clf 0.288, Loss_fkd 4.419, Loss_proto 0.005, Train_accy 62.62
2023-03-22 10:05:08,564 [ssre.py] => Task 1, Epoch 33/101 => Loss 6.503, Loss_clf 0.277, Loss_fkd 6.220, Loss_proto 0.006, Train_accy 62.96
2023-03-22 10:05:13,706 [ssre.py] => Task 1, Epoch 34/101 => Loss 5.906, Loss_clf 0.281, Loss_fkd 5.620, Loss_proto 0.005, Train_accy 62.98
2023-03-22 10:05:18,754 [ssre.py] => Task 1, Epoch 35/101 => Loss 5.749, Loss_clf 0.291, Loss_fkd 5.453, Loss_proto 0.005, Train_accy 62.14
2023-03-22 10:05:26,233 [ssre.py] => Task 1, Epoch 36/101 => Loss 7.652, Loss_clf 0.287, Loss_fkd 7.359, Loss_proto 0.005, Train_accy 62.86, Test_accy 67.27
2023-03-22 10:05:31,381 [ssre.py] => Task 1, Epoch 37/101 => Loss 8.011, Loss_clf 0.288, Loss_fkd 7.718, Loss_proto 0.005, Train_accy 62.44
2023-03-22 10:05:36,323 [ssre.py] => Task 1, Epoch 38/101 => Loss 6.329, Loss_clf 0.281, Loss_fkd 6.042, Loss_proto 0.005, Train_accy 62.16
2023-03-22 10:05:41,519 [ssre.py] => Task 1, Epoch 39/101 => Loss 6.255, Loss_clf 0.281, Loss_fkd 5.969, Loss_proto 0.005, Train_accy 62.88
2023-03-22 10:05:46,670 [ssre.py] => Task 1, Epoch 40/101 => Loss 4.725, Loss_clf 0.282, Loss_fkd 4.438, Loss_proto 0.005, Train_accy 62.90
2023-03-22 10:05:54,237 [ssre.py] => Task 1, Epoch 41/101 => Loss 4.853, Loss_clf 0.281, Loss_fkd 4.567, Loss_proto 0.005, Train_accy 62.60, Test_accy 67.15
2023-03-22 10:05:59,342 [ssre.py] => Task 1, Epoch 42/101 => Loss 5.815, Loss_clf 0.285, Loss_fkd 5.525, Loss_proto 0.005, Train_accy 62.30
2023-03-22 10:06:04,465 [ssre.py] => Task 1, Epoch 43/101 => Loss 5.232, Loss_clf 0.276, Loss_fkd 4.951, Loss_proto 0.005, Train_accy 62.94
2023-03-22 10:06:09,623 [ssre.py] => Task 1, Epoch 44/101 => Loss 6.085, Loss_clf 0.276, Loss_fkd 5.804, Loss_proto 0.005, Train_accy 63.24
2023-03-22 10:06:14,532 [ssre.py] => Task 1, Epoch 45/101 => Loss 6.841, Loss_clf 0.277, Loss_fkd 6.558, Loss_proto 0.005, Train_accy 63.60
2023-03-22 10:06:22,210 [ssre.py] => Task 1, Epoch 46/101 => Loss 2.998, Loss_clf 0.277, Loss_fkd 2.717, Loss_proto 0.005, Train_accy 64.00, Test_accy 67.60
2023-03-22 10:06:27,369 [ssre.py] => Task 1, Epoch 47/101 => Loss 1.663, Loss_clf 0.278, Loss_fkd 1.380, Loss_proto 0.005, Train_accy 63.98
2023-03-22 10:06:32,342 [ssre.py] => Task 1, Epoch 48/101 => Loss 1.388, Loss_clf 0.278, Loss_fkd 1.105, Loss_proto 0.005, Train_accy 63.64
2023-03-22 10:06:37,436 [ssre.py] => Task 1, Epoch 49/101 => Loss 1.248, Loss_clf 0.278, Loss_fkd 0.966, Loss_proto 0.005, Train_accy 63.72
2023-03-22 10:06:42,451 [ssre.py] => Task 1, Epoch 50/101 => Loss 1.126, Loss_clf 0.274, Loss_fkd 0.848, Loss_proto 0.005, Train_accy 63.50
2023-03-22 10:06:49,851 [ssre.py] => Task 1, Epoch 51/101 => Loss 1.057, Loss_clf 0.271, Loss_fkd 0.781, Loss_proto 0.005, Train_accy 63.50, Test_accy 67.58
2023-03-22 10:06:54,954 [ssre.py] => Task 1, Epoch 52/101 => Loss 0.979, Loss_clf 0.276, Loss_fkd 0.699, Loss_proto 0.005, Train_accy 64.56
2023-03-22 10:06:59,960 [ssre.py] => Task 1, Epoch 53/101 => Loss 0.933, Loss_clf 0.276, Loss_fkd 0.652, Loss_proto 0.004, Train_accy 63.32
2023-03-22 10:07:05,091 [ssre.py] => Task 1, Epoch 54/101 => Loss 0.919, Loss_clf 0.275, Loss_fkd 0.639, Loss_proto 0.004, Train_accy 63.62
2023-03-22 10:07:10,133 [ssre.py] => Task 1, Epoch 55/101 => Loss 0.889, Loss_clf 0.271, Loss_fkd 0.613, Loss_proto 0.005, Train_accy 63.88
2023-03-22 10:07:17,605 [ssre.py] => Task 1, Epoch 56/101 => Loss 0.863, Loss_clf 0.271, Loss_fkd 0.586, Loss_proto 0.005, Train_accy 63.98, Test_accy 67.72
2023-03-22 10:07:22,687 [ssre.py] => Task 1, Epoch 57/101 => Loss 0.875, Loss_clf 0.275, Loss_fkd 0.596, Loss_proto 0.005, Train_accy 63.50
2023-03-22 10:07:27,735 [ssre.py] => Task 1, Epoch 58/101 => Loss 0.858, Loss_clf 0.282, Loss_fkd 0.571, Loss_proto 0.005, Train_accy 62.44
2023-03-22 10:07:32,992 [ssre.py] => Task 1, Epoch 59/101 => Loss 0.833, Loss_clf 0.271, Loss_fkd 0.557, Loss_proto 0.005, Train_accy 64.64
2023-03-22 10:07:38,074 [ssre.py] => Task 1, Epoch 60/101 => Loss 0.824, Loss_clf 0.282, Loss_fkd 0.537, Loss_proto 0.005, Train_accy 63.26
2023-03-22 10:07:45,590 [ssre.py] => Task 1, Epoch 61/101 => Loss 0.830, Loss_clf 0.275, Loss_fkd 0.550, Loss_proto 0.005, Train_accy 63.26, Test_accy 67.65
2023-03-22 10:07:50,692 [ssre.py] => Task 1, Epoch 62/101 => Loss 0.813, Loss_clf 0.271, Loss_fkd 0.537, Loss_proto 0.005, Train_accy 64.70
2023-03-22 10:07:55,894 [ssre.py] => Task 1, Epoch 63/101 => Loss 0.815, Loss_clf 0.277, Loss_fkd 0.533, Loss_proto 0.005, Train_accy 64.74
2023-03-22 10:08:01,064 [ssre.py] => Task 1, Epoch 64/101 => Loss 0.865, Loss_clf 0.277, Loss_fkd 0.583, Loss_proto 0.005, Train_accy 63.94
2023-03-22 10:08:06,278 [ssre.py] => Task 1, Epoch 65/101 => Loss 0.813, Loss_clf 0.269, Loss_fkd 0.540, Loss_proto 0.005, Train_accy 63.68
2023-03-22 10:08:13,836 [ssre.py] => Task 1, Epoch 66/101 => Loss 0.832, Loss_clf 0.272, Loss_fkd 0.556, Loss_proto 0.005, Train_accy 64.44, Test_accy 67.55
2023-03-22 10:08:18,939 [ssre.py] => Task 1, Epoch 67/101 => Loss 0.854, Loss_clf 0.269, Loss_fkd 0.581, Loss_proto 0.004, Train_accy 64.30
2023-03-22 10:08:24,140 [ssre.py] => Task 1, Epoch 68/101 => Loss 0.820, Loss_clf 0.282, Loss_fkd 0.533, Loss_proto 0.005, Train_accy 63.20
2023-03-22 10:08:29,372 [ssre.py] => Task 1, Epoch 69/101 => Loss 0.809, Loss_clf 0.272, Loss_fkd 0.533, Loss_proto 0.005, Train_accy 63.88
2023-03-22 10:08:34,522 [ssre.py] => Task 1, Epoch 70/101 => Loss 0.796, Loss_clf 0.271, Loss_fkd 0.520, Loss_proto 0.005, Train_accy 64.62
2023-03-22 10:08:41,948 [ssre.py] => Task 1, Epoch 71/101 => Loss 0.792, Loss_clf 0.268, Loss_fkd 0.519, Loss_proto 0.005, Train_accy 64.42, Test_accy 67.67
2023-03-22 10:08:47,122 [ssre.py] => Task 1, Epoch 72/101 => Loss 0.786, Loss_clf 0.272, Loss_fkd 0.509, Loss_proto 0.005, Train_accy 64.62
2023-03-22 10:08:52,225 [ssre.py] => Task 1, Epoch 73/101 => Loss 1.050, Loss_clf 0.276, Loss_fkd 0.770, Loss_proto 0.005, Train_accy 64.30
2023-03-22 10:08:57,279 [ssre.py] => Task 1, Epoch 74/101 => Loss 0.976, Loss_clf 0.269, Loss_fkd 0.702, Loss_proto 0.005, Train_accy 64.42
2023-03-22 10:09:02,468 [ssre.py] => Task 1, Epoch 75/101 => Loss 0.813, Loss_clf 0.276, Loss_fkd 0.532, Loss_proto 0.005, Train_accy 64.40
2023-03-22 10:09:09,851 [ssre.py] => Task 1, Epoch 76/101 => Loss 0.878, Loss_clf 0.280, Loss_fkd 0.593, Loss_proto 0.005, Train_accy 63.46, Test_accy 67.58
2023-03-22 10:09:15,006 [ssre.py] => Task 1, Epoch 77/101 => Loss 0.789, Loss_clf 0.269, Loss_fkd 0.515, Loss_proto 0.005, Train_accy 64.34
2023-03-22 10:09:20,165 [ssre.py] => Task 1, Epoch 78/101 => Loss 0.856, Loss_clf 0.272, Loss_fkd 0.580, Loss_proto 0.005, Train_accy 63.46
2023-03-22 10:09:25,316 [ssre.py] => Task 1, Epoch 79/101 => Loss 0.773, Loss_clf 0.269, Loss_fkd 0.499, Loss_proto 0.005, Train_accy 63.72
2023-03-22 10:09:30,364 [ssre.py] => Task 1, Epoch 80/101 => Loss 0.989, Loss_clf 0.268, Loss_fkd 0.716, Loss_proto 0.005, Train_accy 65.34
2023-03-22 10:09:37,821 [ssre.py] => Task 1, Epoch 81/101 => Loss 0.874, Loss_clf 0.279, Loss_fkd 0.591, Loss_proto 0.004, Train_accy 63.32, Test_accy 67.82
2023-03-22 10:09:42,954 [ssre.py] => Task 1, Epoch 82/101 => Loss 0.871, Loss_clf 0.277, Loss_fkd 0.590, Loss_proto 0.004, Train_accy 63.54
2023-03-22 10:09:48,020 [ssre.py] => Task 1, Epoch 83/101 => Loss 1.161, Loss_clf 0.281, Loss_fkd 0.876, Loss_proto 0.005, Train_accy 63.82
2023-03-22 10:09:53,160 [ssre.py] => Task 1, Epoch 84/101 => Loss 1.148, Loss_clf 0.271, Loss_fkd 0.873, Loss_proto 0.005, Train_accy 64.72
2023-03-22 10:09:58,251 [ssre.py] => Task 1, Epoch 85/101 => Loss 1.004, Loss_clf 0.274, Loss_fkd 0.726, Loss_proto 0.005, Train_accy 63.24
2023-03-22 10:10:05,579 [ssre.py] => Task 1, Epoch 86/101 => Loss 0.803, Loss_clf 0.271, Loss_fkd 0.527, Loss_proto 0.005, Train_accy 63.66, Test_accy 67.45
2023-03-22 10:10:10,635 [ssre.py] => Task 1, Epoch 87/101 => Loss 0.841, Loss_clf 0.268, Loss_fkd 0.568, Loss_proto 0.005, Train_accy 64.18
2023-03-22 10:10:15,644 [ssre.py] => Task 1, Epoch 88/101 => Loss 0.761, Loss_clf 0.269, Loss_fkd 0.487, Loss_proto 0.005, Train_accy 63.74
2023-03-22 10:10:20,680 [ssre.py] => Task 1, Epoch 89/101 => Loss 0.808, Loss_clf 0.276, Loss_fkd 0.527, Loss_proto 0.005, Train_accy 63.82
2023-03-22 10:10:25,788 [ssre.py] => Task 1, Epoch 90/101 => Loss 0.772, Loss_clf 0.276, Loss_fkd 0.491, Loss_proto 0.005, Train_accy 62.94
2023-03-22 10:10:33,340 [ssre.py] => Task 1, Epoch 91/101 => Loss 0.629, Loss_clf 0.270, Loss_fkd 0.355, Loss_proto 0.005, Train_accy 64.38, Test_accy 67.77
2023-03-22 10:10:38,547 [ssre.py] => Task 1, Epoch 92/101 => Loss 0.448, Loss_clf 0.270, Loss_fkd 0.173, Loss_proto 0.005, Train_accy 63.78
2023-03-22 10:10:43,727 [ssre.py] => Task 1, Epoch 93/101 => Loss 0.436, Loss_clf 0.274, Loss_fkd 0.157, Loss_proto 0.005, Train_accy 63.64
2023-03-22 10:10:48,758 [ssre.py] => Task 1, Epoch 94/101 => Loss 0.436, Loss_clf 0.284, Loss_fkd 0.147, Loss_proto 0.005, Train_accy 63.32
2023-03-22 10:10:53,848 [ssre.py] => Task 1, Epoch 95/101 => Loss 0.420, Loss_clf 0.274, Loss_fkd 0.142, Loss_proto 0.005, Train_accy 64.62
2023-03-22 10:11:01,400 [ssre.py] => Task 1, Epoch 96/101 => Loss 0.411, Loss_clf 0.269, Loss_fkd 0.137, Loss_proto 0.004, Train_accy 64.78, Test_accy 67.67
2023-03-22 10:11:06,619 [ssre.py] => Task 1, Epoch 97/101 => Loss 0.408, Loss_clf 0.269, Loss_fkd 0.135, Loss_proto 0.005, Train_accy 63.86
2023-03-22 10:11:11,749 [ssre.py] => Task 1, Epoch 98/101 => Loss 0.406, Loss_clf 0.270, Loss_fkd 0.131, Loss_proto 0.005, Train_accy 64.42
2023-03-22 10:11:16,963 [ssre.py] => Task 1, Epoch 99/101 => Loss 0.407, Loss_clf 0.272, Loss_fkd 0.130, Loss_proto 0.005, Train_accy 63.78
2023-03-22 10:11:22,097 [ssre.py] => Task 1, Epoch 100/101 => Loss 0.406, Loss_clf 0.275, Loss_fkd 0.126, Loss_proto 0.005, Train_accy 64.76
2023-03-22 10:11:29,597 [ssre.py] => Task 1, Epoch 101/101 => Loss 0.405, Loss_clf 0.277, Loss_fkd 0.124, Loss_proto 0.005, Train_accy 63.96, Test_accy 67.60
2023-03-22 10:11:36,083 [ssre.py] => Model Compression!
2023-03-22 10:11:40,117 [trainer.py] => CNN: {'total': 67.6, '00-09': 69.9, '10-19': 64.7, '20-29': 71.4, '30-39': 65.8, '40-49': 72.6, '50-59': 61.2, 'old': 68.88, 'new': 61.2}
2023-03-22 10:11:40,118 [trainer.py] => NME: {'total': 65.95, '00-09': 70.3, '10-19': 61.6, '20-29': 73.7, '30-39': 64.2, '40-49': 72.2, '50-59': 53.7, 'old': 68.4, 'new': 53.7}
2023-03-22 10:11:40,118 [trainer.py] => CNN top1 curve: [79.4, 67.6]
2023-03-22 10:11:40,118 [trainer.py] => CNN top5 curve: [95.74, 90.0]
2023-03-22 10:11:40,118 [trainer.py] => NME top1 curve: [73.28, 65.95]
2023-03-22 10:11:40,118 [trainer.py] => NME top5 curve: [94.32, 90.88]

2023-03-22 10:11:40,118 [trainer.py] => All params: 12427004
2023-03-22 10:11:40,119 [trainer.py] => Trainable params: 1255228
2023-03-22 10:11:40,120 [ssre.py] => Model Expansion!
2023-03-22 10:11:40,121 [ssre.py] => Learning on 60-70
2023-03-22 10:11:40,121 [ssre.py] => All params: 12432134
2023-03-22 10:11:40,122 [ssre.py] => Trainable params: 1260358
2023-03-22 10:11:47,790 [ssre.py] => Task 2, Epoch 1/101 => Loss 19.090, Loss_clf 0.961, Loss_fkd 17.795, Loss_proto 0.334, Train_accy 8.60, Test_accy 58.93
2023-03-22 10:11:52,820 [ssre.py] => Task 2, Epoch 2/101 => Loss 6.750, Loss_clf 0.486, Loss_fkd 6.063, Loss_proto 0.201, Train_accy 37.24
2023-03-22 10:11:57,775 [ssre.py] => Task 2, Epoch 3/101 => Loss 6.622, Loss_clf 0.357, Loss_fkd 6.116, Loss_proto 0.148, Train_accy 52.18
2023-03-22 10:12:02,875 [ssre.py] => Task 2, Epoch 4/101 => Loss 6.438, Loss_clf 0.300, Loss_fkd 6.024, Loss_proto 0.115, Train_accy 59.02
2023-03-22 10:12:07,882 [ssre.py] => Task 2, Epoch 5/101 => Loss 6.262, Loss_clf 0.262, Loss_fkd 5.901, Loss_proto 0.099, Train_accy 63.78
2023-03-22 10:12:15,572 [ssre.py] => Task 2, Epoch 6/101 => Loss 7.100, Loss_clf 0.243, Loss_fkd 6.775, Loss_proto 0.082, Train_accy 66.48, Test_accy 62.84
2023-03-22 10:12:20,694 [ssre.py] => Task 2, Epoch 7/101 => Loss 5.887, Loss_clf 0.228, Loss_fkd 5.587, Loss_proto 0.072, Train_accy 67.76
2023-03-22 10:12:25,716 [ssre.py] => Task 2, Epoch 8/101 => Loss 5.511, Loss_clf 0.219, Loss_fkd 5.225, Loss_proto 0.067, Train_accy 69.52
2023-03-22 10:12:30,714 [ssre.py] => Task 2, Epoch 9/101 => Loss 5.662, Loss_clf 0.208, Loss_fkd 5.394, Loss_proto 0.060, Train_accy 71.64
2023-03-22 10:12:35,842 [ssre.py] => Task 2, Epoch 10/101 => Loss 6.910, Loss_clf 0.204, Loss_fkd 6.652, Loss_proto 0.054, Train_accy 71.86
2023-03-22 10:12:43,634 [ssre.py] => Task 2, Epoch 11/101 => Loss 6.745, Loss_clf 0.202, Loss_fkd 6.491, Loss_proto 0.051, Train_accy 73.42, Test_accy 63.31
2023-03-22 10:12:48,665 [ssre.py] => Task 2, Epoch 12/101 => Loss 7.954, Loss_clf 0.190, Loss_fkd 7.715, Loss_proto 0.049, Train_accy 73.84
2023-03-22 10:12:53,749 [ssre.py] => Task 2, Epoch 13/101 => Loss 7.559, Loss_clf 0.184, Loss_fkd 7.329, Loss_proto 0.045, Train_accy 74.52
2023-03-22 10:12:58,822 [ssre.py] => Task 2, Epoch 14/101 => Loss 7.083, Loss_clf 0.179, Loss_fkd 6.861, Loss_proto 0.043, Train_accy 75.84
2023-03-22 10:13:03,918 [ssre.py] => Task 2, Epoch 15/101 => Loss 6.299, Loss_clf 0.173, Loss_fkd 6.086, Loss_proto 0.041, Train_accy 76.38
2023-03-22 10:13:11,831 [ssre.py] => Task 2, Epoch 16/101 => Loss 5.442, Loss_clf 0.172, Loss_fkd 5.232, Loss_proto 0.038, Train_accy 76.78, Test_accy 63.14
2023-03-22 10:13:16,835 [ssre.py] => Task 2, Epoch 17/101 => Loss 5.262, Loss_clf 0.167, Loss_fkd 5.058, Loss_proto 0.037, Train_accy 76.30
2023-03-22 10:13:21,923 [ssre.py] => Task 2, Epoch 18/101 => Loss 5.112, Loss_clf 0.163, Loss_fkd 4.915, Loss_proto 0.035, Train_accy 77.02
2023-03-22 10:13:27,077 [ssre.py] => Task 2, Epoch 19/101 => Loss 5.879, Loss_clf 0.160, Loss_fkd 5.683, Loss_proto 0.035, Train_accy 78.40
2023-03-22 10:13:32,108 [ssre.py] => Task 2, Epoch 20/101 => Loss 6.403, Loss_clf 0.163, Loss_fkd 6.207, Loss_proto 0.033, Train_accy 78.20
2023-03-22 10:13:39,889 [ssre.py] => Task 2, Epoch 21/101 => Loss 5.054, Loss_clf 0.150, Loss_fkd 4.872, Loss_proto 0.032, Train_accy 78.84, Test_accy 62.80
2023-03-22 10:13:44,999 [ssre.py] => Task 2, Epoch 22/101 => Loss 4.865, Loss_clf 0.149, Loss_fkd 4.686, Loss_proto 0.031, Train_accy 79.04
2023-03-22 10:13:50,073 [ssre.py] => Task 2, Epoch 23/101 => Loss 5.207, Loss_clf 0.152, Loss_fkd 5.024, Loss_proto 0.030, Train_accy 78.40
2023-03-22 10:13:55,162 [ssre.py] => Task 2, Epoch 24/101 => Loss 7.243, Loss_clf 0.153, Loss_fkd 7.059, Loss_proto 0.031, Train_accy 79.50
2023-03-22 10:14:00,367 [ssre.py] => Task 2, Epoch 25/101 => Loss 5.398, Loss_clf 0.146, Loss_fkd 5.223, Loss_proto 0.029, Train_accy 79.62
2023-03-22 10:14:08,067 [ssre.py] => Task 2, Epoch 26/101 => Loss 6.089, Loss_clf 0.145, Loss_fkd 5.916, Loss_proto 0.028, Train_accy 79.88, Test_accy 63.04
2023-03-22 10:14:13,267 [ssre.py] => Task 2, Epoch 27/101 => Loss 6.529, Loss_clf 0.142, Loss_fkd 6.358, Loss_proto 0.030, Train_accy 80.04
2023-03-22 10:14:18,278 [ssre.py] => Task 2, Epoch 28/101 => Loss 5.987, Loss_clf 0.149, Loss_fkd 5.811, Loss_proto 0.027, Train_accy 80.26
2023-03-22 10:14:23,347 [ssre.py] => Task 2, Epoch 29/101 => Loss 7.542, Loss_clf 0.140, Loss_fkd 7.374, Loss_proto 0.028, Train_accy 80.78
2023-03-22 10:14:28,362 [ssre.py] => Task 2, Epoch 30/101 => Loss 7.209, Loss_clf 0.137, Loss_fkd 7.045, Loss_proto 0.027, Train_accy 80.00
2023-03-22 10:14:35,922 [ssre.py] => Task 2, Epoch 31/101 => Loss 5.243, Loss_clf 0.131, Loss_fkd 5.088, Loss_proto 0.024, Train_accy 81.78, Test_accy 62.76
2023-03-22 10:14:40,888 [ssre.py] => Task 2, Epoch 32/101 => Loss 5.560, Loss_clf 0.135, Loss_fkd 5.399, Loss_proto 0.026, Train_accy 81.50
2023-03-22 10:14:46,044 [ssre.py] => Task 2, Epoch 33/101 => Loss 5.164, Loss_clf 0.138, Loss_fkd 5.002, Loss_proto 0.025, Train_accy 81.22
2023-03-22 10:14:51,254 [ssre.py] => Task 2, Epoch 34/101 => Loss 7.421, Loss_clf 0.127, Loss_fkd 7.269, Loss_proto 0.025, Train_accy 81.60
2023-03-22 10:14:56,332 [ssre.py] => Task 2, Epoch 35/101 => Loss 5.341, Loss_clf 0.128, Loss_fkd 5.188, Loss_proto 0.025, Train_accy 81.90
2023-03-22 10:15:03,941 [ssre.py] => Task 2, Epoch 36/101 => Loss 5.751, Loss_clf 0.124, Loss_fkd 5.603, Loss_proto 0.024, Train_accy 82.22, Test_accy 62.56
2023-03-22 10:15:09,052 [ssre.py] => Task 2, Epoch 37/101 => Loss 6.064, Loss_clf 0.124, Loss_fkd 5.918, Loss_proto 0.023, Train_accy 81.98
2023-03-22 10:15:14,125 [ssre.py] => Task 2, Epoch 38/101 => Loss 5.128, Loss_clf 0.125, Loss_fkd 4.980, Loss_proto 0.022, Train_accy 82.02
2023-03-22 10:15:19,323 [ssre.py] => Task 2, Epoch 39/101 => Loss 5.987, Loss_clf 0.123, Loss_fkd 5.842, Loss_proto 0.022, Train_accy 82.54
2023-03-22 10:15:24,432 [ssre.py] => Task 2, Epoch 40/101 => Loss 5.893, Loss_clf 0.127, Loss_fkd 5.743, Loss_proto 0.023, Train_accy 82.38
2023-03-22 10:15:32,256 [ssre.py] => Task 2, Epoch 41/101 => Loss 5.561, Loss_clf 0.125, Loss_fkd 5.414, Loss_proto 0.022, Train_accy 82.28, Test_accy 62.27
2023-03-22 10:15:37,341 [ssre.py] => Task 2, Epoch 42/101 => Loss 5.041, Loss_clf 0.121, Loss_fkd 4.899, Loss_proto 0.022, Train_accy 82.60
2023-03-22 10:15:42,567 [ssre.py] => Task 2, Epoch 43/101 => Loss 5.090, Loss_clf 0.122, Loss_fkd 4.946, Loss_proto 0.021, Train_accy 81.82
2023-03-22 10:15:47,634 [ssre.py] => Task 2, Epoch 44/101 => Loss 5.008, Loss_clf 0.119, Loss_fkd 4.868, Loss_proto 0.021, Train_accy 82.78
2023-03-22 10:15:52,755 [ssre.py] => Task 2, Epoch 45/101 => Loss 4.869, Loss_clf 0.124, Loss_fkd 4.725, Loss_proto 0.020, Train_accy 83.08
2023-03-22 10:16:00,558 [ssre.py] => Task 2, Epoch 46/101 => Loss 3.179, Loss_clf 0.115, Loss_fkd 3.043, Loss_proto 0.021, Train_accy 83.02, Test_accy 62.70
2023-03-22 10:16:05,678 [ssre.py] => Task 2, Epoch 47/101 => Loss 1.461, Loss_clf 0.117, Loss_fkd 1.324, Loss_proto 0.020, Train_accy 82.56
2023-03-22 10:16:10,662 [ssre.py] => Task 2, Epoch 48/101 => Loss 1.179, Loss_clf 0.115, Loss_fkd 1.043, Loss_proto 0.020, Train_accy 83.90
2023-03-22 10:16:15,806 [ssre.py] => Task 2, Epoch 49/101 => Loss 1.027, Loss_clf 0.114, Loss_fkd 0.893, Loss_proto 0.020, Train_accy 83.26
2023-03-22 10:16:20,859 [ssre.py] => Task 2, Epoch 50/101 => Loss 0.932, Loss_clf 0.114, Loss_fkd 0.799, Loss_proto 0.019, Train_accy 84.02
2023-03-22 10:16:28,513 [ssre.py] => Task 2, Epoch 51/101 => Loss 0.872, Loss_clf 0.112, Loss_fkd 0.740, Loss_proto 0.020, Train_accy 83.60, Test_accy 62.60
2023-03-22 10:16:33,670 [ssre.py] => Task 2, Epoch 52/101 => Loss 0.802, Loss_clf 0.114, Loss_fkd 0.668, Loss_proto 0.020, Train_accy 83.88
2023-03-22 10:16:38,768 [ssre.py] => Task 2, Epoch 53/101 => Loss 0.758, Loss_clf 0.112, Loss_fkd 0.625, Loss_proto 0.020, Train_accy 83.82
2023-03-22 10:16:43,923 [ssre.py] => Task 2, Epoch 54/101 => Loss 0.756, Loss_clf 0.118, Loss_fkd 0.619, Loss_proto 0.019, Train_accy 83.18
2023-03-22 10:16:48,983 [ssre.py] => Task 2, Epoch 55/101 => Loss 0.772, Loss_clf 0.115, Loss_fkd 0.637, Loss_proto 0.020, Train_accy 83.46
2023-03-22 10:16:56,470 [ssre.py] => Task 2, Epoch 56/101 => Loss 0.764, Loss_clf 0.113, Loss_fkd 0.631, Loss_proto 0.020, Train_accy 83.18, Test_accy 62.41
2023-03-22 10:17:01,579 [ssre.py] => Task 2, Epoch 57/101 => Loss 0.721, Loss_clf 0.112, Loss_fkd 0.589, Loss_proto 0.020, Train_accy 83.58
2023-03-22 10:17:06,624 [ssre.py] => Task 2, Epoch 58/101 => Loss 0.726, Loss_clf 0.112, Loss_fkd 0.594, Loss_proto 0.019, Train_accy 83.74
2023-03-22 10:17:11,668 [ssre.py] => Task 2, Epoch 59/101 => Loss 1.097, Loss_clf 0.115, Loss_fkd 0.963, Loss_proto 0.019, Train_accy 83.16
2023-03-22 10:17:16,535 [ssre.py] => Task 2, Epoch 60/101 => Loss 0.885, Loss_clf 0.115, Loss_fkd 0.751, Loss_proto 0.019, Train_accy 83.50
2023-03-22 10:17:24,350 [ssre.py] => Task 2, Epoch 61/101 => Loss 0.813, Loss_clf 0.117, Loss_fkd 0.673, Loss_proto 0.022, Train_accy 82.92, Test_accy 62.61
2023-03-22 10:17:29,500 [ssre.py] => Task 2, Epoch 62/101 => Loss 0.841, Loss_clf 0.113, Loss_fkd 0.708, Loss_proto 0.020, Train_accy 83.82
2023-03-22 10:17:34,501 [ssre.py] => Task 2, Epoch 63/101 => Loss 0.734, Loss_clf 0.116, Loss_fkd 0.598, Loss_proto 0.020, Train_accy 83.54
2023-03-22 10:17:39,545 [ssre.py] => Task 2, Epoch 64/101 => Loss 0.676, Loss_clf 0.111, Loss_fkd 0.545, Loss_proto 0.020, Train_accy 84.36
2023-03-22 10:17:44,734 [ssre.py] => Task 2, Epoch 65/101 => Loss 0.717, Loss_clf 0.118, Loss_fkd 0.580, Loss_proto 0.019, Train_accy 83.54
2023-03-22 10:17:52,192 [ssre.py] => Task 2, Epoch 66/101 => Loss 0.688, Loss_clf 0.109, Loss_fkd 0.558, Loss_proto 0.021, Train_accy 83.98, Test_accy 62.64
2023-03-22 10:17:57,057 [ssre.py] => Task 2, Epoch 67/101 => Loss 0.985, Loss_clf 0.112, Loss_fkd 0.854, Loss_proto 0.019, Train_accy 84.16
2023-03-22 10:18:02,277 [ssre.py] => Task 2, Epoch 68/101 => Loss 1.118, Loss_clf 0.114, Loss_fkd 0.984, Loss_proto 0.020, Train_accy 82.82
2023-03-22 10:18:07,514 [ssre.py] => Task 2, Epoch 69/101 => Loss 0.811, Loss_clf 0.110, Loss_fkd 0.681, Loss_proto 0.020, Train_accy 83.80
2023-03-22 10:18:12,584 [ssre.py] => Task 2, Epoch 70/101 => Loss 0.840, Loss_clf 0.118, Loss_fkd 0.703, Loss_proto 0.020, Train_accy 83.70
2023-03-22 10:18:20,495 [ssre.py] => Task 2, Epoch 71/101 => Loss 0.734, Loss_clf 0.114, Loss_fkd 0.600, Loss_proto 0.019, Train_accy 83.94, Test_accy 62.79
2023-03-22 10:18:25,664 [ssre.py] => Task 2, Epoch 72/101 => Loss 0.781, Loss_clf 0.110, Loss_fkd 0.650, Loss_proto 0.020, Train_accy 83.44
2023-03-22 10:18:30,871 [ssre.py] => Task 2, Epoch 73/101 => Loss 0.761, Loss_clf 0.111, Loss_fkd 0.631, Loss_proto 0.019, Train_accy 83.58
2023-03-22 10:18:35,909 [ssre.py] => Task 2, Epoch 74/101 => Loss 0.955, Loss_clf 0.114, Loss_fkd 0.822, Loss_proto 0.020, Train_accy 83.90
2023-03-22 10:18:41,016 [ssre.py] => Task 2, Epoch 75/101 => Loss 0.931, Loss_clf 0.112, Loss_fkd 0.799, Loss_proto 0.020, Train_accy 83.38
2023-03-22 10:18:48,710 [ssre.py] => Task 2, Epoch 76/101 => Loss 0.828, Loss_clf 0.116, Loss_fkd 0.692, Loss_proto 0.020, Train_accy 83.68, Test_accy 62.44
2023-03-22 10:18:53,919 [ssre.py] => Task 2, Epoch 77/101 => Loss 0.722, Loss_clf 0.113, Loss_fkd 0.589, Loss_proto 0.020, Train_accy 83.74
2023-03-22 10:18:59,075 [ssre.py] => Task 2, Epoch 78/101 => Loss 0.658, Loss_clf 0.115, Loss_fkd 0.523, Loss_proto 0.020, Train_accy 84.22
2023-03-22 10:19:04,022 [ssre.py] => Task 2, Epoch 79/101 => Loss 0.656, Loss_clf 0.111, Loss_fkd 0.525, Loss_proto 0.020, Train_accy 83.78
2023-03-22 10:19:09,128 [ssre.py] => Task 2, Epoch 80/101 => Loss 0.672, Loss_clf 0.110, Loss_fkd 0.542, Loss_proto 0.020, Train_accy 84.12
2023-03-22 10:19:16,914 [ssre.py] => Task 2, Epoch 81/101 => Loss 1.000, Loss_clf 0.111, Loss_fkd 0.870, Loss_proto 0.019, Train_accy 83.60, Test_accy 62.57
2023-03-22 10:19:22,095 [ssre.py] => Task 2, Epoch 82/101 => Loss 0.920, Loss_clf 0.111, Loss_fkd 0.790, Loss_proto 0.019, Train_accy 84.16
2023-03-22 10:19:27,152 [ssre.py] => Task 2, Epoch 83/101 => Loss 0.861, Loss_clf 0.111, Loss_fkd 0.731, Loss_proto 0.019, Train_accy 84.04
2023-03-22 10:19:32,268 [ssre.py] => Task 2, Epoch 84/101 => Loss 0.633, Loss_clf 0.106, Loss_fkd 0.506, Loss_proto 0.020, Train_accy 84.42
2023-03-22 10:19:37,206 [ssre.py] => Task 2, Epoch 85/101 => Loss 0.675, Loss_clf 0.110, Loss_fkd 0.546, Loss_proto 0.019, Train_accy 84.12
2023-03-22 10:19:44,645 [ssre.py] => Task 2, Epoch 86/101 => Loss 0.666, Loss_clf 0.113, Loss_fkd 0.535, Loss_proto 0.019, Train_accy 84.18, Test_accy 62.61
2023-03-22 10:19:49,657 [ssre.py] => Task 2, Epoch 87/101 => Loss 0.660, Loss_clf 0.111, Loss_fkd 0.529, Loss_proto 0.019, Train_accy 84.30
2023-03-22 10:19:54,736 [ssre.py] => Task 2, Epoch 88/101 => Loss 0.679, Loss_clf 0.109, Loss_fkd 0.550, Loss_proto 0.020, Train_accy 84.06
2023-03-22 10:19:59,911 [ssre.py] => Task 2, Epoch 89/101 => Loss 0.639, Loss_clf 0.109, Loss_fkd 0.512, Loss_proto 0.019, Train_accy 84.22
2023-03-22 10:20:05,002 [ssre.py] => Task 2, Epoch 90/101 => Loss 0.643, Loss_clf 0.111, Loss_fkd 0.513, Loss_proto 0.019, Train_accy 83.92
2023-03-22 10:20:12,676 [ssre.py] => Task 2, Epoch 91/101 => Loss 0.489, Loss_clf 0.112, Loss_fkd 0.356, Loss_proto 0.020, Train_accy 83.62, Test_accy 62.61
2023-03-22 10:20:17,753 [ssre.py] => Task 2, Epoch 92/101 => Loss 0.305, Loss_clf 0.110, Loss_fkd 0.175, Loss_proto 0.020, Train_accy 84.38
2023-03-22 10:20:22,822 [ssre.py] => Task 2, Epoch 93/101 => Loss 0.280, Loss_clf 0.108, Loss_fkd 0.151, Loss_proto 0.020, Train_accy 84.36
2023-03-22 10:20:27,897 [ssre.py] => Task 2, Epoch 94/101 => Loss 0.268, Loss_clf 0.109, Loss_fkd 0.141, Loss_proto 0.018, Train_accy 84.38
2023-03-22 10:20:32,928 [ssre.py] => Task 2, Epoch 95/101 => Loss 0.262, Loss_clf 0.110, Loss_fkd 0.134, Loss_proto 0.019, Train_accy 83.90
2023-03-22 10:20:40,635 [ssre.py] => Task 2, Epoch 96/101 => Loss 0.254, Loss_clf 0.105, Loss_fkd 0.129, Loss_proto 0.020, Train_accy 84.66, Test_accy 62.64
2023-03-22 10:20:45,731 [ssre.py] => Task 2, Epoch 97/101 => Loss 0.259, Loss_clf 0.114, Loss_fkd 0.126, Loss_proto 0.019, Train_accy 84.10
2023-03-22 10:20:50,855 [ssre.py] => Task 2, Epoch 98/101 => Loss 0.250, Loss_clf 0.110, Loss_fkd 0.122, Loss_proto 0.018, Train_accy 84.22
2023-03-22 10:20:55,926 [ssre.py] => Task 2, Epoch 99/101 => Loss 0.249, Loss_clf 0.112, Loss_fkd 0.118, Loss_proto 0.019, Train_accy 84.28
2023-03-22 10:21:01,113 [ssre.py] => Task 2, Epoch 100/101 => Loss 0.244, Loss_clf 0.110, Loss_fkd 0.116, Loss_proto 0.018, Train_accy 83.78
2023-03-22 10:21:08,789 [ssre.py] => Task 2, Epoch 101/101 => Loss 0.238, Loss_clf 0.106, Loss_fkd 0.114, Loss_proto 0.018, Train_accy 84.88, Test_accy 62.70
2023-03-22 10:21:15,420 [ssre.py] => Model Compression!
2023-03-22 10:21:19,825 [trainer.py] => CNN: {'total': 62.7, '00-09': 65.5, '10-19': 55.1, '20-29': 67.2, '30-39': 58.5, '40-49': 66.0, '50-59': 56.0, '60-69': 70.6, 'old': 61.38, 'new': 70.6}
2023-03-22 10:21:19,825 [trainer.py] => NME: {'total': 61.56, '00-09': 68.0, '10-19': 58.2, '20-29': 72.6, '30-39': 61.1, '40-49': 69.3, '50-59': 47.8, '60-69': 53.9, 'old': 62.83, 'new': 53.9}
2023-03-22 10:21:19,825 [trainer.py] => CNN top1 curve: [79.4, 67.6, 62.7]
2023-03-22 10:21:19,825 [trainer.py] => CNN top5 curve: [95.74, 90.0, 87.86]
2023-03-22 10:21:19,825 [trainer.py] => NME top1 curve: [73.28, 65.95, 61.56]
2023-03-22 10:21:19,826 [trainer.py] => NME top5 curve: [94.32, 90.88, 87.79]

2023-03-22 10:21:19,826 [trainer.py] => All params: 12432134
2023-03-22 10:21:19,826 [trainer.py] => Trainable params: 1260358
2023-03-22 10:21:19,827 [ssre.py] => Model Expansion!
2023-03-22 10:21:19,829 [ssre.py] => Learning on 70-80
2023-03-22 10:21:19,829 [ssre.py] => All params: 12437264
2023-03-22 10:21:19,829 [ssre.py] => Trainable params: 1265488
2023-03-22 10:21:27,799 [ssre.py] => Task 3, Epoch 1/101 => Loss 15.958, Loss_clf 1.112, Loss_fkd 14.648, Loss_proto 0.198, Train_accy 6.88, Test_accy 56.74
2023-03-22 10:21:32,977 [ssre.py] => Task 3, Epoch 2/101 => Loss 8.102, Loss_clf 0.621, Loss_fkd 7.322, Loss_proto 0.159, Train_accy 28.26
2023-03-22 10:21:37,971 [ssre.py] => Task 3, Epoch 3/101 => Loss 6.746, Loss_clf 0.477, Loss_fkd 6.137, Loss_proto 0.132, Train_accy 41.98
2023-03-22 10:21:43,119 [ssre.py] => Task 3, Epoch 4/101 => Loss 7.695, Loss_clf 0.423, Loss_fkd 7.154, Loss_proto 0.119, Train_accy 48.00
2023-03-22 10:21:48,278 [ssre.py] => Task 3, Epoch 5/101 => Loss 7.163, Loss_clf 0.366, Loss_fkd 6.697, Loss_proto 0.100, Train_accy 52.88
2023-03-22 10:21:56,367 [ssre.py] => Task 3, Epoch 6/101 => Loss 6.599, Loss_clf 0.340, Loss_fkd 6.169, Loss_proto 0.090, Train_accy 57.32, Test_accy 58.68
2023-03-22 10:22:01,474 [ssre.py] => Task 3, Epoch 7/101 => Loss 6.500, Loss_clf 0.315, Loss_fkd 6.100, Loss_proto 0.085, Train_accy 59.52
2023-03-22 10:22:06,518 [ssre.py] => Task 3, Epoch 8/101 => Loss 7.537, Loss_clf 0.307, Loss_fkd 7.143, Loss_proto 0.086, Train_accy 61.28
2023-03-22 10:22:11,592 [ssre.py] => Task 3, Epoch 9/101 => Loss 7.117, Loss_clf 0.282, Loss_fkd 6.754, Loss_proto 0.081, Train_accy 63.10
2023-03-22 10:22:16,539 [ssre.py] => Task 3, Epoch 10/101 => Loss 5.387, Loss_clf 0.277, Loss_fkd 5.038, Loss_proto 0.072, Train_accy 64.36
2023-03-22 10:22:24,658 [ssre.py] => Task 3, Epoch 11/101 => Loss 7.254, Loss_clf 0.265, Loss_fkd 6.919, Loss_proto 0.070, Train_accy 65.52, Test_accy 58.78
2023-03-22 10:22:29,746 [ssre.py] => Task 3, Epoch 12/101 => Loss 6.666, Loss_clf 0.258, Loss_fkd 6.342, Loss_proto 0.066, Train_accy 66.58
2023-03-22 10:22:34,853 [ssre.py] => Task 3, Epoch 13/101 => Loss 5.573, Loss_clf 0.251, Loss_fkd 5.261, Loss_proto 0.061, Train_accy 67.24
2023-03-22 10:22:39,993 [ssre.py] => Task 3, Epoch 14/101 => Loss 6.711, Loss_clf 0.239, Loss_fkd 6.409, Loss_proto 0.063, Train_accy 68.18
2023-03-22 10:22:45,008 [ssre.py] => Task 3, Epoch 15/101 => Loss 5.410, Loss_clf 0.230, Loss_fkd 5.124, Loss_proto 0.056, Train_accy 69.44
2023-03-22 10:22:52,723 [ssre.py] => Task 3, Epoch 16/101 => Loss 5.352, Loss_clf 0.228, Loss_fkd 5.067, Loss_proto 0.056, Train_accy 69.44, Test_accy 58.60
2023-03-22 10:22:57,848 [ssre.py] => Task 3, Epoch 17/101 => Loss 8.168, Loss_clf 0.220, Loss_fkd 7.893, Loss_proto 0.055, Train_accy 70.66
2023-03-22 10:23:02,875 [ssre.py] => Task 3, Epoch 18/101 => Loss 6.635, Loss_clf 0.217, Loss_fkd 6.365, Loss_proto 0.053, Train_accy 71.14
2023-03-22 10:23:07,984 [ssre.py] => Task 3, Epoch 19/101 => Loss 6.788, Loss_clf 0.210, Loss_fkd 6.523, Loss_proto 0.055, Train_accy 71.16
2023-03-22 10:23:13,097 [ssre.py] => Task 3, Epoch 20/101 => Loss 5.635, Loss_clf 0.206, Loss_fkd 5.375, Loss_proto 0.053, Train_accy 71.98
2023-03-22 10:23:21,329 [ssre.py] => Task 3, Epoch 21/101 => Loss 7.093, Loss_clf 0.204, Loss_fkd 6.840, Loss_proto 0.049, Train_accy 72.42, Test_accy 58.00
2023-03-22 10:23:26,609 [ssre.py] => Task 3, Epoch 22/101 => Loss 5.650, Loss_clf 0.209, Loss_fkd 5.391, Loss_proto 0.049, Train_accy 72.60
2023-03-22 10:23:31,755 [ssre.py] => Task 3, Epoch 23/101 => Loss 5.485, Loss_clf 0.199, Loss_fkd 5.237, Loss_proto 0.049, Train_accy 73.12
2023-03-22 10:23:36,944 [ssre.py] => Task 3, Epoch 24/101 => Loss 8.575, Loss_clf 0.193, Loss_fkd 8.334, Loss_proto 0.048, Train_accy 72.62
2023-03-22 10:23:42,106 [ssre.py] => Task 3, Epoch 25/101 => Loss 7.674, Loss_clf 0.193, Loss_fkd 7.436, Loss_proto 0.045, Train_accy 73.64
2023-03-22 10:23:50,060 [ssre.py] => Task 3, Epoch 26/101 => Loss 7.317, Loss_clf 0.195, Loss_fkd 7.074, Loss_proto 0.048, Train_accy 73.80, Test_accy 58.45
2023-03-22 10:23:55,148 [ssre.py] => Task 3, Epoch 27/101 => Loss 6.945, Loss_clf 0.179, Loss_fkd 6.721, Loss_proto 0.045, Train_accy 75.34
2023-03-22 10:24:00,192 [ssre.py] => Task 3, Epoch 28/101 => Loss 6.649, Loss_clf 0.182, Loss_fkd 6.425, Loss_proto 0.042, Train_accy 74.78
2023-03-22 10:24:05,064 [ssre.py] => Task 3, Epoch 29/101 => Loss 5.838, Loss_clf 0.180, Loss_fkd 5.614, Loss_proto 0.044, Train_accy 75.14
2023-03-22 10:24:10,148 [ssre.py] => Task 3, Epoch 30/101 => Loss 6.668, Loss_clf 0.177, Loss_fkd 6.449, Loss_proto 0.042, Train_accy 75.96
2023-03-22 10:24:18,096 [ssre.py] => Task 3, Epoch 31/101 => Loss 5.095, Loss_clf 0.178, Loss_fkd 4.875, Loss_proto 0.042, Train_accy 75.00, Test_accy 58.05
2023-03-22 10:24:23,199 [ssre.py] => Task 3, Epoch 32/101 => Loss 7.459, Loss_clf 0.168, Loss_fkd 7.251, Loss_proto 0.040, Train_accy 76.00
2023-03-22 10:24:28,213 [ssre.py] => Task 3, Epoch 33/101 => Loss 5.029, Loss_clf 0.171, Loss_fkd 4.818, Loss_proto 0.040, Train_accy 75.96
2023-03-22 10:24:33,162 [ssre.py] => Task 3, Epoch 34/101 => Loss 5.603, Loss_clf 0.169, Loss_fkd 5.395, Loss_proto 0.039, Train_accy 77.12
2023-03-22 10:24:38,207 [ssre.py] => Task 3, Epoch 35/101 => Loss 5.832, Loss_clf 0.163, Loss_fkd 5.632, Loss_proto 0.037, Train_accy 76.52
2023-03-22 10:24:46,179 [ssre.py] => Task 3, Epoch 36/101 => Loss 5.985, Loss_clf 0.163, Loss_fkd 5.783, Loss_proto 0.040, Train_accy 76.84, Test_accy 58.14
2023-03-22 10:24:51,226 [ssre.py] => Task 3, Epoch 37/101 => Loss 7.377, Loss_clf 0.168, Loss_fkd 7.170, Loss_proto 0.039, Train_accy 77.16
2023-03-22 10:24:56,385 [ssre.py] => Task 3, Epoch 38/101 => Loss 6.590, Loss_clf 0.161, Loss_fkd 6.393, Loss_proto 0.037, Train_accy 77.14
2023-03-22 10:25:01,618 [ssre.py] => Task 3, Epoch 39/101 => Loss 5.154, Loss_clf 0.160, Loss_fkd 4.954, Loss_proto 0.040, Train_accy 76.58
2023-03-22 10:25:06,693 [ssre.py] => Task 3, Epoch 40/101 => Loss 6.762, Loss_clf 0.158, Loss_fkd 6.568, Loss_proto 0.037, Train_accy 77.44
2023-03-22 10:25:14,695 [ssre.py] => Task 3, Epoch 41/101 => Loss 7.798, Loss_clf 0.160, Loss_fkd 7.601, Loss_proto 0.037, Train_accy 77.86, Test_accy 57.79
2023-03-22 10:25:19,666 [ssre.py] => Task 3, Epoch 42/101 => Loss 7.107, Loss_clf 0.155, Loss_fkd 6.915, Loss_proto 0.037, Train_accy 77.92
2023-03-22 10:25:24,581 [ssre.py] => Task 3, Epoch 43/101 => Loss 7.166, Loss_clf 0.156, Loss_fkd 6.973, Loss_proto 0.037, Train_accy 77.68
2023-03-22 10:25:29,777 [ssre.py] => Task 3, Epoch 44/101 => Loss 4.951, Loss_clf 0.156, Loss_fkd 4.760, Loss_proto 0.036, Train_accy 77.18
2023-03-22 10:25:34,757 [ssre.py] => Task 3, Epoch 45/101 => Loss 5.335, Loss_clf 0.149, Loss_fkd 5.150, Loss_proto 0.035, Train_accy 78.46
2023-03-22 10:25:42,632 [ssre.py] => Task 3, Epoch 46/101 => Loss 3.657, Loss_clf 0.156, Loss_fkd 3.469, Loss_proto 0.032, Train_accy 78.22, Test_accy 58.06
2023-03-22 10:25:47,771 [ssre.py] => Task 3, Epoch 47/101 => Loss 1.643, Loss_clf 0.148, Loss_fkd 1.462, Loss_proto 0.033, Train_accy 78.74
2023-03-22 10:25:52,948 [ssre.py] => Task 3, Epoch 48/101 => Loss 1.337, Loss_clf 0.146, Loss_fkd 1.157, Loss_proto 0.034, Train_accy 78.66
2023-03-22 10:25:57,982 [ssre.py] => Task 3, Epoch 49/101 => Loss 1.171, Loss_clf 0.149, Loss_fkd 0.991, Loss_proto 0.031, Train_accy 79.08
2023-03-22 10:26:03,060 [ssre.py] => Task 3, Epoch 50/101 => Loss 1.071, Loss_clf 0.143, Loss_fkd 0.894, Loss_proto 0.034, Train_accy 79.50
2023-03-22 10:26:11,010 [ssre.py] => Task 3, Epoch 51/101 => Loss 0.996, Loss_clf 0.142, Loss_fkd 0.822, Loss_proto 0.032, Train_accy 78.88, Test_accy 58.21
2023-03-22 10:26:15,995 [ssre.py] => Task 3, Epoch 52/101 => Loss 0.932, Loss_clf 0.147, Loss_fkd 0.752, Loss_proto 0.033, Train_accy 78.98
2023-03-22 10:26:21,057 [ssre.py] => Task 3, Epoch 53/101 => Loss 0.873, Loss_clf 0.151, Loss_fkd 0.688, Loss_proto 0.033, Train_accy 79.26
2023-03-22 10:26:26,089 [ssre.py] => Task 3, Epoch 54/101 => Loss 0.858, Loss_clf 0.150, Loss_fkd 0.672, Loss_proto 0.036, Train_accy 78.48
2023-03-22 10:26:31,090 [ssre.py] => Task 3, Epoch 55/101 => Loss 0.828, Loss_clf 0.147, Loss_fkd 0.650, Loss_proto 0.030, Train_accy 78.76
2023-03-22 10:26:39,150 [ssre.py] => Task 3, Epoch 56/101 => Loss 0.813, Loss_clf 0.144, Loss_fkd 0.634, Loss_proto 0.034, Train_accy 78.14, Test_accy 58.20
2023-03-22 10:26:44,229 [ssre.py] => Task 3, Epoch 57/101 => Loss 0.825, Loss_clf 0.151, Loss_fkd 0.641, Loss_proto 0.033, Train_accy 79.18
2023-03-22 10:26:49,425 [ssre.py] => Task 3, Epoch 58/101 => Loss 0.785, Loss_clf 0.146, Loss_fkd 0.607, Loss_proto 0.032, Train_accy 78.74
2023-03-22 10:26:54,681 [ssre.py] => Task 3, Epoch 59/101 => Loss 1.034, Loss_clf 0.147, Loss_fkd 0.854, Loss_proto 0.033, Train_accy 79.02
2023-03-22 10:26:59,803 [ssre.py] => Task 3, Epoch 60/101 => Loss 0.859, Loss_clf 0.147, Loss_fkd 0.679, Loss_proto 0.034, Train_accy 79.00
2023-03-22 10:27:07,967 [ssre.py] => Task 3, Epoch 61/101 => Loss 0.773, Loss_clf 0.147, Loss_fkd 0.595, Loss_proto 0.031, Train_accy 78.54, Test_accy 58.16
2023-03-22 10:27:13,343 [ssre.py] => Task 3, Epoch 62/101 => Loss 0.788, Loss_clf 0.148, Loss_fkd 0.605, Loss_proto 0.036, Train_accy 78.50
2023-03-22 10:27:18,478 [ssre.py] => Task 3, Epoch 63/101 => Loss 0.783, Loss_clf 0.145, Loss_fkd 0.604, Loss_proto 0.033, Train_accy 79.80
2023-03-22 10:27:23,616 [ssre.py] => Task 3, Epoch 64/101 => Loss 0.928, Loss_clf 0.143, Loss_fkd 0.754, Loss_proto 0.031, Train_accy 79.10
2023-03-22 10:27:28,792 [ssre.py] => Task 3, Epoch 65/101 => Loss 0.836, Loss_clf 0.142, Loss_fkd 0.661, Loss_proto 0.033, Train_accy 79.04
2023-03-22 10:27:36,734 [ssre.py] => Task 3, Epoch 66/101 => Loss 0.806, Loss_clf 0.143, Loss_fkd 0.630, Loss_proto 0.033, Train_accy 79.44, Test_accy 58.21
2023-03-22 10:27:42,010 [ssre.py] => Task 3, Epoch 67/101 => Loss 0.750, Loss_clf 0.143, Loss_fkd 0.573, Loss_proto 0.034, Train_accy 79.28
2023-03-22 10:27:47,160 [ssre.py] => Task 3, Epoch 68/101 => Loss 0.745, Loss_clf 0.146, Loss_fkd 0.566, Loss_proto 0.033, Train_accy 78.68
2023-03-22 10:27:52,316 [ssre.py] => Task 3, Epoch 69/101 => Loss 0.932, Loss_clf 0.148, Loss_fkd 0.752, Loss_proto 0.033, Train_accy 78.36
2023-03-22 10:27:57,613 [ssre.py] => Task 3, Epoch 70/101 => Loss 0.813, Loss_clf 0.141, Loss_fkd 0.639, Loss_proto 0.033, Train_accy 78.86
2023-03-22 10:28:05,916 [ssre.py] => Task 3, Epoch 71/101 => Loss 0.731, Loss_clf 0.142, Loss_fkd 0.559, Loss_proto 0.031, Train_accy 79.18, Test_accy 58.28
2023-03-22 10:28:11,121 [ssre.py] => Task 3, Epoch 72/101 => Loss 0.733, Loss_clf 0.141, Loss_fkd 0.558, Loss_proto 0.033, Train_accy 79.52
2023-03-22 10:28:16,288 [ssre.py] => Task 3, Epoch 73/101 => Loss 0.838, Loss_clf 0.147, Loss_fkd 0.658, Loss_proto 0.033, Train_accy 79.04
2023-03-22 10:28:21,396 [ssre.py] => Task 3, Epoch 74/101 => Loss 0.726, Loss_clf 0.148, Loss_fkd 0.546, Loss_proto 0.033, Train_accy 79.18
2023-03-22 10:28:26,632 [ssre.py] => Task 3, Epoch 75/101 => Loss 0.822, Loss_clf 0.148, Loss_fkd 0.641, Loss_proto 0.033, Train_accy 78.84
2023-03-22 10:28:34,501 [ssre.py] => Task 3, Epoch 76/101 => Loss 0.731, Loss_clf 0.142, Loss_fkd 0.556, Loss_proto 0.034, Train_accy 79.06, Test_accy 58.28
2023-03-22 10:28:39,747 [ssre.py] => Task 3, Epoch 77/101 => Loss 0.908, Loss_clf 0.141, Loss_fkd 0.735, Loss_proto 0.033, Train_accy 79.08
2023-03-22 10:28:44,792 [ssre.py] => Task 3, Epoch 78/101 => Loss 0.914, Loss_clf 0.143, Loss_fkd 0.737, Loss_proto 0.033, Train_accy 78.66
2023-03-22 10:28:50,022 [ssre.py] => Task 3, Epoch 79/101 => Loss 0.760, Loss_clf 0.141, Loss_fkd 0.587, Loss_proto 0.032, Train_accy 78.86
2023-03-22 10:28:55,028 [ssre.py] => Task 3, Epoch 80/101 => Loss 0.732, Loss_clf 0.141, Loss_fkd 0.558, Loss_proto 0.033, Train_accy 79.58
2023-03-22 10:29:02,932 [ssre.py] => Task 3, Epoch 81/101 => Loss 0.711, Loss_clf 0.142, Loss_fkd 0.536, Loss_proto 0.034, Train_accy 79.58, Test_accy 58.08
2023-03-22 10:29:08,195 [ssre.py] => Task 3, Epoch 82/101 => Loss 0.734, Loss_clf 0.146, Loss_fkd 0.556, Loss_proto 0.032, Train_accy 78.66
2023-03-22 10:29:13,316 [ssre.py] => Task 3, Epoch 83/101 => Loss 0.713, Loss_clf 0.146, Loss_fkd 0.532, Loss_proto 0.034, Train_accy 78.60
2023-03-22 10:29:18,658 [ssre.py] => Task 3, Epoch 84/101 => Loss 1.049, Loss_clf 0.139, Loss_fkd 0.879, Loss_proto 0.031, Train_accy 79.76
2023-03-22 10:29:23,881 [ssre.py] => Task 3, Epoch 85/101 => Loss 0.986, Loss_clf 0.143, Loss_fkd 0.811, Loss_proto 0.032, Train_accy 79.70
2023-03-22 10:29:31,778 [ssre.py] => Task 3, Epoch 86/101 => Loss 0.915, Loss_clf 0.142, Loss_fkd 0.738, Loss_proto 0.035, Train_accy 78.86, Test_accy 58.21
2023-03-22 10:29:36,945 [ssre.py] => Task 3, Epoch 87/101 => Loss 0.785, Loss_clf 0.140, Loss_fkd 0.612, Loss_proto 0.033, Train_accy 79.08
2023-03-22 10:29:42,018 [ssre.py] => Task 3, Epoch 88/101 => Loss 0.724, Loss_clf 0.156, Loss_fkd 0.536, Loss_proto 0.031, Train_accy 79.02
2023-03-22 10:29:47,077 [ssre.py] => Task 3, Epoch 89/101 => Loss 0.703, Loss_clf 0.139, Loss_fkd 0.530, Loss_proto 0.034, Train_accy 79.46
2023-03-22 10:29:52,438 [ssre.py] => Task 3, Epoch 90/101 => Loss 0.685, Loss_clf 0.140, Loss_fkd 0.513, Loss_proto 0.032, Train_accy 79.44
2023-03-22 10:30:00,623 [ssre.py] => Task 3, Epoch 91/101 => Loss 0.538, Loss_clf 0.139, Loss_fkd 0.367, Loss_proto 0.032, Train_accy 79.34, Test_accy 58.22
2023-03-22 10:30:05,901 [ssre.py] => Task 3, Epoch 92/101 => Loss 0.351, Loss_clf 0.137, Loss_fkd 0.183, Loss_proto 0.031, Train_accy 79.44
2023-03-22 10:30:11,106 [ssre.py] => Task 3, Epoch 93/101 => Loss 0.335, Loss_clf 0.148, Loss_fkd 0.155, Loss_proto 0.032, Train_accy 78.90
2023-03-22 10:30:16,424 [ssre.py] => Task 3, Epoch 94/101 => Loss 0.319, Loss_clf 0.141, Loss_fkd 0.145, Loss_proto 0.032, Train_accy 79.04
2023-03-22 10:30:21,606 [ssre.py] => Task 3, Epoch 95/101 => Loss 0.307, Loss_clf 0.139, Loss_fkd 0.137, Loss_proto 0.031, Train_accy 79.84
2023-03-22 10:30:29,881 [ssre.py] => Task 3, Epoch 96/101 => Loss 0.310, Loss_clf 0.148, Loss_fkd 0.131, Loss_proto 0.031, Train_accy 79.26, Test_accy 58.22
2023-03-22 10:30:35,224 [ssre.py] => Task 3, Epoch 97/101 => Loss 0.300, Loss_clf 0.141, Loss_fkd 0.127, Loss_proto 0.031, Train_accy 79.18
2023-03-22 10:30:40,538 [ssre.py] => Task 3, Epoch 98/101 => Loss 0.292, Loss_clf 0.138, Loss_fkd 0.124, Loss_proto 0.031, Train_accy 79.64
2023-03-22 10:30:45,730 [ssre.py] => Task 3, Epoch 99/101 => Loss 0.297, Loss_clf 0.142, Loss_fkd 0.120, Loss_proto 0.034, Train_accy 79.52
2023-03-22 10:30:50,963 [ssre.py] => Task 3, Epoch 100/101 => Loss 0.290, Loss_clf 0.140, Loss_fkd 0.118, Loss_proto 0.032, Train_accy 78.92
2023-03-22 10:30:59,321 [ssre.py] => Task 3, Epoch 101/101 => Loss 0.285, Loss_clf 0.138, Loss_fkd 0.115, Loss_proto 0.032, Train_accy 79.74, Test_accy 58.29
2023-03-22 10:31:05,918 [ssre.py] => Model Compression!
2023-03-22 10:31:10,589 [trainer.py] => CNN: {'total': 58.29, '00-09': 63.1, '10-19': 54.0, '20-29': 62.5, '30-39': 55.2, '40-49': 61.5, '50-59': 54.7, '60-69': 54.6, '70-79': 60.7, 'old': 57.94, 'new': 60.7}
2023-03-22 10:31:10,590 [trainer.py] => NME: {'total': 57.62, '00-09': 66.1, '10-19': 56.3, '20-29': 72.1, '30-39': 59.0, '40-49': 67.3, '50-59': 43.2, '60-69': 49.1, '70-79': 47.9, 'old': 59.01, 'new': 47.9}
2023-03-22 10:31:10,590 [trainer.py] => CNN top1 curve: [79.4, 67.6, 62.7, 58.29]
2023-03-22 10:31:10,590 [trainer.py] => CNN top5 curve: [95.74, 90.0, 87.86, 85.64]
2023-03-22 10:31:10,590 [trainer.py] => NME top1 curve: [73.28, 65.95, 61.56, 57.62]
2023-03-22 10:31:10,590 [trainer.py] => NME top5 curve: [94.32, 90.88, 87.79, 85.16]

2023-03-22 10:31:10,590 [trainer.py] => All params: 12437264
2023-03-22 10:31:10,591 [trainer.py] => Trainable params: 1265488
2023-03-22 10:31:10,592 [ssre.py] => Model Expansion!
2023-03-22 10:31:10,593 [ssre.py] => Learning on 80-90
2023-03-22 10:31:10,594 [ssre.py] => All params: 12442394
2023-03-22 10:31:10,594 [ssre.py] => Trainable params: 1270618
2023-03-22 10:31:19,287 [ssre.py] => Task 4, Epoch 1/101 => Loss 16.353, Loss_clf 1.122, Loss_fkd 14.941, Loss_proto 0.291, Train_accy 3.78, Test_accy 52.39
2023-03-22 10:31:24,488 [ssre.py] => Task 4, Epoch 2/101 => Loss 6.821, Loss_clf 0.624, Loss_fkd 5.977, Loss_proto 0.220, Train_accy 25.54
2023-03-22 10:31:29,575 [ssre.py] => Task 4, Epoch 3/101 => Loss 6.019, Loss_clf 0.454, Loss_fkd 5.388, Loss_proto 0.176, Train_accy 42.44
2023-03-22 10:31:35,002 [ssre.py] => Task 4, Epoch 4/101 => Loss 6.820, Loss_clf 0.375, Loss_fkd 6.290, Loss_proto 0.155, Train_accy 50.50
2023-03-22 10:31:40,280 [ssre.py] => Task 4, Epoch 5/101 => Loss 5.699, Loss_clf 0.330, Loss_fkd 5.224, Loss_proto 0.145, Train_accy 56.72
2023-03-22 10:31:48,940 [ssre.py] => Task 4, Epoch 6/101 => Loss 7.552, Loss_clf 0.301, Loss_fkd 7.121, Loss_proto 0.130, Train_accy 60.24, Test_accy 55.78
2023-03-22 10:31:54,279 [ssre.py] => Task 4, Epoch 7/101 => Loss 5.954, Loss_clf 0.271, Loss_fkd 5.570, Loss_proto 0.113, Train_accy 63.18
2023-03-22 10:31:59,487 [ssre.py] => Task 4, Epoch 8/101 => Loss 6.570, Loss_clf 0.246, Loss_fkd 6.215, Loss_proto 0.108, Train_accy 65.20
2023-03-22 10:32:04,727 [ssre.py] => Task 4, Epoch 9/101 => Loss 5.618, Loss_clf 0.236, Loss_fkd 5.280, Loss_proto 0.102, Train_accy 67.62
2023-03-22 10:32:10,067 [ssre.py] => Task 4, Epoch 10/101 => Loss 7.096, Loss_clf 0.228, Loss_fkd 6.771, Loss_proto 0.096, Train_accy 69.16
2023-03-22 10:32:18,289 [ssre.py] => Task 4, Epoch 11/101 => Loss 7.198, Loss_clf 0.221, Loss_fkd 6.889, Loss_proto 0.087, Train_accy 70.00, Test_accy 55.69
2023-03-22 10:32:23,464 [ssre.py] => Task 4, Epoch 12/101 => Loss 7.206, Loss_clf 0.209, Loss_fkd 6.912, Loss_proto 0.084, Train_accy 71.08
2023-03-22 10:32:28,764 [ssre.py] => Task 4, Epoch 13/101 => Loss 6.665, Loss_clf 0.205, Loss_fkd 6.382, Loss_proto 0.079, Train_accy 72.74
2023-03-22 10:32:33,784 [ssre.py] => Task 4, Epoch 14/101 => Loss 6.812, Loss_clf 0.191, Loss_fkd 6.548, Loss_proto 0.073, Train_accy 73.62
2023-03-22 10:32:39,001 [ssre.py] => Task 4, Epoch 15/101 => Loss 8.562, Loss_clf 0.200, Loss_fkd 8.293, Loss_proto 0.069, Train_accy 74.50
2023-03-22 10:32:47,666 [ssre.py] => Task 4, Epoch 16/101 => Loss 7.228, Loss_clf 0.178, Loss_fkd 6.982, Loss_proto 0.068, Train_accy 75.46, Test_accy 55.20
2023-03-22 10:32:53,004 [ssre.py] => Task 4, Epoch 17/101 => Loss 9.029, Loss_clf 0.177, Loss_fkd 8.788, Loss_proto 0.063, Train_accy 75.54
2023-03-22 10:32:58,180 [ssre.py] => Task 4, Epoch 18/101 => Loss 5.408, Loss_clf 0.170, Loss_fkd 5.175, Loss_proto 0.064, Train_accy 75.82
2023-03-22 10:33:03,305 [ssre.py] => Task 4, Epoch 19/101 => Loss 8.017, Loss_clf 0.174, Loss_fkd 7.785, Loss_proto 0.058, Train_accy 75.92
2023-03-22 10:33:08,461 [ssre.py] => Task 4, Epoch 20/101 => Loss 6.127, Loss_clf 0.168, Loss_fkd 5.903, Loss_proto 0.057, Train_accy 77.10
2023-03-22 10:33:16,879 [ssre.py] => Task 4, Epoch 21/101 => Loss 6.201, Loss_clf 0.167, Loss_fkd 5.976, Loss_proto 0.058, Train_accy 77.04, Test_accy 54.86
2023-03-22 10:33:21,961 [ssre.py] => Task 4, Epoch 22/101 => Loss 6.675, Loss_clf 0.163, Loss_fkd 6.459, Loss_proto 0.053, Train_accy 77.80
2023-03-22 10:33:27,113 [ssre.py] => Task 4, Epoch 23/101 => Loss 5.034, Loss_clf 0.159, Loss_fkd 4.823, Loss_proto 0.051, Train_accy 77.22
2023-03-22 10:33:32,333 [ssre.py] => Task 4, Epoch 24/101 => Loss 5.224, Loss_clf 0.156, Loss_fkd 5.015, Loss_proto 0.052, Train_accy 78.32
2023-03-22 10:33:37,475 [ssre.py] => Task 4, Epoch 25/101 => Loss 5.404, Loss_clf 0.148, Loss_fkd 5.208, Loss_proto 0.048, Train_accy 79.04
2023-03-22 10:33:45,673 [ssre.py] => Task 4, Epoch 26/101 => Loss 5.273, Loss_clf 0.149, Loss_fkd 5.076, Loss_proto 0.047, Train_accy 79.20, Test_accy 54.70
2023-03-22 10:33:50,901 [ssre.py] => Task 4, Epoch 27/101 => Loss 7.018, Loss_clf 0.153, Loss_fkd 6.819, Loss_proto 0.046, Train_accy 78.68
2023-03-22 10:33:55,967 [ssre.py] => Task 4, Epoch 28/101 => Loss 7.856, Loss_clf 0.146, Loss_fkd 7.664, Loss_proto 0.046, Train_accy 79.68
2023-03-22 10:34:01,046 [ssre.py] => Task 4, Epoch 29/101 => Loss 6.195, Loss_clf 0.149, Loss_fkd 6.001, Loss_proto 0.045, Train_accy 80.06
2023-03-22 10:34:06,323 [ssre.py] => Task 4, Epoch 30/101 => Loss 6.350, Loss_clf 0.143, Loss_fkd 6.163, Loss_proto 0.044, Train_accy 80.26
2023-03-22 10:34:14,645 [ssre.py] => Task 4, Epoch 31/101 => Loss 6.603, Loss_clf 0.142, Loss_fkd 6.420, Loss_proto 0.042, Train_accy 80.22, Test_accy 54.80
2023-03-22 10:34:19,776 [ssre.py] => Task 4, Epoch 32/101 => Loss 5.084, Loss_clf 0.140, Loss_fkd 4.902, Loss_proto 0.042, Train_accy 80.22
2023-03-22 10:34:24,981 [ssre.py] => Task 4, Epoch 33/101 => Loss 5.813, Loss_clf 0.142, Loss_fkd 5.628, Loss_proto 0.042, Train_accy 80.34
2023-03-22 10:34:30,107 [ssre.py] => Task 4, Epoch 34/101 => Loss 6.443, Loss_clf 0.136, Loss_fkd 6.266, Loss_proto 0.040, Train_accy 81.30
2023-03-22 10:34:35,250 [ssre.py] => Task 4, Epoch 35/101 => Loss 6.750, Loss_clf 0.134, Loss_fkd 6.577, Loss_proto 0.038, Train_accy 80.62
2023-03-22 10:34:43,391 [ssre.py] => Task 4, Epoch 36/101 => Loss 8.111, Loss_clf 0.134, Loss_fkd 7.938, Loss_proto 0.038, Train_accy 81.64, Test_accy 54.94
2023-03-22 10:34:48,709 [ssre.py] => Task 4, Epoch 37/101 => Loss 6.555, Loss_clf 0.132, Loss_fkd 6.383, Loss_proto 0.039, Train_accy 80.80
2023-03-22 10:34:53,821 [ssre.py] => Task 4, Epoch 38/101 => Loss 6.380, Loss_clf 0.134, Loss_fkd 6.208, Loss_proto 0.037, Train_accy 81.12
2023-03-22 10:34:58,866 [ssre.py] => Task 4, Epoch 39/101 => Loss 5.299, Loss_clf 0.128, Loss_fkd 5.134, Loss_proto 0.037, Train_accy 81.32
2023-03-22 10:35:03,954 [ssre.py] => Task 4, Epoch 40/101 => Loss 6.575, Loss_clf 0.131, Loss_fkd 6.405, Loss_proto 0.040, Train_accy 81.36
2023-03-22 10:35:12,391 [ssre.py] => Task 4, Epoch 41/101 => Loss 5.243, Loss_clf 0.135, Loss_fkd 5.071, Loss_proto 0.037, Train_accy 81.00, Test_accy 54.46
2023-03-22 10:35:17,518 [ssre.py] => Task 4, Epoch 42/101 => Loss 5.343, Loss_clf 0.126, Loss_fkd 5.181, Loss_proto 0.037, Train_accy 82.54
2023-03-22 10:35:22,619 [ssre.py] => Task 4, Epoch 43/101 => Loss 7.314, Loss_clf 0.131, Loss_fkd 7.147, Loss_proto 0.036, Train_accy 82.04
2023-03-22 10:35:27,908 [ssre.py] => Task 4, Epoch 44/101 => Loss 6.237, Loss_clf 0.126, Loss_fkd 6.074, Loss_proto 0.037, Train_accy 81.86
2023-03-22 10:35:33,124 [ssre.py] => Task 4, Epoch 45/101 => Loss 5.110, Loss_clf 0.123, Loss_fkd 4.951, Loss_proto 0.036, Train_accy 82.58
2023-03-22 10:35:42,136 [ssre.py] => Task 4, Epoch 46/101 => Loss 3.564, Loss_clf 0.119, Loss_fkd 3.410, Loss_proto 0.035, Train_accy 82.20, Test_accy 54.71
2023-03-22 10:35:47,366 [ssre.py] => Task 4, Epoch 47/101 => Loss 1.550, Loss_clf 0.121, Loss_fkd 1.396, Loss_proto 0.033, Train_accy 82.82
2023-03-22 10:35:52,543 [ssre.py] => Task 4, Epoch 48/101 => Loss 1.252, Loss_clf 0.115, Loss_fkd 1.104, Loss_proto 0.032, Train_accy 83.26
2023-03-22 10:35:57,616 [ssre.py] => Task 4, Epoch 49/101 => Loss 1.100, Loss_clf 0.118, Loss_fkd 0.949, Loss_proto 0.033, Train_accy 83.22
2023-03-22 10:36:02,848 [ssre.py] => Task 4, Epoch 50/101 => Loss 1.013, Loss_clf 0.117, Loss_fkd 0.864, Loss_proto 0.032, Train_accy 83.54
2023-03-22 10:36:11,469 [ssre.py] => Task 4, Epoch 51/101 => Loss 0.934, Loss_clf 0.120, Loss_fkd 0.782, Loss_proto 0.033, Train_accy 83.48, Test_accy 54.60
2023-03-22 10:36:16,644 [ssre.py] => Task 4, Epoch 52/101 => Loss 0.877, Loss_clf 0.123, Loss_fkd 0.721, Loss_proto 0.033, Train_accy 82.74
2023-03-22 10:36:21,860 [ssre.py] => Task 4, Epoch 53/101 => Loss 0.849, Loss_clf 0.117, Loss_fkd 0.700, Loss_proto 0.032, Train_accy 83.18
2023-03-22 10:36:26,985 [ssre.py] => Task 4, Epoch 54/101 => Loss 0.808, Loss_clf 0.120, Loss_fkd 0.657, Loss_proto 0.032, Train_accy 82.48
2023-03-22 10:36:32,220 [ssre.py] => Task 4, Epoch 55/101 => Loss 0.777, Loss_clf 0.116, Loss_fkd 0.629, Loss_proto 0.032, Train_accy 83.24
2023-03-22 10:36:40,515 [ssre.py] => Task 4, Epoch 56/101 => Loss 0.761, Loss_clf 0.119, Loss_fkd 0.609, Loss_proto 0.033, Train_accy 82.92, Test_accy 54.68
2023-03-22 10:36:45,646 [ssre.py] => Task 4, Epoch 57/101 => Loss 0.753, Loss_clf 0.121, Loss_fkd 0.600, Loss_proto 0.032, Train_accy 83.06
2023-03-22 10:36:50,898 [ssre.py] => Task 4, Epoch 58/101 => Loss 0.740, Loss_clf 0.114, Loss_fkd 0.594, Loss_proto 0.032, Train_accy 83.34
2023-03-22 10:36:55,949 [ssre.py] => Task 4, Epoch 59/101 => Loss 0.757, Loss_clf 0.119, Loss_fkd 0.603, Loss_proto 0.034, Train_accy 83.12
2023-03-22 10:37:00,951 [ssre.py] => Task 4, Epoch 60/101 => Loss 0.810, Loss_clf 0.118, Loss_fkd 0.658, Loss_proto 0.033, Train_accy 83.08
2023-03-22 10:37:09,483 [ssre.py] => Task 4, Epoch 61/101 => Loss 0.734, Loss_clf 0.115, Loss_fkd 0.586, Loss_proto 0.033, Train_accy 83.58, Test_accy 54.70
2023-03-22 10:37:14,736 [ssre.py] => Task 4, Epoch 62/101 => Loss 0.854, Loss_clf 0.117, Loss_fkd 0.705, Loss_proto 0.032, Train_accy 83.40
2023-03-22 10:37:19,778 [ssre.py] => Task 4, Epoch 63/101 => Loss 0.869, Loss_clf 0.116, Loss_fkd 0.721, Loss_proto 0.032, Train_accy 82.90
2023-03-22 10:37:24,803 [ssre.py] => Task 4, Epoch 64/101 => Loss 0.800, Loss_clf 0.118, Loss_fkd 0.648, Loss_proto 0.033, Train_accy 82.90
2023-03-22 10:37:29,890 [ssre.py] => Task 4, Epoch 65/101 => Loss 0.720, Loss_clf 0.120, Loss_fkd 0.566, Loss_proto 0.034, Train_accy 83.08
2023-03-22 10:37:38,079 [ssre.py] => Task 4, Epoch 66/101 => Loss 0.710, Loss_clf 0.121, Loss_fkd 0.558, Loss_proto 0.031, Train_accy 82.82, Test_accy 54.52
2023-03-22 10:37:43,213 [ssre.py] => Task 4, Epoch 67/101 => Loss 0.711, Loss_clf 0.115, Loss_fkd 0.562, Loss_proto 0.033, Train_accy 82.98
2023-03-22 10:37:48,342 [ssre.py] => Task 4, Epoch 68/101 => Loss 0.728, Loss_clf 0.116, Loss_fkd 0.580, Loss_proto 0.031, Train_accy 83.24
2023-03-22 10:37:53,593 [ssre.py] => Task 4, Epoch 69/101 => Loss 0.742, Loss_clf 0.120, Loss_fkd 0.590, Loss_proto 0.032, Train_accy 83.06
2023-03-22 10:37:58,732 [ssre.py] => Task 4, Epoch 70/101 => Loss 0.702, Loss_clf 0.112, Loss_fkd 0.558, Loss_proto 0.031, Train_accy 84.04
2023-03-22 10:38:07,179 [ssre.py] => Task 4, Epoch 71/101 => Loss 0.832, Loss_clf 0.115, Loss_fkd 0.686, Loss_proto 0.031, Train_accy 83.20, Test_accy 54.66
2023-03-22 10:38:12,310 [ssre.py] => Task 4, Epoch 72/101 => Loss 0.748, Loss_clf 0.118, Loss_fkd 0.598, Loss_proto 0.032, Train_accy 83.10
2023-03-22 10:38:17,313 [ssre.py] => Task 4, Epoch 73/101 => Loss 0.741, Loss_clf 0.121, Loss_fkd 0.588, Loss_proto 0.032, Train_accy 82.98
2023-03-22 10:38:22,409 [ssre.py] => Task 4, Epoch 74/101 => Loss 0.950, Loss_clf 0.112, Loss_fkd 0.806, Loss_proto 0.033, Train_accy 83.70
2023-03-22 10:38:27,558 [ssre.py] => Task 4, Epoch 75/101 => Loss 0.945, Loss_clf 0.118, Loss_fkd 0.796, Loss_proto 0.032, Train_accy 83.66
2023-03-22 10:38:36,105 [ssre.py] => Task 4, Epoch 76/101 => Loss 0.755, Loss_clf 0.115, Loss_fkd 0.608, Loss_proto 0.032, Train_accy 83.84, Test_accy 54.68
2023-03-22 10:38:41,177 [ssre.py] => Task 4, Epoch 77/101 => Loss 0.877, Loss_clf 0.121, Loss_fkd 0.723, Loss_proto 0.032, Train_accy 83.34
2023-03-22 10:38:46,361 [ssre.py] => Task 4, Epoch 78/101 => Loss 0.781, Loss_clf 0.117, Loss_fkd 0.631, Loss_proto 0.033, Train_accy 82.92
2023-03-22 10:38:51,556 [ssre.py] => Task 4, Epoch 79/101 => Loss 0.761, Loss_clf 0.115, Loss_fkd 0.613, Loss_proto 0.033, Train_accy 82.66
2023-03-22 10:38:56,781 [ssre.py] => Task 4, Epoch 80/101 => Loss 0.830, Loss_clf 0.129, Loss_fkd 0.670, Loss_proto 0.031, Train_accy 82.94
2023-03-22 10:39:05,181 [ssre.py] => Task 4, Epoch 81/101 => Loss 0.802, Loss_clf 0.116, Loss_fkd 0.653, Loss_proto 0.032, Train_accy 83.58, Test_accy 54.72
2023-03-22 10:39:10,277 [ssre.py] => Task 4, Epoch 82/101 => Loss 0.701, Loss_clf 0.118, Loss_fkd 0.550, Loss_proto 0.033, Train_accy 82.38
2023-03-22 10:39:15,631 [ssre.py] => Task 4, Epoch 83/101 => Loss 0.689, Loss_clf 0.119, Loss_fkd 0.538, Loss_proto 0.032, Train_accy 83.40
2023-03-22 10:39:20,803 [ssre.py] => Task 4, Epoch 84/101 => Loss 0.722, Loss_clf 0.112, Loss_fkd 0.579, Loss_proto 0.031, Train_accy 83.40
2023-03-22 10:39:25,892 [ssre.py] => Task 4, Epoch 85/101 => Loss 0.668, Loss_clf 0.113, Loss_fkd 0.524, Loss_proto 0.031, Train_accy 83.28
2023-03-22 10:39:34,223 [ssre.py] => Task 4, Epoch 86/101 => Loss 0.743, Loss_clf 0.111, Loss_fkd 0.600, Loss_proto 0.032, Train_accy 84.06, Test_accy 54.66
2023-03-22 10:39:39,524 [ssre.py] => Task 4, Epoch 87/101 => Loss 0.677, Loss_clf 0.117, Loss_fkd 0.528, Loss_proto 0.031, Train_accy 83.48
2023-03-22 10:39:44,791 [ssre.py] => Task 4, Epoch 88/101 => Loss 0.811, Loss_clf 0.115, Loss_fkd 0.665, Loss_proto 0.032, Train_accy 83.62
2023-03-22 10:39:49,996 [ssre.py] => Task 4, Epoch 89/101 => Loss 0.833, Loss_clf 0.110, Loss_fkd 0.692, Loss_proto 0.031, Train_accy 83.42
2023-03-22 10:39:55,099 [ssre.py] => Task 4, Epoch 90/101 => Loss 0.674, Loss_clf 0.118, Loss_fkd 0.525, Loss_proto 0.031, Train_accy 83.16
2023-03-22 10:40:03,251 [ssre.py] => Task 4, Epoch 91/101 => Loss 0.545, Loss_clf 0.118, Loss_fkd 0.396, Loss_proto 0.031, Train_accy 83.34, Test_accy 54.54
2023-03-22 10:40:08,668 [ssre.py] => Task 4, Epoch 92/101 => Loss 0.323, Loss_clf 0.112, Loss_fkd 0.180, Loss_proto 0.031, Train_accy 84.02
2023-03-22 10:40:13,833 [ssre.py] => Task 4, Epoch 93/101 => Loss 0.305, Loss_clf 0.117, Loss_fkd 0.157, Loss_proto 0.031, Train_accy 83.38
2023-03-22 10:40:18,821 [ssre.py] => Task 4, Epoch 94/101 => Loss 0.294, Loss_clf 0.117, Loss_fkd 0.145, Loss_proto 0.033, Train_accy 83.06
2023-03-22 10:40:23,992 [ssre.py] => Task 4, Epoch 95/101 => Loss 0.279, Loss_clf 0.110, Loss_fkd 0.137, Loss_proto 0.032, Train_accy 83.72
2023-03-22 10:40:32,376 [ssre.py] => Task 4, Epoch 96/101 => Loss 0.273, Loss_clf 0.111, Loss_fkd 0.131, Loss_proto 0.030, Train_accy 83.72, Test_accy 54.66
2023-03-22 10:40:37,602 [ssre.py] => Task 4, Epoch 97/101 => Loss 0.272, Loss_clf 0.115, Loss_fkd 0.126, Loss_proto 0.031, Train_accy 83.62
2023-03-22 10:40:42,754 [ssre.py] => Task 4, Epoch 98/101 => Loss 0.266, Loss_clf 0.112, Loss_fkd 0.123, Loss_proto 0.031, Train_accy 83.70
2023-03-22 10:40:47,988 [ssre.py] => Task 4, Epoch 99/101 => Loss 0.262, Loss_clf 0.113, Loss_fkd 0.118, Loss_proto 0.031, Train_accy 83.78
2023-03-22 10:40:53,009 [ssre.py] => Task 4, Epoch 100/101 => Loss 0.261, Loss_clf 0.114, Loss_fkd 0.116, Loss_proto 0.032, Train_accy 84.06
2023-03-22 10:41:01,512 [ssre.py] => Task 4, Epoch 101/101 => Loss 0.258, Loss_clf 0.113, Loss_fkd 0.114, Loss_proto 0.030, Train_accy 83.48, Test_accy 54.70
2023-03-22 10:41:08,080 [ssre.py] => Model Compression!
2023-03-22 10:41:13,073 [trainer.py] => CNN: {'total': 54.7, '00-09': 58.6, '10-19': 49.7, '20-29': 58.9, '30-39': 51.8, '40-49': 59.6, '50-59': 46.5, '60-69': 49.5, '70-79': 51.7, '80-89': 66.0, 'old': 53.29, 'new': 66.0}
2023-03-22 10:41:13,073 [trainer.py] => NME: {'total': 54.33, '00-09': 63.2, '10-19': 54.0, '20-29': 69.8, '30-39': 58.4, '40-49': 65.8, '50-59': 40.8, '60-69': 46.2, '70-79': 46.7, '80-89': 44.1, 'old': 55.61, 'new': 44.1}
2023-03-22 10:41:13,073 [trainer.py] => CNN top1 curve: [79.4, 67.6, 62.7, 58.29, 54.7]
2023-03-22 10:41:13,073 [trainer.py] => CNN top5 curve: [95.74, 90.0, 87.86, 85.64, 83.36]
2023-03-22 10:41:13,073 [trainer.py] => NME top1 curve: [73.28, 65.95, 61.56, 57.62, 54.33]
2023-03-22 10:41:13,073 [trainer.py] => NME top5 curve: [94.32, 90.88, 87.79, 85.16, 83.24]

2023-03-22 10:41:13,074 [trainer.py] => All params: 12442394
2023-03-22 10:41:13,074 [trainer.py] => Trainable params: 1270618
2023-03-22 10:41:13,075 [ssre.py] => Model Expansion!
2023-03-22 10:41:13,076 [ssre.py] => Learning on 90-100
2023-03-22 10:41:13,077 [ssre.py] => All params: 12447524
2023-03-22 10:41:13,077 [ssre.py] => Trainable params: 1275748
2023-03-22 10:41:21,655 [ssre.py] => Task 5, Epoch 1/101 => Loss 15.728, Loss_clf 1.336, Loss_fkd 14.184, Loss_proto 0.208, Train_accy 3.66, Test_accy 48.76
2023-03-22 10:41:26,966 [ssre.py] => Task 5, Epoch 2/101 => Loss 7.102, Loss_clf 0.706, Loss_fkd 6.241, Loss_proto 0.155, Train_accy 23.80
2023-03-22 10:41:32,107 [ssre.py] => Task 5, Epoch 3/101 => Loss 6.110, Loss_clf 0.470, Loss_fkd 5.531, Loss_proto 0.109, Train_accy 44.86
2023-03-22 10:41:37,278 [ssre.py] => Task 5, Epoch 4/101 => Loss 7.727, Loss_clf 0.383, Loss_fkd 7.248, Loss_proto 0.096, Train_accy 53.18
2023-03-22 10:41:42,469 [ssre.py] => Task 5, Epoch 5/101 => Loss 6.987, Loss_clf 0.336, Loss_fkd 6.570, Loss_proto 0.082, Train_accy 58.06
2023-03-22 10:41:51,318 [ssre.py] => Task 5, Epoch 6/101 => Loss 6.821, Loss_clf 0.307, Loss_fkd 6.440, Loss_proto 0.074, Train_accy 62.22, Test_accy 53.48
2023-03-22 10:41:56,630 [ssre.py] => Task 5, Epoch 7/101 => Loss 7.546, Loss_clf 0.279, Loss_fkd 7.197, Loss_proto 0.070, Train_accy 63.88
2023-03-22 10:42:01,976 [ssre.py] => Task 5, Epoch 8/101 => Loss 7.580, Loss_clf 0.261, Loss_fkd 7.252, Loss_proto 0.067, Train_accy 66.46
2023-03-22 10:42:07,189 [ssre.py] => Task 5, Epoch 9/101 => Loss 6.060, Loss_clf 0.251, Loss_fkd 5.751, Loss_proto 0.059, Train_accy 67.82
2023-03-22 10:42:12,285 [ssre.py] => Task 5, Epoch 10/101 => Loss 7.526, Loss_clf 0.236, Loss_fkd 7.231, Loss_proto 0.060, Train_accy 68.74
2023-03-22 10:42:21,119 [ssre.py] => Task 5, Epoch 11/101 => Loss 7.191, Loss_clf 0.228, Loss_fkd 6.908, Loss_proto 0.055, Train_accy 70.34, Test_accy 53.56
2023-03-22 10:42:26,286 [ssre.py] => Task 5, Epoch 12/101 => Loss 5.705, Loss_clf 0.227, Loss_fkd 5.425, Loss_proto 0.052, Train_accy 71.58
2023-03-22 10:42:31,484 [ssre.py] => Task 5, Epoch 13/101 => Loss 7.580, Loss_clf 0.222, Loss_fkd 7.308, Loss_proto 0.050, Train_accy 72.24
2023-03-22 10:42:36,674 [ssre.py] => Task 5, Epoch 14/101 => Loss 5.013, Loss_clf 0.207, Loss_fkd 4.757, Loss_proto 0.049, Train_accy 72.60
2023-03-22 10:42:41,954 [ssre.py] => Task 5, Epoch 15/101 => Loss 5.069, Loss_clf 0.203, Loss_fkd 4.819, Loss_proto 0.047, Train_accy 73.06
2023-03-22 10:42:50,842 [ssre.py] => Task 5, Epoch 16/101 => Loss 6.533, Loss_clf 0.192, Loss_fkd 6.297, Loss_proto 0.045, Train_accy 73.86, Test_accy 53.67
2023-03-22 10:42:56,060 [ssre.py] => Task 5, Epoch 17/101 => Loss 8.048, Loss_clf 0.187, Loss_fkd 7.818, Loss_proto 0.043, Train_accy 74.58
2023-03-22 10:43:01,284 [ssre.py] => Task 5, Epoch 18/101 => Loss 6.925, Loss_clf 0.185, Loss_fkd 6.697, Loss_proto 0.043, Train_accy 75.16
2023-03-22 10:43:06,600 [ssre.py] => Task 5, Epoch 19/101 => Loss 6.744, Loss_clf 0.179, Loss_fkd 6.524, Loss_proto 0.041, Train_accy 75.02
2023-03-22 10:43:11,824 [ssre.py] => Task 5, Epoch 20/101 => Loss 5.234, Loss_clf 0.179, Loss_fkd 5.016, Loss_proto 0.040, Train_accy 75.78
2023-03-22 10:43:20,356 [ssre.py] => Task 5, Epoch 21/101 => Loss 6.533, Loss_clf 0.177, Loss_fkd 6.317, Loss_proto 0.040, Train_accy 76.22, Test_accy 53.24
2023-03-22 10:43:25,722 [ssre.py] => Task 5, Epoch 22/101 => Loss 6.938, Loss_clf 0.174, Loss_fkd 6.725, Loss_proto 0.039, Train_accy 76.06
2023-03-22 10:43:30,985 [ssre.py] => Task 5, Epoch 23/101 => Loss 7.668, Loss_clf 0.166, Loss_fkd 7.463, Loss_proto 0.040, Train_accy 76.88
2023-03-22 10:43:36,347 [ssre.py] => Task 5, Epoch 24/101 => Loss 6.118, Loss_clf 0.167, Loss_fkd 5.913, Loss_proto 0.038, Train_accy 76.94
2023-03-22 10:43:41,565 [ssre.py] => Task 5, Epoch 25/101 => Loss 5.198, Loss_clf 0.167, Loss_fkd 4.995, Loss_proto 0.037, Train_accy 77.70
2023-03-22 10:43:50,055 [ssre.py] => Task 5, Epoch 26/101 => Loss 6.269, Loss_clf 0.160, Loss_fkd 6.075, Loss_proto 0.035, Train_accy 78.16, Test_accy 53.19
2023-03-22 10:43:55,171 [ssre.py] => Task 5, Epoch 27/101 => Loss 5.512, Loss_clf 0.158, Loss_fkd 5.318, Loss_proto 0.036, Train_accy 77.40
2023-03-22 10:44:00,259 [ssre.py] => Task 5, Epoch 28/101 => Loss 5.020, Loss_clf 0.156, Loss_fkd 4.828, Loss_proto 0.035, Train_accy 78.92
2023-03-22 10:44:05,467 [ssre.py] => Task 5, Epoch 29/101 => Loss 5.090, Loss_clf 0.154, Loss_fkd 4.902, Loss_proto 0.034, Train_accy 78.66
2023-03-22 10:44:10,602 [ssre.py] => Task 5, Epoch 30/101 => Loss 5.893, Loss_clf 0.158, Loss_fkd 5.700, Loss_proto 0.034, Train_accy 78.72
2023-03-22 10:44:19,126 [ssre.py] => Task 5, Epoch 31/101 => Loss 6.060, Loss_clf 0.153, Loss_fkd 5.873, Loss_proto 0.034, Train_accy 78.74, Test_accy 53.08
2023-03-22 10:44:24,225 [ssre.py] => Task 5, Epoch 32/101 => Loss 7.994, Loss_clf 0.151, Loss_fkd 7.810, Loss_proto 0.032, Train_accy 79.36
2023-03-22 10:44:29,351 [ssre.py] => Task 5, Epoch 33/101 => Loss 6.804, Loss_clf 0.152, Loss_fkd 6.619, Loss_proto 0.033, Train_accy 78.76
2023-03-22 10:44:34,458 [ssre.py] => Task 5, Epoch 34/101 => Loss 6.739, Loss_clf 0.147, Loss_fkd 6.560, Loss_proto 0.032, Train_accy 79.80
2023-03-22 10:44:39,614 [ssre.py] => Task 5, Epoch 35/101 => Loss 5.616, Loss_clf 0.145, Loss_fkd 5.440, Loss_proto 0.031, Train_accy 79.84
2023-03-22 10:44:48,587 [ssre.py] => Task 5, Epoch 36/101 => Loss 5.603, Loss_clf 0.142, Loss_fkd 5.430, Loss_proto 0.031, Train_accy 79.96, Test_accy 53.51
2023-03-22 10:44:53,771 [ssre.py] => Task 5, Epoch 37/101 => Loss 5.107, Loss_clf 0.142, Loss_fkd 4.933, Loss_proto 0.032, Train_accy 80.00
2023-03-22 10:44:58,874 [ssre.py] => Task 5, Epoch 38/101 => Loss 5.233, Loss_clf 0.142, Loss_fkd 5.062, Loss_proto 0.029, Train_accy 80.38
2023-03-22 10:45:04,168 [ssre.py] => Task 5, Epoch 39/101 => Loss 6.020, Loss_clf 0.140, Loss_fkd 5.849, Loss_proto 0.031, Train_accy 80.12
2023-03-22 10:45:09,327 [ssre.py] => Task 5, Epoch 40/101 => Loss 7.289, Loss_clf 0.137, Loss_fkd 7.123, Loss_proto 0.030, Train_accy 81.10
2023-03-22 10:45:17,659 [ssre.py] => Task 5, Epoch 41/101 => Loss 5.900, Loss_clf 0.138, Loss_fkd 5.731, Loss_proto 0.030, Train_accy 80.36, Test_accy 53.41
2023-03-22 10:45:22,916 [ssre.py] => Task 5, Epoch 42/101 => Loss 4.858, Loss_clf 0.136, Loss_fkd 4.693, Loss_proto 0.029, Train_accy 80.28
2023-03-22 10:45:28,197 [ssre.py] => Task 5, Epoch 43/101 => Loss 5.050, Loss_clf 0.136, Loss_fkd 4.885, Loss_proto 0.029, Train_accy 80.52
2023-03-22 10:45:33,429 [ssre.py] => Task 5, Epoch 44/101 => Loss 5.274, Loss_clf 0.135, Loss_fkd 5.109, Loss_proto 0.029, Train_accy 80.96
2023-03-22 10:45:38,610 [ssre.py] => Task 5, Epoch 45/101 => Loss 4.958, Loss_clf 0.137, Loss_fkd 4.792, Loss_proto 0.029, Train_accy 80.50
2023-03-22 10:45:47,373 [ssre.py] => Task 5, Epoch 46/101 => Loss 3.557, Loss_clf 0.126, Loss_fkd 3.404, Loss_proto 0.027, Train_accy 81.74, Test_accy 53.14
2023-03-22 10:45:52,659 [ssre.py] => Task 5, Epoch 47/101 => Loss 1.566, Loss_clf 0.131, Loss_fkd 1.410, Loss_proto 0.026, Train_accy 81.92
2023-03-22 10:45:57,865 [ssre.py] => Task 5, Epoch 48/101 => Loss 1.262, Loss_clf 0.136, Loss_fkd 1.099, Loss_proto 0.027, Train_accy 81.92
2023-03-22 10:46:03,214 [ssre.py] => Task 5, Epoch 49/101 => Loss 1.099, Loss_clf 0.130, Loss_fkd 0.942, Loss_proto 0.027, Train_accy 81.54
2023-03-22 10:46:08,330 [ssre.py] => Task 5, Epoch 50/101 => Loss 1.003, Loss_clf 0.129, Loss_fkd 0.848, Loss_proto 0.026, Train_accy 81.54
2023-03-22 10:46:16,890 [ssre.py] => Task 5, Epoch 51/101 => Loss 0.909, Loss_clf 0.126, Loss_fkd 0.757, Loss_proto 0.026, Train_accy 81.56, Test_accy 53.14
2023-03-22 10:46:22,104 [ssre.py] => Task 5, Epoch 52/101 => Loss 0.870, Loss_clf 0.125, Loss_fkd 0.718, Loss_proto 0.027, Train_accy 81.62
2023-03-22 10:46:27,351 [ssre.py] => Task 5, Epoch 53/101 => Loss 0.845, Loss_clf 0.129, Loss_fkd 0.690, Loss_proto 0.026, Train_accy 81.30
2023-03-22 10:46:32,475 [ssre.py] => Task 5, Epoch 54/101 => Loss 0.799, Loss_clf 0.135, Loss_fkd 0.637, Loss_proto 0.027, Train_accy 81.18
2023-03-22 10:46:37,774 [ssre.py] => Task 5, Epoch 55/101 => Loss 0.799, Loss_clf 0.127, Loss_fkd 0.644, Loss_proto 0.027, Train_accy 81.64
2023-03-22 10:46:46,740 [ssre.py] => Task 5, Epoch 56/101 => Loss 0.752, Loss_clf 0.124, Loss_fkd 0.600, Loss_proto 0.028, Train_accy 82.32, Test_accy 53.18
2023-03-22 10:46:52,096 [ssre.py] => Task 5, Epoch 57/101 => Loss 0.768, Loss_clf 0.128, Loss_fkd 0.613, Loss_proto 0.027, Train_accy 81.84
2023-03-22 10:46:57,329 [ssre.py] => Task 5, Epoch 58/101 => Loss 0.751, Loss_clf 0.127, Loss_fkd 0.597, Loss_proto 0.027, Train_accy 82.16
2023-03-22 10:47:02,562 [ssre.py] => Task 5, Epoch 59/101 => Loss 0.765, Loss_clf 0.131, Loss_fkd 0.608, Loss_proto 0.027, Train_accy 81.08
2023-03-22 10:47:07,799 [ssre.py] => Task 5, Epoch 60/101 => Loss 0.755, Loss_clf 0.126, Loss_fkd 0.602, Loss_proto 0.027, Train_accy 82.72
2023-03-22 10:47:16,601 [ssre.py] => Task 5, Epoch 61/101 => Loss 0.765, Loss_clf 0.133, Loss_fkd 0.606, Loss_proto 0.026, Train_accy 81.28, Test_accy 53.22
2023-03-22 10:47:21,776 [ssre.py] => Task 5, Epoch 62/101 => Loss 0.751, Loss_clf 0.129, Loss_fkd 0.594, Loss_proto 0.028, Train_accy 81.74
2023-03-22 10:47:27,030 [ssre.py] => Task 5, Epoch 63/101 => Loss 0.715, Loss_clf 0.128, Loss_fkd 0.560, Loss_proto 0.027, Train_accy 81.78
2023-03-22 10:47:32,269 [ssre.py] => Task 5, Epoch 64/101 => Loss 0.722, Loss_clf 0.127, Loss_fkd 0.568, Loss_proto 0.027, Train_accy 82.08
2023-03-22 10:47:37,413 [ssre.py] => Task 5, Epoch 65/101 => Loss 0.757, Loss_clf 0.130, Loss_fkd 0.601, Loss_proto 0.026, Train_accy 81.32
2023-03-22 10:47:46,095 [ssre.py] => Task 5, Epoch 66/101 => Loss 0.702, Loss_clf 0.125, Loss_fkd 0.551, Loss_proto 0.027, Train_accy 81.36, Test_accy 53.22
2023-03-22 10:47:51,420 [ssre.py] => Task 5, Epoch 67/101 => Loss 0.903, Loss_clf 0.120, Loss_fkd 0.756, Loss_proto 0.027, Train_accy 82.16
2023-03-22 10:47:56,567 [ssre.py] => Task 5, Epoch 68/101 => Loss 0.940, Loss_clf 0.130, Loss_fkd 0.784, Loss_proto 0.026, Train_accy 81.56
2023-03-22 10:48:01,640 [ssre.py] => Task 5, Epoch 69/101 => Loss 0.876, Loss_clf 0.127, Loss_fkd 0.722, Loss_proto 0.027, Train_accy 81.76
2023-03-22 10:48:06,893 [ssre.py] => Task 5, Epoch 70/101 => Loss 0.867, Loss_clf 0.129, Loss_fkd 0.711, Loss_proto 0.027, Train_accy 81.86
2023-03-22 10:48:15,629 [ssre.py] => Task 5, Epoch 71/101 => Loss 0.714, Loss_clf 0.122, Loss_fkd 0.564, Loss_proto 0.027, Train_accy 82.82, Test_accy 53.25
2023-03-22 10:48:20,919 [ssre.py] => Task 5, Epoch 72/101 => Loss 0.698, Loss_clf 0.125, Loss_fkd 0.545, Loss_proto 0.028, Train_accy 81.68
2023-03-22 10:48:26,124 [ssre.py] => Task 5, Epoch 73/101 => Loss 0.700, Loss_clf 0.131, Loss_fkd 0.543, Loss_proto 0.027, Train_accy 81.62
2023-03-22 10:48:31,150 [ssre.py] => Task 5, Epoch 74/101 => Loss 1.102, Loss_clf 0.127, Loss_fkd 0.949, Loss_proto 0.026, Train_accy 82.20
2023-03-22 10:48:36,248 [ssre.py] => Task 5, Epoch 75/101 => Loss 1.029, Loss_clf 0.124, Loss_fkd 0.879, Loss_proto 0.027, Train_accy 82.66
2023-03-22 10:48:44,781 [ssre.py] => Task 5, Epoch 76/101 => Loss 1.110, Loss_clf 0.129, Loss_fkd 0.954, Loss_proto 0.027, Train_accy 81.96, Test_accy 53.14
2023-03-22 10:48:49,932 [ssre.py] => Task 5, Epoch 77/101 => Loss 0.990, Loss_clf 0.126, Loss_fkd 0.835, Loss_proto 0.028, Train_accy 81.92
2023-03-22 10:48:55,147 [ssre.py] => Task 5, Epoch 78/101 => Loss 0.815, Loss_clf 0.126, Loss_fkd 0.662, Loss_proto 0.027, Train_accy 81.94
2023-03-22 10:49:00,344 [ssre.py] => Task 5, Epoch 79/101 => Loss 0.682, Loss_clf 0.130, Loss_fkd 0.525, Loss_proto 0.027, Train_accy 81.42
2023-03-22 10:49:05,574 [ssre.py] => Task 5, Epoch 80/101 => Loss 0.686, Loss_clf 0.126, Loss_fkd 0.533, Loss_proto 0.027, Train_accy 81.90
2023-03-22 10:49:14,394 [ssre.py] => Task 5, Epoch 81/101 => Loss 0.785, Loss_clf 0.125, Loss_fkd 0.633, Loss_proto 0.026, Train_accy 81.74, Test_accy 53.21
2023-03-22 10:49:19,594 [ssre.py] => Task 5, Epoch 82/101 => Loss 0.741, Loss_clf 0.124, Loss_fkd 0.590, Loss_proto 0.027, Train_accy 82.30
2023-03-22 10:49:24,731 [ssre.py] => Task 5, Epoch 83/101 => Loss 0.923, Loss_clf 0.124, Loss_fkd 0.774, Loss_proto 0.026, Train_accy 81.72
2023-03-22 10:49:29,961 [ssre.py] => Task 5, Epoch 84/101 => Loss 0.700, Loss_clf 0.127, Loss_fkd 0.547, Loss_proto 0.026, Train_accy 82.32
2023-03-22 10:49:35,128 [ssre.py] => Task 5, Epoch 85/101 => Loss 0.705, Loss_clf 0.128, Loss_fkd 0.550, Loss_proto 0.027, Train_accy 82.36
2023-03-22 10:49:43,786 [ssre.py] => Task 5, Epoch 86/101 => Loss 0.683, Loss_clf 0.124, Loss_fkd 0.532, Loss_proto 0.026, Train_accy 81.82, Test_accy 53.27
2023-03-22 10:49:48,974 [ssre.py] => Task 5, Epoch 87/101 => Loss 0.694, Loss_clf 0.125, Loss_fkd 0.543, Loss_proto 0.026, Train_accy 82.08
2023-03-22 10:49:54,059 [ssre.py] => Task 5, Epoch 88/101 => Loss 1.042, Loss_clf 0.125, Loss_fkd 0.890, Loss_proto 0.027, Train_accy 82.34
2023-03-22 10:49:59,141 [ssre.py] => Task 5, Epoch 89/101 => Loss 0.990, Loss_clf 0.128, Loss_fkd 0.834, Loss_proto 0.028, Train_accy 82.24
2023-03-22 10:50:04,444 [ssre.py] => Task 5, Epoch 90/101 => Loss 0.662, Loss_clf 0.127, Loss_fkd 0.510, Loss_proto 0.026, Train_accy 82.08
2023-03-22 10:50:13,057 [ssre.py] => Task 5, Epoch 91/101 => Loss 0.480, Loss_clf 0.125, Loss_fkd 0.328, Loss_proto 0.027, Train_accy 82.30, Test_accy 53.21
2023-03-22 10:50:18,267 [ssre.py] => Task 5, Epoch 92/101 => Loss 0.329, Loss_clf 0.122, Loss_fkd 0.181, Loss_proto 0.027, Train_accy 82.96
2023-03-22 10:50:23,343 [ssre.py] => Task 5, Epoch 93/101 => Loss 0.309, Loss_clf 0.123, Loss_fkd 0.159, Loss_proto 0.027, Train_accy 82.26
2023-03-22 10:50:28,439 [ssre.py] => Task 5, Epoch 94/101 => Loss 0.307, Loss_clf 0.135, Loss_fkd 0.146, Loss_proto 0.026, Train_accy 81.76
2023-03-22 10:50:33,607 [ssre.py] => Task 5, Epoch 95/101 => Loss 0.287, Loss_clf 0.122, Loss_fkd 0.139, Loss_proto 0.026, Train_accy 82.32
2023-03-22 10:50:42,356 [ssre.py] => Task 5, Epoch 96/101 => Loss 0.280, Loss_clf 0.121, Loss_fkd 0.133, Loss_proto 0.026, Train_accy 82.82, Test_accy 53.27
2023-03-22 10:50:47,561 [ssre.py] => Task 5, Epoch 97/101 => Loss 0.279, Loss_clf 0.124, Loss_fkd 0.129, Loss_proto 0.027, Train_accy 82.44
2023-03-22 10:50:52,648 [ssre.py] => Task 5, Epoch 98/101 => Loss 0.274, Loss_clf 0.122, Loss_fkd 0.125, Loss_proto 0.027, Train_accy 82.14
2023-03-22 10:50:57,833 [ssre.py] => Task 5, Epoch 99/101 => Loss 0.270, Loss_clf 0.122, Loss_fkd 0.123, Loss_proto 0.025, Train_accy 82.36
2023-03-22 10:51:03,023 [ssre.py] => Task 5, Epoch 100/101 => Loss 0.265, Loss_clf 0.120, Loss_fkd 0.119, Loss_proto 0.026, Train_accy 83.20
2023-03-22 10:51:11,605 [ssre.py] => Task 5, Epoch 101/101 => Loss 0.270, Loss_clf 0.127, Loss_fkd 0.116, Loss_proto 0.026, Train_accy 81.96, Test_accy 53.22
2023-03-22 10:51:18,191 [ssre.py] => Model Compression!
2023-03-22 10:51:23,344 [trainer.py] => CNN: {'total': 53.22, '00-09': 56.2, '10-19': 47.2, '20-29': 59.6, '30-39': 52.1, '40-49': 57.8, '50-59': 46.3, '60-69': 51.7, '70-79': 48.1, '80-89': 44.9, '90-99': 68.3, 'old': 51.54, 'new': 68.3}
2023-03-22 10:51:23,344 [trainer.py] => NME: {'total': 51.72, '00-09': 61.2, '10-19': 52.9, '20-29': 69.1, '30-39': 57.1, '40-49': 64.4, '50-59': 37.3, '60-69': 45.4, '70-79': 44.4, '80-89': 43.2, '90-99': 42.2, 'old': 52.78, 'new': 42.2}
2023-03-22 10:51:23,344 [trainer.py] => CNN top1 curve: [79.4, 67.6, 62.7, 58.29, 54.7, 53.22]
2023-03-22 10:51:23,344 [trainer.py] => CNN top5 curve: [95.74, 90.0, 87.86, 85.64, 83.36, 81.94]
2023-03-22 10:51:23,344 [trainer.py] => NME top1 curve: [73.28, 65.95, 61.56, 57.62, 54.33, 51.72]
2023-03-22 10:51:23,344 [trainer.py] => NME top5 curve: [94.32, 90.88, 87.79, 85.16, 83.24, 81.08]

