2022-11-28 17:51:58,203 [trainer.py] => config: ./exps/bic.json
2022-11-28 17:51:58,205 [trainer.py] => prefix: reproduce
2022-11-28 17:51:58,205 [trainer.py] => dataset: cifar100
2022-11-28 17:51:58,205 [trainer.py] => memory_size: 2000
2022-11-28 17:51:58,205 [trainer.py] => memory_per_class: 20
2022-11-28 17:51:58,205 [trainer.py] => fixed_memory: False
2022-11-28 17:51:58,206 [trainer.py] => shuffle: True
2022-11-28 17:51:58,206 [trainer.py] => init_cls: 10
2022-11-28 17:51:58,206 [trainer.py] => increment: 10
2022-11-28 17:51:58,206 [trainer.py] => model_name: bic
2022-11-28 17:51:58,206 [trainer.py] => convnet_type: resnet32
2022-11-28 17:51:58,206 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1), device(type='cuda', index=2), device(type='cuda', index=3)]
2022-11-28 17:51:58,212 [trainer.py] => seed: 1993
Files already downloaded and verified
Files already downloaded and verified
2022-11-28 17:52:00,900 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2022-11-28 17:52:01,239 [trainer.py] => All params: 464154
2022-11-28 17:52:01,239 [trainer.py] => Trainable params: 464154
2022-11-28 17:52:01,240 [bic.py] => Learning on 0-10
2022-11-28 17:52:01,254 [bic.py] => Parameters of bias layer:
2022-11-28 17:52:01,255 [bic.py] => 0 => 1.000, 0.000
2022-11-28 17:52:28,493 [bic.py] => training => Task 0, Epoch 1/170 => Loss 2.810, Train_accy 18.620, Test_accy 17.000
2022-11-28 17:52:34,436 [bic.py] => training => Task 0, Epoch 2/170 => Loss 2.009, Train_accy 28.020, Test_accy 29.500
2022-11-28 17:52:40,210 [bic.py] => training => Task 0, Epoch 3/170 => Loss 1.822, Train_accy 31.200, Test_accy 32.300
2022-11-28 17:52:46,376 [bic.py] => training => Task 0, Epoch 4/170 => Loss 1.678, Train_accy 36.700, Test_accy 34.000
2022-11-28 17:52:52,164 [bic.py] => training => Task 0, Epoch 5/170 => Loss 1.582, Train_accy 39.840, Test_accy 40.400
2022-11-28 17:52:58,042 [bic.py] => training => Task 0, Epoch 6/170 => Loss 1.529, Train_accy 39.260, Test_accy 42.300
2022-11-28 17:53:04,008 [bic.py] => training => Task 0, Epoch 7/170 => Loss 1.438, Train_accy 51.100, Test_accy 50.700
2022-11-28 17:53:10,078 [bic.py] => training => Task 0, Epoch 8/170 => Loss 1.335, Train_accy 46.740, Test_accy 47.300
2022-11-28 17:53:15,877 [bic.py] => training => Task 0, Epoch 9/170 => Loss 1.303, Train_accy 53.480, Test_accy 51.300
2022-11-28 17:53:21,924 [bic.py] => training => Task 0, Epoch 10/170 => Loss 1.226, Train_accy 54.260, Test_accy 53.500
2022-11-28 17:53:27,823 [bic.py] => training => Task 0, Epoch 11/170 => Loss 1.187, Train_accy 49.540, Test_accy 46.100
2022-11-28 17:53:33,923 [bic.py] => training => Task 0, Epoch 12/170 => Loss 1.153, Train_accy 62.680, Test_accy 61.300
2022-11-28 17:53:39,726 [bic.py] => training => Task 0, Epoch 13/170 => Loss 1.099, Train_accy 61.560, Test_accy 60.800
2022-11-28 17:53:45,543 [bic.py] => training => Task 0, Epoch 14/170 => Loss 1.020, Train_accy 64.160, Test_accy 60.900
2022-11-28 17:53:51,529 [bic.py] => training => Task 0, Epoch 15/170 => Loss 0.950, Train_accy 69.640, Test_accy 67.300
2022-11-28 17:53:57,790 [bic.py] => training => Task 0, Epoch 16/170 => Loss 0.918, Train_accy 68.540, Test_accy 68.300
2022-11-28 17:54:03,729 [bic.py] => training => Task 0, Epoch 17/170 => Loss 0.902, Train_accy 59.280, Test_accy 61.900
2022-11-28 17:54:09,963 [bic.py] => training => Task 0, Epoch 18/170 => Loss 0.895, Train_accy 70.320, Test_accy 67.300
2022-11-28 17:54:15,955 [bic.py] => training => Task 0, Epoch 19/170 => Loss 0.810, Train_accy 71.560, Test_accy 71.400
2022-11-28 17:54:21,838 [bic.py] => training => Task 0, Epoch 20/170 => Loss 0.834, Train_accy 70.400, Test_accy 68.200
2022-11-28 17:54:27,841 [bic.py] => training => Task 0, Epoch 21/170 => Loss 0.789, Train_accy 67.740, Test_accy 67.200
2022-11-28 17:54:34,021 [bic.py] => training => Task 0, Epoch 22/170 => Loss 0.741, Train_accy 67.880, Test_accy 64.800
2022-11-28 17:54:40,402 [bic.py] => training => Task 0, Epoch 23/170 => Loss 0.689, Train_accy 72.560, Test_accy 69.100
2022-11-28 17:54:46,385 [bic.py] => training => Task 0, Epoch 24/170 => Loss 0.670, Train_accy 76.640, Test_accy 71.900
2022-11-28 17:54:52,056 [bic.py] => training => Task 0, Epoch 25/170 => Loss 0.643, Train_accy 76.140, Test_accy 75.300
2022-11-28 17:54:58,208 [bic.py] => training => Task 0, Epoch 26/170 => Loss 0.648, Train_accy 78.860, Test_accy 75.500
2022-11-28 17:55:03,920 [bic.py] => training => Task 0, Epoch 27/170 => Loss 0.616, Train_accy 75.960, Test_accy 72.500
2022-11-28 17:55:09,761 [bic.py] => training => Task 0, Epoch 28/170 => Loss 0.595, Train_accy 67.220, Test_accy 65.200
2022-11-28 17:55:16,033 [bic.py] => training => Task 0, Epoch 29/170 => Loss 0.576, Train_accy 77.080, Test_accy 72.700
2022-11-28 17:55:21,777 [bic.py] => training => Task 0, Epoch 30/170 => Loss 0.545, Train_accy 79.980, Test_accy 75.400
2022-11-28 17:55:27,927 [bic.py] => training => Task 0, Epoch 31/170 => Loss 0.532, Train_accy 81.720, Test_accy 79.000
2022-11-28 17:55:33,846 [bic.py] => training => Task 0, Epoch 32/170 => Loss 0.513, Train_accy 81.620, Test_accy 78.400
2022-11-28 17:55:39,759 [bic.py] => training => Task 0, Epoch 33/170 => Loss 0.520, Train_accy 79.320, Test_accy 74.400
2022-11-28 17:55:45,950 [bic.py] => training => Task 0, Epoch 34/170 => Loss 0.524, Train_accy 84.660, Test_accy 79.700
2022-11-28 17:55:51,933 [bic.py] => training => Task 0, Epoch 35/170 => Loss 0.489, Train_accy 82.920, Test_accy 78.900
2022-11-28 17:55:58,038 [bic.py] => training => Task 0, Epoch 36/170 => Loss 0.513, Train_accy 77.440, Test_accy 74.800
2022-11-28 17:56:04,113 [bic.py] => training => Task 0, Epoch 37/170 => Loss 0.466, Train_accy 79.480, Test_accy 75.200
2022-11-28 17:56:09,848 [bic.py] => training => Task 0, Epoch 38/170 => Loss 0.494, Train_accy 81.460, Test_accy 77.100
2022-11-28 17:56:15,990 [bic.py] => training => Task 0, Epoch 39/170 => Loss 0.435, Train_accy 85.760, Test_accy 81.400
2022-11-28 17:56:22,074 [bic.py] => training => Task 0, Epoch 40/170 => Loss 0.435, Train_accy 86.960, Test_accy 81.200
2022-11-28 17:56:27,874 [bic.py] => training => Task 0, Epoch 41/170 => Loss 0.479, Train_accy 83.140, Test_accy 77.500
2022-11-28 17:56:33,975 [bic.py] => training => Task 0, Epoch 42/170 => Loss 0.419, Train_accy 88.260, Test_accy 83.000
2022-11-28 17:56:39,714 [bic.py] => training => Task 0, Epoch 43/170 => Loss 0.400, Train_accy 86.620, Test_accy 82.200
2022-11-28 17:56:45,742 [bic.py] => training => Task 0, Epoch 44/170 => Loss 0.363, Train_accy 90.060, Test_accy 83.000
2022-11-28 17:56:52,012 [bic.py] => training => Task 0, Epoch 45/170 => Loss 0.353, Train_accy 88.300, Test_accy 81.500
2022-11-28 17:56:57,885 [bic.py] => training => Task 0, Epoch 46/170 => Loss 0.349, Train_accy 85.980, Test_accy 78.600
2022-11-28 17:57:04,020 [bic.py] => training => Task 0, Epoch 47/170 => Loss 0.361, Train_accy 82.580, Test_accy 77.400
2022-11-28 17:57:09,924 [bic.py] => training => Task 0, Epoch 48/170 => Loss 0.399, Train_accy 84.260, Test_accy 76.700
2022-11-28 17:57:16,239 [bic.py] => training => Task 0, Epoch 49/170 => Loss 0.415, Train_accy 85.540, Test_accy 78.800
2022-11-28 17:57:22,425 [bic.py] => training => Task 0, Epoch 50/170 => Loss 0.363, Train_accy 86.520, Test_accy 80.000
2022-11-28 17:57:28,451 [bic.py] => training => Task 0, Epoch 51/170 => Loss 0.368, Train_accy 89.600, Test_accy 81.900
2022-11-28 17:57:34,427 [bic.py] => training => Task 0, Epoch 52/170 => Loss 0.286, Train_accy 89.220, Test_accy 83.800
2022-11-28 17:57:40,356 [bic.py] => training => Task 0, Epoch 53/170 => Loss 0.333, Train_accy 90.140, Test_accy 83.200
2022-11-28 17:57:46,452 [bic.py] => training => Task 0, Epoch 54/170 => Loss 0.360, Train_accy 89.660, Test_accy 83.200
2022-11-28 17:57:52,295 [bic.py] => training => Task 0, Epoch 55/170 => Loss 0.324, Train_accy 90.020, Test_accy 81.300
2022-11-28 17:57:58,200 [bic.py] => training => Task 0, Epoch 56/170 => Loss 0.340, Train_accy 86.660, Test_accy 81.300
2022-11-28 17:58:04,286 [bic.py] => training => Task 0, Epoch 57/170 => Loss 0.378, Train_accy 82.460, Test_accy 77.100
2022-11-28 17:58:10,319 [bic.py] => training => Task 0, Epoch 58/170 => Loss 0.328, Train_accy 91.300, Test_accy 84.600
2022-11-28 17:58:16,269 [bic.py] => training => Task 0, Epoch 59/170 => Loss 0.271, Train_accy 92.840, Test_accy 87.100
2022-11-28 17:58:22,277 [bic.py] => training => Task 0, Epoch 60/170 => Loss 0.244, Train_accy 92.300, Test_accy 85.800
2022-11-28 17:58:28,296 [bic.py] => training => Task 0, Epoch 61/170 => Loss 0.190, Train_accy 96.060, Test_accy 88.300
2022-11-28 17:58:34,266 [bic.py] => training => Task 0, Epoch 62/170 => Loss 0.175, Train_accy 96.840, Test_accy 88.300
2022-11-28 17:58:40,036 [bic.py] => training => Task 0, Epoch 63/170 => Loss 0.149, Train_accy 97.380, Test_accy 88.100
2022-11-28 17:58:46,156 [bic.py] => training => Task 0, Epoch 64/170 => Loss 0.152, Train_accy 97.080, Test_accy 88.500
2022-11-28 17:58:52,387 [bic.py] => training => Task 0, Epoch 65/170 => Loss 0.143, Train_accy 97.200, Test_accy 88.200
2022-11-28 17:58:58,575 [bic.py] => training => Task 0, Epoch 66/170 => Loss 0.138, Train_accy 97.680, Test_accy 88.400
2022-11-28 17:59:04,315 [bic.py] => training => Task 0, Epoch 67/170 => Loss 0.114, Train_accy 97.680, Test_accy 87.600
2022-11-28 17:59:10,462 [bic.py] => training => Task 0, Epoch 68/170 => Loss 0.119, Train_accy 97.720, Test_accy 88.200
2022-11-28 17:59:16,350 [bic.py] => training => Task 0, Epoch 69/170 => Loss 0.107, Train_accy 97.560, Test_accy 88.900
2022-11-28 17:59:22,387 [bic.py] => training => Task 0, Epoch 70/170 => Loss 0.128, Train_accy 97.740, Test_accy 88.100
2022-11-28 17:59:28,224 [bic.py] => training => Task 0, Epoch 71/170 => Loss 0.114, Train_accy 97.800, Test_accy 88.400
2022-11-28 17:59:34,179 [bic.py] => training => Task 0, Epoch 72/170 => Loss 0.124, Train_accy 97.980, Test_accy 89.100
2022-11-28 17:59:40,464 [bic.py] => training => Task 0, Epoch 73/170 => Loss 0.102, Train_accy 98.240, Test_accy 88.400
2022-11-28 17:59:46,662 [bic.py] => training => Task 0, Epoch 74/170 => Loss 0.107, Train_accy 98.340, Test_accy 88.700
2022-11-28 17:59:52,649 [bic.py] => training => Task 0, Epoch 75/170 => Loss 0.103, Train_accy 98.140, Test_accy 89.300
2022-11-28 17:59:58,637 [bic.py] => training => Task 0, Epoch 76/170 => Loss 0.108, Train_accy 98.520, Test_accy 89.000
2022-11-28 18:00:04,581 [bic.py] => training => Task 0, Epoch 77/170 => Loss 0.098, Train_accy 97.840, Test_accy 88.700
2022-11-28 18:00:10,653 [bic.py] => training => Task 0, Epoch 78/170 => Loss 0.113, Train_accy 98.160, Test_accy 89.200
2022-11-28 18:00:16,904 [bic.py] => training => Task 0, Epoch 79/170 => Loss 0.086, Train_accy 98.520, Test_accy 88.400
2022-11-28 18:00:22,584 [bic.py] => training => Task 0, Epoch 80/170 => Loss 0.111, Train_accy 98.880, Test_accy 88.400
2022-11-28 18:00:28,439 [bic.py] => training => Task 0, Epoch 81/170 => Loss 0.098, Train_accy 98.460, Test_accy 89.100
2022-11-28 18:00:34,338 [bic.py] => training => Task 0, Epoch 82/170 => Loss 0.083, Train_accy 98.540, Test_accy 89.200
2022-11-28 18:00:40,365 [bic.py] => training => Task 0, Epoch 83/170 => Loss 0.085, Train_accy 98.420, Test_accy 88.800
2022-11-28 18:00:46,494 [bic.py] => training => Task 0, Epoch 84/170 => Loss 0.079, Train_accy 98.900, Test_accy 89.000
2022-11-28 18:00:52,455 [bic.py] => training => Task 0, Epoch 85/170 => Loss 0.094, Train_accy 98.900, Test_accy 88.900
2022-11-28 18:00:58,462 [bic.py] => training => Task 0, Epoch 86/170 => Loss 0.082, Train_accy 98.780, Test_accy 88.800
2022-11-28 18:01:04,426 [bic.py] => training => Task 0, Epoch 87/170 => Loss 0.103, Train_accy 98.640, Test_accy 89.100
2022-11-28 18:01:10,445 [bic.py] => training => Task 0, Epoch 88/170 => Loss 0.109, Train_accy 98.660, Test_accy 89.000
2022-11-28 18:01:16,635 [bic.py] => training => Task 0, Epoch 89/170 => Loss 0.084, Train_accy 98.620, Test_accy 88.500
2022-11-28 18:01:22,583 [bic.py] => training => Task 0, Epoch 90/170 => Loss 0.086, Train_accy 98.840, Test_accy 88.500
2022-11-28 18:01:28,196 [bic.py] => training => Task 0, Epoch 91/170 => Loss 0.079, Train_accy 98.740, Test_accy 88.400
2022-11-28 18:01:34,320 [bic.py] => training => Task 0, Epoch 92/170 => Loss 0.088, Train_accy 98.700, Test_accy 88.900
2022-11-28 18:01:40,500 [bic.py] => training => Task 0, Epoch 93/170 => Loss 0.090, Train_accy 98.940, Test_accy 88.600
2022-11-28 18:01:46,418 [bic.py] => training => Task 0, Epoch 94/170 => Loss 0.089, Train_accy 98.920, Test_accy 88.800
2022-11-28 18:01:52,354 [bic.py] => training => Task 0, Epoch 95/170 => Loss 0.101, Train_accy 99.180, Test_accy 88.800
2022-11-28 18:01:58,313 [bic.py] => training => Task 0, Epoch 96/170 => Loss 0.072, Train_accy 98.980, Test_accy 88.900
2022-11-28 18:02:04,364 [bic.py] => training => Task 0, Epoch 97/170 => Loss 0.067, Train_accy 99.220, Test_accy 89.100
2022-11-28 18:02:10,579 [bic.py] => training => Task 0, Epoch 98/170 => Loss 0.081, Train_accy 99.080, Test_accy 89.100
2022-11-28 18:02:16,702 [bic.py] => training => Task 0, Epoch 99/170 => Loss 0.071, Train_accy 99.080, Test_accy 89.000
2022-11-28 18:02:22,722 [bic.py] => training => Task 0, Epoch 100/170 => Loss 0.085, Train_accy 99.420, Test_accy 89.400
2022-11-28 18:02:28,929 [bic.py] => training => Task 0, Epoch 101/170 => Loss 0.074, Train_accy 99.100, Test_accy 89.300
2022-11-28 18:02:35,032 [bic.py] => training => Task 0, Epoch 102/170 => Loss 0.085, Train_accy 99.020, Test_accy 89.600
2022-11-28 18:02:41,044 [bic.py] => training => Task 0, Epoch 103/170 => Loss 0.057, Train_accy 99.020, Test_accy 89.300
2022-11-28 18:02:47,148 [bic.py] => training => Task 0, Epoch 104/170 => Loss 0.056, Train_accy 99.320, Test_accy 89.800
2022-11-28 18:02:53,087 [bic.py] => training => Task 0, Epoch 105/170 => Loss 0.064, Train_accy 99.240, Test_accy 89.600
2022-11-28 18:02:59,007 [bic.py] => training => Task 0, Epoch 106/170 => Loss 0.075, Train_accy 99.240, Test_accy 90.100
2022-11-28 18:03:04,826 [bic.py] => training => Task 0, Epoch 107/170 => Loss 0.054, Train_accy 99.020, Test_accy 89.000
2022-11-28 18:03:10,758 [bic.py] => training => Task 0, Epoch 108/170 => Loss 0.054, Train_accy 99.460, Test_accy 89.900
2022-11-28 18:03:16,453 [bic.py] => training => Task 0, Epoch 109/170 => Loss 0.067, Train_accy 99.360, Test_accy 89.700
2022-11-28 18:03:22,340 [bic.py] => training => Task 0, Epoch 110/170 => Loss 0.068, Train_accy 99.260, Test_accy 89.500
2022-11-28 18:03:28,518 [bic.py] => training => Task 0, Epoch 111/170 => Loss 0.058, Train_accy 99.280, Test_accy 89.200
2022-11-28 18:03:34,494 [bic.py] => training => Task 0, Epoch 112/170 => Loss 0.065, Train_accy 99.260, Test_accy 89.700
2022-11-28 18:03:40,695 [bic.py] => training => Task 0, Epoch 113/170 => Loss 0.058, Train_accy 99.260, Test_accy 88.900
2022-11-28 18:03:46,640 [bic.py] => training => Task 0, Epoch 114/170 => Loss 0.085, Train_accy 99.160, Test_accy 89.200
2022-11-28 18:03:52,580 [bic.py] => training => Task 0, Epoch 115/170 => Loss 0.061, Train_accy 99.240, Test_accy 89.000
2022-11-28 18:03:58,304 [bic.py] => training => Task 0, Epoch 116/170 => Loss 0.056, Train_accy 99.400, Test_accy 89.400
2022-11-28 18:04:03,961 [bic.py] => training => Task 0, Epoch 117/170 => Loss 0.085, Train_accy 99.400, Test_accy 89.600
2022-11-28 18:04:09,935 [bic.py] => training => Task 0, Epoch 118/170 => Loss 0.066, Train_accy 99.440, Test_accy 89.600
2022-11-28 18:04:15,874 [bic.py] => training => Task 0, Epoch 119/170 => Loss 0.052, Train_accy 99.400, Test_accy 89.800
2022-11-28 18:04:21,775 [bic.py] => training => Task 0, Epoch 120/170 => Loss 0.046, Train_accy 99.320, Test_accy 89.200
2022-11-28 18:04:28,025 [bic.py] => training => Task 0, Epoch 121/170 => Loss 0.058, Train_accy 99.580, Test_accy 90.000
2022-11-28 18:04:34,149 [bic.py] => training => Task 0, Epoch 122/170 => Loss 0.072, Train_accy 99.160, Test_accy 89.500
2022-11-28 18:04:40,228 [bic.py] => training => Task 0, Epoch 123/170 => Loss 0.058, Train_accy 99.380, Test_accy 89.600
2022-11-28 18:04:46,051 [bic.py] => training => Task 0, Epoch 124/170 => Loss 0.044, Train_accy 99.180, Test_accy 89.600
2022-11-28 18:04:52,057 [bic.py] => training => Task 0, Epoch 125/170 => Loss 0.067, Train_accy 99.380, Test_accy 89.700
2022-11-28 18:04:58,226 [bic.py] => training => Task 0, Epoch 126/170 => Loss 0.074, Train_accy 99.360, Test_accy 89.800
2022-11-28 18:05:04,261 [bic.py] => training => Task 0, Epoch 127/170 => Loss 0.051, Train_accy 99.240, Test_accy 89.400
2022-11-28 18:05:10,282 [bic.py] => training => Task 0, Epoch 128/170 => Loss 0.056, Train_accy 99.400, Test_accy 89.200
2022-11-28 18:05:16,474 [bic.py] => training => Task 0, Epoch 129/170 => Loss 0.058, Train_accy 99.260, Test_accy 88.900
2022-11-28 18:05:22,554 [bic.py] => training => Task 0, Epoch 130/170 => Loss 0.063, Train_accy 99.460, Test_accy 88.800
2022-11-28 18:05:28,489 [bic.py] => training => Task 0, Epoch 131/170 => Loss 0.064, Train_accy 99.400, Test_accy 88.800
2022-11-28 18:05:34,477 [bic.py] => training => Task 0, Epoch 132/170 => Loss 0.055, Train_accy 99.320, Test_accy 89.600
2022-11-28 18:05:40,591 [bic.py] => training => Task 0, Epoch 133/170 => Loss 0.068, Train_accy 99.420, Test_accy 89.500
2022-11-28 18:05:46,759 [bic.py] => training => Task 0, Epoch 134/170 => Loss 0.058, Train_accy 99.520, Test_accy 89.200
2022-11-28 18:05:52,808 [bic.py] => training => Task 0, Epoch 135/170 => Loss 0.049, Train_accy 99.200, Test_accy 88.500
2022-11-28 18:05:58,782 [bic.py] => training => Task 0, Epoch 136/170 => Loss 0.078, Train_accy 99.460, Test_accy 89.200
2022-11-28 18:06:05,404 [bic.py] => training => Task 0, Epoch 137/170 => Loss 0.046, Train_accy 99.300, Test_accy 89.500
2022-11-28 18:06:11,555 [bic.py] => training => Task 0, Epoch 138/170 => Loss 0.061, Train_accy 99.480, Test_accy 89.500
2022-11-28 18:06:17,557 [bic.py] => training => Task 0, Epoch 139/170 => Loss 0.067, Train_accy 99.420, Test_accy 89.200
2022-11-28 18:06:23,694 [bic.py] => training => Task 0, Epoch 140/170 => Loss 0.056, Train_accy 99.400, Test_accy 89.500
2022-11-28 18:06:29,683 [bic.py] => training => Task 0, Epoch 141/170 => Loss 0.087, Train_accy 99.280, Test_accy 88.800
2022-11-28 18:06:36,000 [bic.py] => training => Task 0, Epoch 142/170 => Loss 0.063, Train_accy 99.540, Test_accy 89.300
2022-11-28 18:06:41,823 [bic.py] => training => Task 0, Epoch 143/170 => Loss 0.058, Train_accy 99.440, Test_accy 89.500
2022-11-28 18:06:47,866 [bic.py] => training => Task 0, Epoch 144/170 => Loss 0.078, Train_accy 99.460, Test_accy 89.600
2022-11-28 18:06:53,924 [bic.py] => training => Task 0, Epoch 145/170 => Loss 0.060, Train_accy 99.320, Test_accy 89.100
2022-11-28 18:06:59,715 [bic.py] => training => Task 0, Epoch 146/170 => Loss 0.060, Train_accy 99.540, Test_accy 89.000
2022-11-28 18:07:05,854 [bic.py] => training => Task 0, Epoch 147/170 => Loss 0.079, Train_accy 99.520, Test_accy 88.500
2022-11-28 18:07:11,539 [bic.py] => training => Task 0, Epoch 148/170 => Loss 0.068, Train_accy 99.480, Test_accy 89.700
2022-11-28 18:07:17,331 [bic.py] => training => Task 0, Epoch 149/170 => Loss 0.082, Train_accy 99.180, Test_accy 89.300
2022-11-28 18:07:23,147 [bic.py] => training => Task 0, Epoch 150/170 => Loss 0.054, Train_accy 99.420, Test_accy 89.400
2022-11-28 18:07:29,197 [bic.py] => training => Task 0, Epoch 151/170 => Loss 0.074, Train_accy 99.180, Test_accy 88.900
2022-11-28 18:07:35,104 [bic.py] => training => Task 0, Epoch 152/170 => Loss 0.061, Train_accy 99.380, Test_accy 89.600
2022-11-28 18:07:41,287 [bic.py] => training => Task 0, Epoch 153/170 => Loss 0.066, Train_accy 99.520, Test_accy 89.200
2022-11-28 18:07:47,303 [bic.py] => training => Task 0, Epoch 154/170 => Loss 0.047, Train_accy 99.420, Test_accy 89.100
2022-11-28 18:07:53,040 [bic.py] => training => Task 0, Epoch 155/170 => Loss 0.056, Train_accy 99.380, Test_accy 89.400
2022-11-28 18:07:59,022 [bic.py] => training => Task 0, Epoch 156/170 => Loss 0.056, Train_accy 99.460, Test_accy 89.000
2022-11-28 18:08:05,247 [bic.py] => training => Task 0, Epoch 157/170 => Loss 0.053, Train_accy 99.620, Test_accy 89.500
2022-11-28 18:08:11,293 [bic.py] => training => Task 0, Epoch 158/170 => Loss 0.049, Train_accy 99.360, Test_accy 89.800
2022-11-28 18:08:17,121 [bic.py] => training => Task 0, Epoch 159/170 => Loss 0.068, Train_accy 99.260, Test_accy 89.300
2022-11-28 18:08:23,215 [bic.py] => training => Task 0, Epoch 160/170 => Loss 0.058, Train_accy 99.420, Test_accy 89.400
2022-11-28 18:08:29,487 [bic.py] => training => Task 0, Epoch 161/170 => Loss 0.066, Train_accy 99.440, Test_accy 89.100
2022-11-28 18:08:35,994 [bic.py] => training => Task 0, Epoch 162/170 => Loss 0.055, Train_accy 99.400, Test_accy 89.700
2022-11-28 18:08:42,160 [bic.py] => training => Task 0, Epoch 163/170 => Loss 0.076, Train_accy 99.380, Test_accy 89.200
2022-11-28 18:08:47,990 [bic.py] => training => Task 0, Epoch 164/170 => Loss 0.076, Train_accy 99.160, Test_accy 89.300
2022-11-28 18:08:54,194 [bic.py] => training => Task 0, Epoch 165/170 => Loss 0.081, Train_accy 99.220, Test_accy 89.000
2022-11-28 18:09:00,334 [bic.py] => training => Task 0, Epoch 166/170 => Loss 0.081, Train_accy 99.340, Test_accy 89.000
2022-11-28 18:09:06,497 [bic.py] => training => Task 0, Epoch 167/170 => Loss 0.067, Train_accy 99.580, Test_accy 89.600
2022-11-28 18:09:12,744 [bic.py] => training => Task 0, Epoch 168/170 => Loss 0.061, Train_accy 99.460, Test_accy 89.400
2022-11-28 18:09:19,057 [bic.py] => training => Task 0, Epoch 169/170 => Loss 0.056, Train_accy 99.640, Test_accy 89.400
2022-11-28 18:09:25,389 [bic.py] => training => Task 0, Epoch 170/170 => Loss 0.047, Train_accy 99.280, Test_accy 88.700
2022-11-28 18:09:25,391 [base.py] => Reducing exemplars...(200 per classes)
2022-11-28 18:09:25,391 [base.py] => Constructing exemplars...(200 per classes)
2022-11-28 18:09:36,093 [bic.py] => Parameters of bias layer:
2022-11-28 18:09:36,093 [bic.py] => 0 => 1.000, 0.000
2022-11-28 18:09:38,225 [bic.py] => Exemplar size: 2000
2022-11-28 18:09:38,225 [trainer.py] => CNN: {'total': 88.7, '00-09': 88.7, 'old': 0, 'new': 88.7}
2022-11-28 18:09:38,225 [trainer.py] => NME: {'total': 88.5, '00-09': 88.5, 'old': 0, 'new': 88.5}
2022-11-28 18:09:38,225 [trainer.py] => CNN top1 curve: [88.7]
2022-11-28 18:09:38,225 [trainer.py] => CNN top5 curve: [99.4]
2022-11-28 18:09:38,225 [trainer.py] => NME top1 curve: [88.5]
2022-11-28 18:09:38,225 [trainer.py] => NME top5 curve: [99.4]

2022-11-28 18:09:38,226 [trainer.py] => All params: 464806
2022-11-28 18:09:38,226 [trainer.py] => Trainable params: 464806
2022-11-28 18:09:38,227 [bic.py] => Learning on 10-20
2022-11-28 18:09:38,312 [bic.py] => Stage1 dset: 6600, Stage2 dset: 400
2022-11-28 18:09:38,312 [bic.py] => Lambda: 0.500
2022-11-28 18:09:38,317 [bic.py] => Parameters of bias layer:
2022-11-28 18:09:38,318 [bic.py] => 0 => 1.000, 0.000
2022-11-28 18:09:38,318 [bic.py] => 1 => 1.000, 0.000
2022-11-28 18:09:46,322 [bic.py] => training => Task 1, Epoch 1/170 => Loss 1.610, Train_accy 52.610, Test_accy 55.550
2022-11-28 18:09:53,955 [bic.py] => training => Task 1, Epoch 2/170 => Loss 1.214, Train_accy 58.060, Test_accy 56.350
2022-11-28 18:10:01,720 [bic.py] => training => Task 1, Epoch 3/170 => Loss 1.157, Train_accy 61.520, Test_accy 61.150
2022-11-28 18:10:09,716 [bic.py] => training => Task 1, Epoch 4/170 => Loss 1.116, Train_accy 64.000, Test_accy 59.850
2022-11-28 18:10:17,656 [bic.py] => training => Task 1, Epoch 5/170 => Loss 1.083, Train_accy 65.360, Test_accy 61.500
2022-11-28 18:10:25,345 [bic.py] => training => Task 1, Epoch 6/170 => Loss 1.041, Train_accy 65.730, Test_accy 61.850
2022-11-28 18:10:33,014 [bic.py] => training => Task 1, Epoch 7/170 => Loss 1.048, Train_accy 67.470, Test_accy 63.750
2022-11-28 18:10:40,446 [bic.py] => training => Task 1, Epoch 8/170 => Loss 1.015, Train_accy 70.440, Test_accy 64.000
2022-11-28 18:10:48,103 [bic.py] => training => Task 1, Epoch 9/170 => Loss 0.988, Train_accy 72.640, Test_accy 65.550
2022-11-28 18:10:56,024 [bic.py] => training => Task 1, Epoch 10/170 => Loss 0.978, Train_accy 74.450, Test_accy 65.450
2022-11-28 18:11:03,794 [bic.py] => training => Task 1, Epoch 11/170 => Loss 0.969, Train_accy 69.080, Test_accy 61.000
2022-11-28 18:11:11,246 [bic.py] => training => Task 1, Epoch 12/170 => Loss 0.944, Train_accy 71.790, Test_accy 63.500
2022-11-28 18:11:18,868 [bic.py] => training => Task 1, Epoch 13/170 => Loss 0.934, Train_accy 75.290, Test_accy 65.000
2022-11-28 18:11:26,607 [bic.py] => training => Task 1, Epoch 14/170 => Loss 0.925, Train_accy 75.480, Test_accy 64.850
2022-11-28 18:11:34,388 [bic.py] => training => Task 1, Epoch 15/170 => Loss 0.921, Train_accy 76.550, Test_accy 64.550
2022-11-28 18:11:41,915 [bic.py] => training => Task 1, Epoch 16/170 => Loss 0.904, Train_accy 75.210, Test_accy 64.450
2022-11-28 18:11:49,739 [bic.py] => training => Task 1, Epoch 17/170 => Loss 0.893, Train_accy 77.080, Test_accy 65.800
2022-11-28 18:11:57,564 [bic.py] => training => Task 1, Epoch 18/170 => Loss 0.882, Train_accy 75.980, Test_accy 65.600
2022-11-28 18:12:05,530 [bic.py] => training => Task 1, Epoch 19/170 => Loss 0.884, Train_accy 77.560, Test_accy 66.200
2022-11-28 18:12:13,499 [bic.py] => training => Task 1, Epoch 20/170 => Loss 0.868, Train_accy 77.970, Test_accy 64.950
2022-11-28 18:12:21,123 [bic.py] => training => Task 1, Epoch 21/170 => Loss 0.854, Train_accy 77.140, Test_accy 64.700
2022-11-28 18:12:28,562 [bic.py] => training => Task 1, Epoch 22/170 => Loss 0.841, Train_accy 81.770, Test_accy 68.200
2022-11-28 18:12:36,360 [bic.py] => training => Task 1, Epoch 23/170 => Loss 0.835, Train_accy 82.050, Test_accy 68.050
2022-11-28 18:12:44,123 [bic.py] => training => Task 1, Epoch 24/170 => Loss 0.848, Train_accy 78.610, Test_accy 63.800
2022-11-28 18:12:52,156 [bic.py] => training => Task 1, Epoch 25/170 => Loss 0.828, Train_accy 84.910, Test_accy 70.050
2022-11-28 18:12:59,742 [bic.py] => training => Task 1, Epoch 26/170 => Loss 0.821, Train_accy 82.520, Test_accy 67.600
2022-11-28 18:13:07,650 [bic.py] => training => Task 1, Epoch 27/170 => Loss 0.809, Train_accy 79.180, Test_accy 63.050
2022-11-28 18:13:15,287 [bic.py] => training => Task 1, Epoch 28/170 => Loss 0.810, Train_accy 85.110, Test_accy 69.250
2022-11-28 18:13:23,371 [bic.py] => training => Task 1, Epoch 29/170 => Loss 0.810, Train_accy 76.880, Test_accy 62.050
2022-11-28 18:13:31,192 [bic.py] => training => Task 1, Epoch 30/170 => Loss 0.794, Train_accy 85.860, Test_accy 68.950
2022-11-28 18:13:38,710 [bic.py] => training => Task 1, Epoch 31/170 => Loss 0.791, Train_accy 84.210, Test_accy 68.000
2022-11-28 18:13:46,616 [bic.py] => training => Task 1, Epoch 32/170 => Loss 0.782, Train_accy 84.640, Test_accy 67.900
2022-11-28 18:13:54,191 [bic.py] => training => Task 1, Epoch 33/170 => Loss 0.779, Train_accy 85.820, Test_accy 68.400
2022-11-28 18:14:02,142 [bic.py] => training => Task 1, Epoch 34/170 => Loss 0.766, Train_accy 84.530, Test_accy 68.050
2022-11-28 18:14:10,268 [bic.py] => training => Task 1, Epoch 35/170 => Loss 0.760, Train_accy 85.890, Test_accy 67.700
2022-11-28 18:14:17,961 [bic.py] => training => Task 1, Epoch 36/170 => Loss 0.779, Train_accy 82.030, Test_accy 68.800
2022-11-28 18:14:25,704 [bic.py] => training => Task 1, Epoch 37/170 => Loss 0.761, Train_accy 83.210, Test_accy 64.600
2022-11-28 18:14:33,222 [bic.py] => training => Task 1, Epoch 38/170 => Loss 0.757, Train_accy 80.670, Test_accy 68.350
2022-11-28 18:14:40,502 [bic.py] => training => Task 1, Epoch 39/170 => Loss 0.757, Train_accy 83.970, Test_accy 67.150
2022-11-28 18:14:47,866 [bic.py] => training => Task 1, Epoch 40/170 => Loss 0.764, Train_accy 83.670, Test_accy 65.600
2022-11-28 18:14:55,776 [bic.py] => training => Task 1, Epoch 41/170 => Loss 0.755, Train_accy 81.050, Test_accy 64.800
2022-11-28 18:15:03,544 [bic.py] => training => Task 1, Epoch 42/170 => Loss 0.739, Train_accy 89.740, Test_accy 70.900
2022-11-28 18:15:11,231 [bic.py] => training => Task 1, Epoch 43/170 => Loss 0.751, Train_accy 78.270, Test_accy 62.500
2022-11-28 18:15:18,898 [bic.py] => training => Task 1, Epoch 44/170 => Loss 0.741, Train_accy 88.110, Test_accy 68.850
2022-11-28 18:15:26,724 [bic.py] => training => Task 1, Epoch 45/170 => Loss 0.719, Train_accy 85.610, Test_accy 68.550
2022-11-28 18:15:34,276 [bic.py] => training => Task 1, Epoch 46/170 => Loss 0.726, Train_accy 87.060, Test_accy 64.700
2022-11-28 18:15:41,957 [bic.py] => training => Task 1, Epoch 47/170 => Loss 0.731, Train_accy 85.240, Test_accy 66.500
2022-11-28 18:15:49,449 [bic.py] => training => Task 1, Epoch 48/170 => Loss 0.726, Train_accy 86.230, Test_accy 65.150
2022-11-28 18:15:57,357 [bic.py] => training => Task 1, Epoch 49/170 => Loss 0.717, Train_accy 87.200, Test_accy 67.450
2022-11-28 18:16:04,846 [bic.py] => training => Task 1, Epoch 50/170 => Loss 0.717, Train_accy 82.330, Test_accy 62.500
2022-11-28 18:16:12,663 [bic.py] => training => Task 1, Epoch 51/170 => Loss 0.722, Train_accy 90.790, Test_accy 70.650
2022-11-28 18:16:20,111 [bic.py] => training => Task 1, Epoch 52/170 => Loss 0.708, Train_accy 88.830, Test_accy 68.550
2022-11-28 18:16:28,266 [bic.py] => training => Task 1, Epoch 53/170 => Loss 0.713, Train_accy 83.180, Test_accy 64.250
2022-11-28 18:16:35,870 [bic.py] => training => Task 1, Epoch 54/170 => Loss 0.694, Train_accy 90.290, Test_accy 69.050
2022-11-28 18:16:43,489 [bic.py] => training => Task 1, Epoch 55/170 => Loss 0.696, Train_accy 90.550, Test_accy 69.100
2022-11-28 18:16:51,190 [bic.py] => training => Task 1, Epoch 56/170 => Loss 0.724, Train_accy 89.320, Test_accy 69.100
2022-11-28 18:16:59,036 [bic.py] => training => Task 1, Epoch 57/170 => Loss 0.709, Train_accy 90.890, Test_accy 69.750
2022-11-28 18:17:06,608 [bic.py] => training => Task 1, Epoch 58/170 => Loss 0.696, Train_accy 89.440, Test_accy 68.400
2022-11-28 18:17:14,351 [bic.py] => training => Task 1, Epoch 59/170 => Loss 0.727, Train_accy 88.800, Test_accy 70.600
2022-11-28 18:17:21,791 [bic.py] => training => Task 1, Epoch 60/170 => Loss 0.716, Train_accy 87.770, Test_accy 66.000
2022-11-28 18:17:29,843 [bic.py] => training => Task 1, Epoch 61/170 => Loss 0.643, Train_accy 98.140, Test_accy 74.300
2022-11-28 18:17:37,510 [bic.py] => training => Task 1, Epoch 62/170 => Loss 0.610, Train_accy 98.470, Test_accy 74.550
2022-11-28 18:17:45,632 [bic.py] => training => Task 1, Epoch 63/170 => Loss 0.598, Train_accy 98.940, Test_accy 74.850
2022-11-28 18:17:53,293 [bic.py] => training => Task 1, Epoch 64/170 => Loss 0.597, Train_accy 98.890, Test_accy 74.950
2022-11-28 18:18:01,328 [bic.py] => training => Task 1, Epoch 65/170 => Loss 0.588, Train_accy 99.200, Test_accy 75.100
2022-11-28 18:18:09,230 [bic.py] => training => Task 1, Epoch 66/170 => Loss 0.590, Train_accy 99.330, Test_accy 74.850
2022-11-28 18:18:16,552 [bic.py] => training => Task 1, Epoch 67/170 => Loss 0.585, Train_accy 99.210, Test_accy 75.350
2022-11-28 18:18:24,408 [bic.py] => training => Task 1, Epoch 68/170 => Loss 0.583, Train_accy 99.290, Test_accy 74.950
2022-11-28 18:18:31,744 [bic.py] => training => Task 1, Epoch 69/170 => Loss 0.582, Train_accy 99.300, Test_accy 75.350
2022-11-28 18:18:39,660 [bic.py] => training => Task 1, Epoch 70/170 => Loss 0.575, Train_accy 99.360, Test_accy 75.750
2022-11-28 18:18:47,456 [bic.py] => training => Task 1, Epoch 71/170 => Loss 0.578, Train_accy 99.380, Test_accy 75.250
2022-11-28 18:18:55,206 [bic.py] => training => Task 1, Epoch 72/170 => Loss 0.574, Train_accy 99.470, Test_accy 75.350
2022-11-28 18:19:02,923 [bic.py] => training => Task 1, Epoch 73/170 => Loss 0.570, Train_accy 99.440, Test_accy 75.000
2022-11-28 18:19:10,201 [bic.py] => training => Task 1, Epoch 74/170 => Loss 0.575, Train_accy 99.550, Test_accy 75.350
2022-11-28 18:19:18,138 [bic.py] => training => Task 1, Epoch 75/170 => Loss 0.569, Train_accy 99.520, Test_accy 74.850
2022-11-28 18:19:25,961 [bic.py] => training => Task 1, Epoch 76/170 => Loss 0.573, Train_accy 99.640, Test_accy 75.100
2022-11-28 18:19:33,580 [bic.py] => training => Task 1, Epoch 77/170 => Loss 0.573, Train_accy 99.640, Test_accy 74.800
2022-11-28 18:19:41,219 [bic.py] => training => Task 1, Epoch 78/170 => Loss 0.571, Train_accy 99.450, Test_accy 75.400
2022-11-28 18:19:49,073 [bic.py] => training => Task 1, Epoch 79/170 => Loss 0.569, Train_accy 99.650, Test_accy 74.900
2022-11-28 18:19:57,212 [bic.py] => training => Task 1, Epoch 80/170 => Loss 0.568, Train_accy 99.640, Test_accy 75.000
2022-11-28 18:20:05,419 [bic.py] => training => Task 1, Epoch 81/170 => Loss 0.564, Train_accy 99.730, Test_accy 75.150
2022-11-28 18:20:12,771 [bic.py] => training => Task 1, Epoch 82/170 => Loss 0.567, Train_accy 99.670, Test_accy 74.700
2022-11-28 18:20:20,032 [bic.py] => training => Task 1, Epoch 83/170 => Loss 0.567, Train_accy 99.680, Test_accy 74.400
2022-11-28 18:20:27,943 [bic.py] => training => Task 1, Epoch 84/170 => Loss 0.561, Train_accy 99.700, Test_accy 75.350
2022-11-28 18:20:36,082 [bic.py] => training => Task 1, Epoch 85/170 => Loss 0.561, Train_accy 99.640, Test_accy 74.600
2022-11-28 18:20:43,517 [bic.py] => training => Task 1, Epoch 86/170 => Loss 0.564, Train_accy 99.580, Test_accy 74.650
2022-11-28 18:20:51,368 [bic.py] => training => Task 1, Epoch 87/170 => Loss 0.561, Train_accy 99.740, Test_accy 75.150
2022-11-28 18:20:59,306 [bic.py] => training => Task 1, Epoch 88/170 => Loss 0.563, Train_accy 99.770, Test_accy 75.250
2022-11-28 18:21:07,050 [bic.py] => training => Task 1, Epoch 89/170 => Loss 0.559, Train_accy 99.700, Test_accy 74.650
2022-11-28 18:21:14,678 [bic.py] => training => Task 1, Epoch 90/170 => Loss 0.566, Train_accy 99.740, Test_accy 74.800
2022-11-28 18:21:22,435 [bic.py] => training => Task 1, Epoch 91/170 => Loss 0.559, Train_accy 99.730, Test_accy 74.900
2022-11-28 18:21:30,574 [bic.py] => training => Task 1, Epoch 92/170 => Loss 0.560, Train_accy 99.770, Test_accy 74.550
2022-11-28 18:21:38,418 [bic.py] => training => Task 1, Epoch 93/170 => Loss 0.559, Train_accy 99.790, Test_accy 75.150
2022-11-28 18:21:46,305 [bic.py] => training => Task 1, Epoch 94/170 => Loss 0.559, Train_accy 99.800, Test_accy 74.850
2022-11-28 18:21:54,164 [bic.py] => training => Task 1, Epoch 95/170 => Loss 0.559, Train_accy 99.680, Test_accy 75.250
2022-11-28 18:22:02,102 [bic.py] => training => Task 1, Epoch 96/170 => Loss 0.555, Train_accy 99.820, Test_accy 75.200
2022-11-28 18:22:09,913 [bic.py] => training => Task 1, Epoch 97/170 => Loss 0.556, Train_accy 99.730, Test_accy 74.800
2022-11-28 18:22:17,658 [bic.py] => training => Task 1, Epoch 98/170 => Loss 0.558, Train_accy 99.850, Test_accy 75.150
2022-11-28 18:22:25,347 [bic.py] => training => Task 1, Epoch 99/170 => Loss 0.559, Train_accy 99.760, Test_accy 75.850
2022-11-28 18:22:33,015 [bic.py] => training => Task 1, Epoch 100/170 => Loss 0.563, Train_accy 99.770, Test_accy 75.500
2022-11-28 18:22:40,619 [bic.py] => training => Task 1, Epoch 101/170 => Loss 0.553, Train_accy 99.790, Test_accy 74.950
2022-11-28 18:22:48,516 [bic.py] => training => Task 1, Epoch 102/170 => Loss 0.558, Train_accy 99.850, Test_accy 75.250
2022-11-28 18:22:56,645 [bic.py] => training => Task 1, Epoch 103/170 => Loss 0.552, Train_accy 99.880, Test_accy 75.050
2022-11-28 18:23:04,332 [bic.py] => training => Task 1, Epoch 104/170 => Loss 0.554, Train_accy 99.820, Test_accy 75.450
2022-11-28 18:23:11,911 [bic.py] => training => Task 1, Epoch 105/170 => Loss 0.557, Train_accy 99.850, Test_accy 75.200
2022-11-28 18:23:19,451 [bic.py] => training => Task 1, Epoch 106/170 => Loss 0.552, Train_accy 99.860, Test_accy 75.100
2022-11-28 18:23:27,511 [bic.py] => training => Task 1, Epoch 107/170 => Loss 0.548, Train_accy 99.800, Test_accy 75.050
2022-11-28 18:23:35,284 [bic.py] => training => Task 1, Epoch 108/170 => Loss 0.555, Train_accy 99.850, Test_accy 75.100
2022-11-28 18:23:43,266 [bic.py] => training => Task 1, Epoch 109/170 => Loss 0.554, Train_accy 99.880, Test_accy 75.450
2022-11-28 18:23:51,142 [bic.py] => training => Task 1, Epoch 110/170 => Loss 0.558, Train_accy 99.790, Test_accy 75.400
2022-11-28 18:23:58,571 [bic.py] => training => Task 1, Epoch 111/170 => Loss 0.551, Train_accy 99.890, Test_accy 75.500
2022-11-28 18:24:06,172 [bic.py] => training => Task 1, Epoch 112/170 => Loss 0.552, Train_accy 99.880, Test_accy 75.050
2022-11-28 18:24:14,124 [bic.py] => training => Task 1, Epoch 113/170 => Loss 0.550, Train_accy 99.800, Test_accy 75.300
2022-11-28 18:24:22,140 [bic.py] => training => Task 1, Epoch 114/170 => Loss 0.555, Train_accy 99.880, Test_accy 75.550
2022-11-28 18:24:29,787 [bic.py] => training => Task 1, Epoch 115/170 => Loss 0.550, Train_accy 99.850, Test_accy 75.250
2022-11-28 18:24:37,571 [bic.py] => training => Task 1, Epoch 116/170 => Loss 0.553, Train_accy 99.790, Test_accy 75.000
2022-11-28 18:24:45,385 [bic.py] => training => Task 1, Epoch 117/170 => Loss 0.552, Train_accy 99.860, Test_accy 74.800
2022-11-28 18:24:53,366 [bic.py] => training => Task 1, Epoch 118/170 => Loss 0.555, Train_accy 99.830, Test_accy 75.150
2022-11-28 18:25:01,265 [bic.py] => training => Task 1, Epoch 119/170 => Loss 0.553, Train_accy 99.800, Test_accy 74.850
2022-11-28 18:25:09,109 [bic.py] => training => Task 1, Epoch 120/170 => Loss 0.552, Train_accy 99.790, Test_accy 75.000
2022-11-28 18:25:16,668 [bic.py] => training => Task 1, Epoch 121/170 => Loss 0.556, Train_accy 99.790, Test_accy 75.100
2022-11-28 18:25:24,668 [bic.py] => training => Task 1, Epoch 122/170 => Loss 0.554, Train_accy 99.830, Test_accy 74.750
2022-11-28 18:25:32,326 [bic.py] => training => Task 1, Epoch 123/170 => Loss 0.554, Train_accy 99.830, Test_accy 75.600
2022-11-28 18:25:40,053 [bic.py] => training => Task 1, Epoch 124/170 => Loss 0.551, Train_accy 99.850, Test_accy 75.100
2022-11-28 18:25:47,533 [bic.py] => training => Task 1, Epoch 125/170 => Loss 0.551, Train_accy 99.830, Test_accy 74.900
2022-11-28 18:25:55,413 [bic.py] => training => Task 1, Epoch 126/170 => Loss 0.555, Train_accy 99.850, Test_accy 75.150
2022-11-28 18:26:03,388 [bic.py] => training => Task 1, Epoch 127/170 => Loss 0.549, Train_accy 99.860, Test_accy 75.350
2022-11-28 18:26:11,347 [bic.py] => training => Task 1, Epoch 128/170 => Loss 0.550, Train_accy 99.860, Test_accy 75.800
2022-11-28 18:26:18,768 [bic.py] => training => Task 1, Epoch 129/170 => Loss 0.549, Train_accy 99.910, Test_accy 74.850
2022-11-28 18:26:27,039 [bic.py] => training => Task 1, Epoch 130/170 => Loss 0.554, Train_accy 99.910, Test_accy 75.500
2022-11-28 18:26:34,553 [bic.py] => training => Task 1, Epoch 131/170 => Loss 0.551, Train_accy 99.860, Test_accy 74.800
2022-11-28 18:26:42,246 [bic.py] => training => Task 1, Epoch 132/170 => Loss 0.552, Train_accy 99.760, Test_accy 74.850
2022-11-28 18:26:49,741 [bic.py] => training => Task 1, Epoch 133/170 => Loss 0.553, Train_accy 99.880, Test_accy 75.200
2022-11-28 18:26:57,664 [bic.py] => training => Task 1, Epoch 134/170 => Loss 0.554, Train_accy 99.850, Test_accy 75.500
2022-11-28 18:27:05,442 [bic.py] => training => Task 1, Epoch 135/170 => Loss 0.552, Train_accy 99.860, Test_accy 74.900
2022-11-28 18:27:12,868 [bic.py] => training => Task 1, Epoch 136/170 => Loss 0.552, Train_accy 99.890, Test_accy 75.050
2022-11-28 18:27:20,751 [bic.py] => training => Task 1, Epoch 137/170 => Loss 0.552, Train_accy 99.890, Test_accy 74.800
2022-11-28 18:27:28,502 [bic.py] => training => Task 1, Epoch 138/170 => Loss 0.552, Train_accy 99.830, Test_accy 74.550
2022-11-28 18:27:35,877 [bic.py] => training => Task 1, Epoch 139/170 => Loss 0.550, Train_accy 99.910, Test_accy 75.850
2022-11-28 18:27:43,725 [bic.py] => training => Task 1, Epoch 140/170 => Loss 0.552, Train_accy 99.830, Test_accy 75.350
2022-11-28 18:27:51,627 [bic.py] => training => Task 1, Epoch 141/170 => Loss 0.548, Train_accy 99.910, Test_accy 75.350
2022-11-28 18:27:59,440 [bic.py] => training => Task 1, Epoch 142/170 => Loss 0.554, Train_accy 99.910, Test_accy 75.250
2022-11-28 18:28:07,483 [bic.py] => training => Task 1, Epoch 143/170 => Loss 0.553, Train_accy 99.910, Test_accy 74.650
2022-11-28 18:28:15,391 [bic.py] => training => Task 1, Epoch 144/170 => Loss 0.554, Train_accy 99.880, Test_accy 75.150
2022-11-28 18:28:23,635 [bic.py] => training => Task 1, Epoch 145/170 => Loss 0.550, Train_accy 99.850, Test_accy 74.900
2022-11-28 18:28:31,216 [bic.py] => training => Task 1, Epoch 146/170 => Loss 0.553, Train_accy 99.880, Test_accy 74.650
2022-11-28 18:28:39,038 [bic.py] => training => Task 1, Epoch 147/170 => Loss 0.554, Train_accy 99.880, Test_accy 75.550
2022-11-28 18:28:46,808 [bic.py] => training => Task 1, Epoch 148/170 => Loss 0.554, Train_accy 99.830, Test_accy 74.950
2022-11-28 18:28:54,620 [bic.py] => training => Task 1, Epoch 149/170 => Loss 0.552, Train_accy 99.880, Test_accy 74.800
2022-11-28 18:29:02,401 [bic.py] => training => Task 1, Epoch 150/170 => Loss 0.548, Train_accy 99.890, Test_accy 74.750
2022-11-28 18:29:10,175 [bic.py] => training => Task 1, Epoch 151/170 => Loss 0.550, Train_accy 99.830, Test_accy 75.450
2022-11-28 18:29:17,933 [bic.py] => training => Task 1, Epoch 152/170 => Loss 0.551, Train_accy 99.920, Test_accy 74.950
2022-11-28 18:29:25,657 [bic.py] => training => Task 1, Epoch 153/170 => Loss 0.552, Train_accy 99.890, Test_accy 75.400
2022-11-28 18:29:33,421 [bic.py] => training => Task 1, Epoch 154/170 => Loss 0.548, Train_accy 99.860, Test_accy 75.500
2022-11-28 18:29:41,192 [bic.py] => training => Task 1, Epoch 155/170 => Loss 0.551, Train_accy 99.910, Test_accy 74.850
2022-11-28 18:29:48,729 [bic.py] => training => Task 1, Epoch 156/170 => Loss 0.556, Train_accy 99.770, Test_accy 74.800
2022-11-28 18:29:56,604 [bic.py] => training => Task 1, Epoch 157/170 => Loss 0.555, Train_accy 99.860, Test_accy 75.150
2022-11-28 18:30:04,651 [bic.py] => training => Task 1, Epoch 158/170 => Loss 0.553, Train_accy 99.790, Test_accy 75.050
2022-11-28 18:30:12,658 [bic.py] => training => Task 1, Epoch 159/170 => Loss 0.550, Train_accy 99.890, Test_accy 75.600
2022-11-28 18:30:20,321 [bic.py] => training => Task 1, Epoch 160/170 => Loss 0.550, Train_accy 99.940, Test_accy 75.800
2022-11-28 18:30:28,123 [bic.py] => training => Task 1, Epoch 161/170 => Loss 0.549, Train_accy 99.860, Test_accy 74.750
2022-11-28 18:30:36,023 [bic.py] => training => Task 1, Epoch 162/170 => Loss 0.550, Train_accy 99.850, Test_accy 75.100
2022-11-28 18:30:43,651 [bic.py] => training => Task 1, Epoch 163/170 => Loss 0.547, Train_accy 99.880, Test_accy 75.350
2022-11-28 18:30:51,181 [bic.py] => training => Task 1, Epoch 164/170 => Loss 0.553, Train_accy 99.920, Test_accy 75.350
2022-11-28 18:30:58,989 [bic.py] => training => Task 1, Epoch 165/170 => Loss 0.553, Train_accy 99.970, Test_accy 75.450
2022-11-28 18:31:06,497 [bic.py] => training => Task 1, Epoch 166/170 => Loss 0.554, Train_accy 99.890, Test_accy 75.250
2022-11-28 18:31:14,299 [bic.py] => training => Task 1, Epoch 167/170 => Loss 0.551, Train_accy 99.910, Test_accy 75.550
2022-11-28 18:31:22,009 [bic.py] => training => Task 1, Epoch 168/170 => Loss 0.552, Train_accy 99.830, Test_accy 74.800
2022-11-28 18:31:30,077 [bic.py] => training => Task 1, Epoch 169/170 => Loss 0.549, Train_accy 99.910, Test_accy 75.000
2022-11-28 18:31:37,922 [bic.py] => training => Task 1, Epoch 170/170 => Loss 0.553, Train_accy 99.920, Test_accy 74.950
2022-11-28 18:31:41,222 [bic.py] => bias_correction => Task 1, Epoch 1/170 => Loss 2.346, Train_accy 81.000, Test_accy 75.750
2022-11-28 18:31:44,452 [bic.py] => bias_correction => Task 1, Epoch 2/170 => Loss 2.407, Train_accy 81.000, Test_accy 75.700
2022-11-28 18:31:47,545 [bic.py] => bias_correction => Task 1, Epoch 3/170 => Loss 2.364, Train_accy 81.250, Test_accy 76.150
2022-11-28 18:31:50,873 [bic.py] => bias_correction => Task 1, Epoch 4/170 => Loss 2.378, Train_accy 81.000, Test_accy 75.800
2022-11-28 18:31:54,050 [bic.py] => bias_correction => Task 1, Epoch 5/170 => Loss 2.375, Train_accy 81.250, Test_accy 76.100
2022-11-28 18:31:57,193 [bic.py] => bias_correction => Task 1, Epoch 6/170 => Loss 2.370, Train_accy 80.500, Test_accy 76.150
2022-11-28 18:32:00,242 [bic.py] => bias_correction => Task 1, Epoch 7/170 => Loss 2.353, Train_accy 79.750, Test_accy 76.700
2022-11-28 18:32:03,298 [bic.py] => bias_correction => Task 1, Epoch 8/170 => Loss 2.380, Train_accy 81.500, Test_accy 75.600
2022-11-28 18:32:06,520 [bic.py] => bias_correction => Task 1, Epoch 9/170 => Loss 2.325, Train_accy 80.750, Test_accy 76.400
2022-11-28 18:32:09,546 [bic.py] => bias_correction => Task 1, Epoch 10/170 => Loss 2.373, Train_accy 82.750, Test_accy 76.050
2022-11-28 18:32:12,735 [bic.py] => bias_correction => Task 1, Epoch 11/170 => Loss 2.387, Train_accy 80.500, Test_accy 75.750
2022-11-28 18:32:15,858 [bic.py] => bias_correction => Task 1, Epoch 12/170 => Loss 2.361, Train_accy 77.500, Test_accy 75.900
2022-11-28 18:32:18,913 [bic.py] => bias_correction => Task 1, Epoch 13/170 => Loss 2.419, Train_accy 81.000, Test_accy 75.600
2022-11-28 18:32:21,992 [bic.py] => bias_correction => Task 1, Epoch 14/170 => Loss 2.358, Train_accy 80.500, Test_accy 75.800
2022-11-28 18:32:25,170 [bic.py] => bias_correction => Task 1, Epoch 15/170 => Loss 2.304, Train_accy 82.250, Test_accy 75.800
2022-11-28 18:32:28,252 [bic.py] => bias_correction => Task 1, Epoch 16/170 => Loss 2.349, Train_accy 80.750, Test_accy 75.950
2022-11-28 18:32:31,367 [bic.py] => bias_correction => Task 1, Epoch 17/170 => Loss 2.368, Train_accy 79.750, Test_accy 75.500
2022-11-28 18:32:34,552 [bic.py] => bias_correction => Task 1, Epoch 18/170 => Loss 2.347, Train_accy 80.500, Test_accy 74.800
2022-11-28 18:32:37,661 [bic.py] => bias_correction => Task 1, Epoch 19/170 => Loss 2.360, Train_accy 80.750, Test_accy 76.000
2022-11-28 18:32:40,605 [bic.py] => bias_correction => Task 1, Epoch 20/170 => Loss 2.362, Train_accy 79.500, Test_accy 76.000
2022-11-28 18:32:43,754 [bic.py] => bias_correction => Task 1, Epoch 21/170 => Loss 2.401, Train_accy 81.500, Test_accy 75.650
2022-11-28 18:32:46,895 [bic.py] => bias_correction => Task 1, Epoch 22/170 => Loss 2.358, Train_accy 79.500, Test_accy 75.150
2022-11-28 18:32:49,962 [bic.py] => bias_correction => Task 1, Epoch 23/170 => Loss 2.343, Train_accy 81.500, Test_accy 75.500
2022-11-28 18:32:53,074 [bic.py] => bias_correction => Task 1, Epoch 24/170 => Loss 2.387, Train_accy 80.250, Test_accy 75.350
2022-11-28 18:32:56,196 [bic.py] => bias_correction => Task 1, Epoch 25/170 => Loss 2.362, Train_accy 81.000, Test_accy 75.700
2022-11-28 18:32:59,303 [bic.py] => bias_correction => Task 1, Epoch 26/170 => Loss 2.368, Train_accy 80.500, Test_accy 75.500
2022-11-28 18:33:02,508 [bic.py] => bias_correction => Task 1, Epoch 27/170 => Loss 2.311, Train_accy 81.750, Test_accy 74.950
2022-11-28 18:33:05,753 [bic.py] => bias_correction => Task 1, Epoch 28/170 => Loss 2.380, Train_accy 81.250, Test_accy 75.000
2022-11-28 18:33:08,848 [bic.py] => bias_correction => Task 1, Epoch 29/170 => Loss 2.342, Train_accy 81.250, Test_accy 75.300
2022-11-28 18:33:11,901 [bic.py] => bias_correction => Task 1, Epoch 30/170 => Loss 2.373, Train_accy 80.500, Test_accy 75.350
2022-11-28 18:33:14,973 [bic.py] => bias_correction => Task 1, Epoch 31/170 => Loss 2.330, Train_accy 78.250, Test_accy 75.200
2022-11-28 18:33:18,135 [bic.py] => bias_correction => Task 1, Epoch 32/170 => Loss 2.361, Train_accy 81.500, Test_accy 75.600
2022-11-28 18:33:21,186 [bic.py] => bias_correction => Task 1, Epoch 33/170 => Loss 2.349, Train_accy 79.750, Test_accy 75.500
2022-11-28 18:33:24,315 [bic.py] => bias_correction => Task 1, Epoch 34/170 => Loss 2.348, Train_accy 80.250, Test_accy 75.450
2022-11-28 18:33:27,400 [bic.py] => bias_correction => Task 1, Epoch 35/170 => Loss 2.356, Train_accy 79.000, Test_accy 75.950
2022-11-28 18:33:30,383 [bic.py] => bias_correction => Task 1, Epoch 36/170 => Loss 2.344, Train_accy 80.500, Test_accy 75.550
2022-11-28 18:33:33,409 [bic.py] => bias_correction => Task 1, Epoch 37/170 => Loss 2.336, Train_accy 81.000, Test_accy 75.300
2022-11-28 18:33:36,591 [bic.py] => bias_correction => Task 1, Epoch 38/170 => Loss 2.347, Train_accy 79.250, Test_accy 74.900
2022-11-28 18:33:39,720 [bic.py] => bias_correction => Task 1, Epoch 39/170 => Loss 2.349, Train_accy 79.000, Test_accy 75.450
2022-11-28 18:33:42,794 [bic.py] => bias_correction => Task 1, Epoch 40/170 => Loss 2.358, Train_accy 79.250, Test_accy 76.050
2022-11-28 18:33:45,974 [bic.py] => bias_correction => Task 1, Epoch 41/170 => Loss 2.355, Train_accy 80.250, Test_accy 76.300
2022-11-28 18:33:49,156 [bic.py] => bias_correction => Task 1, Epoch 42/170 => Loss 2.381, Train_accy 80.500, Test_accy 76.800
2022-11-28 18:33:52,249 [bic.py] => bias_correction => Task 1, Epoch 43/170 => Loss 2.372, Train_accy 79.250, Test_accy 76.300
2022-11-28 18:33:55,353 [bic.py] => bias_correction => Task 1, Epoch 44/170 => Loss 2.359, Train_accy 80.750, Test_accy 75.300
2022-11-28 18:33:58,384 [bic.py] => bias_correction => Task 1, Epoch 45/170 => Loss 2.326, Train_accy 81.500, Test_accy 75.650
2022-11-28 18:34:01,454 [bic.py] => bias_correction => Task 1, Epoch 46/170 => Loss 2.364, Train_accy 78.500, Test_accy 75.350
2022-11-28 18:34:04,761 [bic.py] => bias_correction => Task 1, Epoch 47/170 => Loss 2.328, Train_accy 80.000, Test_accy 76.300
2022-11-28 18:34:08,028 [bic.py] => bias_correction => Task 1, Epoch 48/170 => Loss 2.348, Train_accy 83.750, Test_accy 76.450
2022-11-28 18:34:11,072 [bic.py] => bias_correction => Task 1, Epoch 49/170 => Loss 2.338, Train_accy 79.500, Test_accy 75.800
2022-11-28 18:34:14,179 [bic.py] => bias_correction => Task 1, Epoch 50/170 => Loss 2.374, Train_accy 78.000, Test_accy 74.700
2022-11-28 18:34:17,155 [bic.py] => bias_correction => Task 1, Epoch 51/170 => Loss 2.332, Train_accy 77.500, Test_accy 75.000
2022-11-28 18:34:20,280 [bic.py] => bias_correction => Task 1, Epoch 52/170 => Loss 2.361, Train_accy 80.750, Test_accy 76.100
2022-11-28 18:34:23,317 [bic.py] => bias_correction => Task 1, Epoch 53/170 => Loss 2.345, Train_accy 81.000, Test_accy 75.900
2022-11-28 18:34:26,591 [bic.py] => bias_correction => Task 1, Epoch 54/170 => Loss 2.348, Train_accy 79.750, Test_accy 75.900
2022-11-28 18:34:29,640 [bic.py] => bias_correction => Task 1, Epoch 55/170 => Loss 2.327, Train_accy 79.750, Test_accy 75.850
2022-11-28 18:34:32,780 [bic.py] => bias_correction => Task 1, Epoch 56/170 => Loss 2.318, Train_accy 81.250, Test_accy 75.800
2022-11-28 18:34:35,929 [bic.py] => bias_correction => Task 1, Epoch 57/170 => Loss 2.357, Train_accy 77.750, Test_accy 74.900
2022-11-28 18:34:39,039 [bic.py] => bias_correction => Task 1, Epoch 58/170 => Loss 2.350, Train_accy 80.000, Test_accy 75.150
2022-11-28 18:34:42,181 [bic.py] => bias_correction => Task 1, Epoch 59/170 => Loss 2.381, Train_accy 82.250, Test_accy 75.650
2022-11-28 18:34:45,457 [bic.py] => bias_correction => Task 1, Epoch 60/170 => Loss 2.386, Train_accy 80.250, Test_accy 75.800
2022-11-28 18:34:48,435 [bic.py] => bias_correction => Task 1, Epoch 61/170 => Loss 2.371, Train_accy 80.500, Test_accy 76.000
2022-11-28 18:34:51,588 [bic.py] => bias_correction => Task 1, Epoch 62/170 => Loss 2.369, Train_accy 80.250, Test_accy 75.550
2022-11-28 18:34:54,620 [bic.py] => bias_correction => Task 1, Epoch 63/170 => Loss 2.346, Train_accy 79.500, Test_accy 75.550
2022-11-28 18:34:57,868 [bic.py] => bias_correction => Task 1, Epoch 64/170 => Loss 2.340, Train_accy 79.250, Test_accy 75.650
2022-11-28 18:35:01,004 [bic.py] => bias_correction => Task 1, Epoch 65/170 => Loss 2.318, Train_accy 81.500, Test_accy 75.950
2022-11-28 18:35:04,170 [bic.py] => bias_correction => Task 1, Epoch 66/170 => Loss 2.330, Train_accy 80.000, Test_accy 75.500
2022-11-28 18:35:07,231 [bic.py] => bias_correction => Task 1, Epoch 67/170 => Loss 2.367, Train_accy 83.750, Test_accy 75.500
2022-11-28 18:35:10,389 [bic.py] => bias_correction => Task 1, Epoch 68/170 => Loss 2.356, Train_accy 81.500, Test_accy 74.900
2022-11-28 18:35:13,515 [bic.py] => bias_correction => Task 1, Epoch 69/170 => Loss 2.353, Train_accy 82.750, Test_accy 75.500
2022-11-28 18:35:16,527 [bic.py] => bias_correction => Task 1, Epoch 70/170 => Loss 2.343, Train_accy 82.250, Test_accy 76.050
2022-11-28 18:35:19,557 [bic.py] => bias_correction => Task 1, Epoch 71/170 => Loss 2.342, Train_accy 77.750, Test_accy 75.600
2022-11-28 18:35:22,721 [bic.py] => bias_correction => Task 1, Epoch 72/170 => Loss 2.403, Train_accy 78.500, Test_accy 75.800
2022-11-28 18:35:25,935 [bic.py] => bias_correction => Task 1, Epoch 73/170 => Loss 2.343, Train_accy 80.500, Test_accy 75.950
2022-11-28 18:35:28,994 [bic.py] => bias_correction => Task 1, Epoch 74/170 => Loss 2.330, Train_accy 80.500, Test_accy 76.150
2022-11-28 18:35:32,121 [bic.py] => bias_correction => Task 1, Epoch 75/170 => Loss 2.359, Train_accy 79.250, Test_accy 75.450
2022-11-28 18:35:35,176 [bic.py] => bias_correction => Task 1, Epoch 76/170 => Loss 2.317, Train_accy 78.500, Test_accy 75.350
2022-11-28 18:35:38,247 [bic.py] => bias_correction => Task 1, Epoch 77/170 => Loss 2.349, Train_accy 80.750, Test_accy 75.550
2022-11-28 18:35:41,368 [bic.py] => bias_correction => Task 1, Epoch 78/170 => Loss 2.338, Train_accy 80.250, Test_accy 76.000
2022-11-28 18:35:44,528 [bic.py] => bias_correction => Task 1, Epoch 79/170 => Loss 2.336, Train_accy 80.500, Test_accy 75.350
2022-11-28 18:35:47,602 [bic.py] => bias_correction => Task 1, Epoch 80/170 => Loss 2.327, Train_accy 81.000, Test_accy 76.600
2022-11-28 18:35:50,602 [bic.py] => bias_correction => Task 1, Epoch 81/170 => Loss 2.314, Train_accy 79.750, Test_accy 75.350
2022-11-28 18:35:53,789 [bic.py] => bias_correction => Task 1, Epoch 82/170 => Loss 2.351, Train_accy 78.500, Test_accy 75.400
2022-11-28 18:35:56,855 [bic.py] => bias_correction => Task 1, Epoch 83/170 => Loss 2.337, Train_accy 80.250, Test_accy 75.200
2022-11-28 18:35:59,983 [bic.py] => bias_correction => Task 1, Epoch 84/170 => Loss 2.367, Train_accy 79.500, Test_accy 75.700
2022-11-28 18:36:03,179 [bic.py] => bias_correction => Task 1, Epoch 85/170 => Loss 2.370, Train_accy 82.500, Test_accy 76.050
2022-11-28 18:36:06,354 [bic.py] => bias_correction => Task 1, Epoch 86/170 => Loss 2.354, Train_accy 80.250, Test_accy 76.100
2022-11-28 18:36:09,506 [bic.py] => bias_correction => Task 1, Epoch 87/170 => Loss 2.344, Train_accy 80.750, Test_accy 76.050
2022-11-28 18:36:12,643 [bic.py] => bias_correction => Task 1, Epoch 88/170 => Loss 2.346, Train_accy 80.500, Test_accy 76.050
2022-11-28 18:36:15,906 [bic.py] => bias_correction => Task 1, Epoch 89/170 => Loss 2.369, Train_accy 80.000, Test_accy 76.200
2022-11-28 18:36:18,998 [bic.py] => bias_correction => Task 1, Epoch 90/170 => Loss 2.335, Train_accy 78.500, Test_accy 76.200
2022-11-28 18:36:22,183 [bic.py] => bias_correction => Task 1, Epoch 91/170 => Loss 2.314, Train_accy 80.000, Test_accy 76.400
2022-11-28 18:36:25,437 [bic.py] => bias_correction => Task 1, Epoch 92/170 => Loss 2.330, Train_accy 81.500, Test_accy 76.250
2022-11-28 18:36:28,676 [bic.py] => bias_correction => Task 1, Epoch 93/170 => Loss 2.340, Train_accy 81.500, Test_accy 76.150
2022-11-28 18:36:31,865 [bic.py] => bias_correction => Task 1, Epoch 94/170 => Loss 2.368, Train_accy 79.500, Test_accy 75.850
2022-11-28 18:36:34,854 [bic.py] => bias_correction => Task 1, Epoch 95/170 => Loss 2.298, Train_accy 81.750, Test_accy 75.250
2022-11-28 18:36:38,063 [bic.py] => bias_correction => Task 1, Epoch 96/170 => Loss 2.343, Train_accy 78.750, Test_accy 75.400
2022-11-28 18:36:41,172 [bic.py] => bias_correction => Task 1, Epoch 97/170 => Loss 2.359, Train_accy 79.750, Test_accy 74.700
2022-11-28 18:36:44,343 [bic.py] => bias_correction => Task 1, Epoch 98/170 => Loss 2.343, Train_accy 82.250, Test_accy 75.250
2022-11-28 18:36:47,668 [bic.py] => bias_correction => Task 1, Epoch 99/170 => Loss 2.356, Train_accy 81.500, Test_accy 75.000
2022-11-28 18:36:50,829 [bic.py] => bias_correction => Task 1, Epoch 100/170 => Loss 2.361, Train_accy 80.000, Test_accy 75.250
2022-11-28 18:36:53,899 [bic.py] => bias_correction => Task 1, Epoch 101/170 => Loss 2.351, Train_accy 83.000, Test_accy 75.850
2022-11-28 18:36:57,156 [bic.py] => bias_correction => Task 1, Epoch 102/170 => Loss 2.325, Train_accy 84.000, Test_accy 76.050
2022-11-28 18:37:00,348 [bic.py] => bias_correction => Task 1, Epoch 103/170 => Loss 2.344, Train_accy 81.250, Test_accy 76.100
2022-11-28 18:37:03,311 [bic.py] => bias_correction => Task 1, Epoch 104/170 => Loss 2.339, Train_accy 81.000, Test_accy 75.750
2022-11-28 18:37:06,382 [bic.py] => bias_correction => Task 1, Epoch 105/170 => Loss 2.331, Train_accy 79.500, Test_accy 75.750
2022-11-28 18:37:09,533 [bic.py] => bias_correction => Task 1, Epoch 106/170 => Loss 2.359, Train_accy 78.750, Test_accy 76.200
2022-11-28 18:37:12,734 [bic.py] => bias_correction => Task 1, Epoch 107/170 => Loss 2.340, Train_accy 76.750, Test_accy 76.200
2022-11-28 18:37:15,951 [bic.py] => bias_correction => Task 1, Epoch 108/170 => Loss 2.373, Train_accy 80.500, Test_accy 76.150
2022-11-28 18:37:19,064 [bic.py] => bias_correction => Task 1, Epoch 109/170 => Loss 2.328, Train_accy 80.000, Test_accy 76.150
2022-11-28 18:37:22,112 [bic.py] => bias_correction => Task 1, Epoch 110/170 => Loss 2.379, Train_accy 81.000, Test_accy 75.850
2022-11-28 18:37:25,269 [bic.py] => bias_correction => Task 1, Epoch 111/170 => Loss 2.309, Train_accy 80.000, Test_accy 75.700
2022-11-28 18:37:28,494 [bic.py] => bias_correction => Task 1, Epoch 112/170 => Loss 2.292, Train_accy 79.500, Test_accy 75.500
2022-11-28 18:37:31,593 [bic.py] => bias_correction => Task 1, Epoch 113/170 => Loss 2.377, Train_accy 80.250, Test_accy 75.650
2022-11-28 18:37:34,800 [bic.py] => bias_correction => Task 1, Epoch 114/170 => Loss 2.353, Train_accy 79.250, Test_accy 76.500
2022-11-28 18:37:38,000 [bic.py] => bias_correction => Task 1, Epoch 115/170 => Loss 2.324, Train_accy 80.500, Test_accy 75.900
2022-11-28 18:37:41,199 [bic.py] => bias_correction => Task 1, Epoch 116/170 => Loss 2.332, Train_accy 78.250, Test_accy 75.450
2022-11-28 18:37:44,325 [bic.py] => bias_correction => Task 1, Epoch 117/170 => Loss 2.343, Train_accy 82.250, Test_accy 75.850
2022-11-28 18:37:47,510 [bic.py] => bias_correction => Task 1, Epoch 118/170 => Loss 2.329, Train_accy 81.000, Test_accy 76.000
2022-11-28 18:37:50,588 [bic.py] => bias_correction => Task 1, Epoch 119/170 => Loss 2.372, Train_accy 79.750, Test_accy 75.900
2022-11-28 18:37:53,790 [bic.py] => bias_correction => Task 1, Epoch 120/170 => Loss 2.316, Train_accy 82.500, Test_accy 76.100
2022-11-28 18:37:56,766 [bic.py] => bias_correction => Task 1, Epoch 121/170 => Loss 2.371, Train_accy 79.250, Test_accy 75.600
2022-11-28 18:37:59,903 [bic.py] => bias_correction => Task 1, Epoch 122/170 => Loss 2.365, Train_accy 79.750, Test_accy 75.850
2022-11-28 18:38:02,953 [bic.py] => bias_correction => Task 1, Epoch 123/170 => Loss 2.331, Train_accy 79.750, Test_accy 76.050
2022-11-28 18:38:06,174 [bic.py] => bias_correction => Task 1, Epoch 124/170 => Loss 2.359, Train_accy 82.500, Test_accy 76.000
2022-11-28 18:38:09,326 [bic.py] => bias_correction => Task 1, Epoch 125/170 => Loss 2.357, Train_accy 80.500, Test_accy 75.850
2022-11-28 18:38:12,338 [bic.py] => bias_correction => Task 1, Epoch 126/170 => Loss 2.356, Train_accy 80.500, Test_accy 76.100
2022-11-28 18:38:15,547 [bic.py] => bias_correction => Task 1, Epoch 127/170 => Loss 2.352, Train_accy 81.000, Test_accy 75.950
2022-11-28 18:38:18,586 [bic.py] => bias_correction => Task 1, Epoch 128/170 => Loss 2.341, Train_accy 80.500, Test_accy 75.850
2022-11-28 18:38:21,817 [bic.py] => bias_correction => Task 1, Epoch 129/170 => Loss 2.358, Train_accy 81.500, Test_accy 75.850
2022-11-28 18:38:24,950 [bic.py] => bias_correction => Task 1, Epoch 130/170 => Loss 2.305, Train_accy 81.500, Test_accy 76.300
2022-11-28 18:38:27,979 [bic.py] => bias_correction => Task 1, Epoch 131/170 => Loss 2.368, Train_accy 81.000, Test_accy 75.950
2022-11-28 18:38:31,150 [bic.py] => bias_correction => Task 1, Epoch 132/170 => Loss 2.363, Train_accy 81.750, Test_accy 75.400
2022-11-28 18:38:34,289 [bic.py] => bias_correction => Task 1, Epoch 133/170 => Loss 2.354, Train_accy 79.250, Test_accy 75.100
2022-11-28 18:38:37,347 [bic.py] => bias_correction => Task 1, Epoch 134/170 => Loss 2.339, Train_accy 80.000, Test_accy 75.350
2022-11-28 18:38:40,431 [bic.py] => bias_correction => Task 1, Epoch 135/170 => Loss 2.358, Train_accy 81.500, Test_accy 75.700
2022-11-28 18:38:43,666 [bic.py] => bias_correction => Task 1, Epoch 136/170 => Loss 2.343, Train_accy 80.250, Test_accy 75.850
2022-11-28 18:38:46,782 [bic.py] => bias_correction => Task 1, Epoch 137/170 => Loss 2.305, Train_accy 79.500, Test_accy 75.200
2022-11-28 18:38:49,878 [bic.py] => bias_correction => Task 1, Epoch 138/170 => Loss 2.332, Train_accy 81.250, Test_accy 75.100
2022-11-28 18:38:53,214 [bic.py] => bias_correction => Task 1, Epoch 139/170 => Loss 2.361, Train_accy 80.500, Test_accy 75.800
2022-11-28 18:38:56,560 [bic.py] => bias_correction => Task 1, Epoch 140/170 => Loss 2.356, Train_accy 80.500, Test_accy 76.250
2022-11-28 18:38:59,767 [bic.py] => bias_correction => Task 1, Epoch 141/170 => Loss 2.357, Train_accy 79.250, Test_accy 76.150
2022-11-28 18:39:02,911 [bic.py] => bias_correction => Task 1, Epoch 142/170 => Loss 2.388, Train_accy 78.250, Test_accy 76.150
2022-11-28 18:39:05,986 [bic.py] => bias_correction => Task 1, Epoch 143/170 => Loss 2.339, Train_accy 81.250, Test_accy 76.500
2022-11-28 18:39:08,939 [bic.py] => bias_correction => Task 1, Epoch 144/170 => Loss 2.323, Train_accy 79.000, Test_accy 76.100
2022-11-28 18:39:12,099 [bic.py] => bias_correction => Task 1, Epoch 145/170 => Loss 2.347, Train_accy 79.250, Test_accy 75.900
2022-11-28 18:39:15,226 [bic.py] => bias_correction => Task 1, Epoch 146/170 => Loss 2.334, Train_accy 81.000, Test_accy 75.800
2022-11-28 18:39:18,451 [bic.py] => bias_correction => Task 1, Epoch 147/170 => Loss 2.353, Train_accy 76.750, Test_accy 75.900
2022-11-28 18:39:21,484 [bic.py] => bias_correction => Task 1, Epoch 148/170 => Loss 2.332, Train_accy 80.500, Test_accy 76.600
2022-11-28 18:39:24,514 [bic.py] => bias_correction => Task 1, Epoch 149/170 => Loss 2.328, Train_accy 78.750, Test_accy 76.400
2022-11-28 18:39:27,761 [bic.py] => bias_correction => Task 1, Epoch 150/170 => Loss 2.356, Train_accy 81.000, Test_accy 75.700
2022-11-28 18:39:30,707 [bic.py] => bias_correction => Task 1, Epoch 151/170 => Loss 2.362, Train_accy 83.250, Test_accy 75.750
2022-11-28 18:39:33,940 [bic.py] => bias_correction => Task 1, Epoch 152/170 => Loss 2.358, Train_accy 80.750, Test_accy 76.550
2022-11-28 18:39:36,964 [bic.py] => bias_correction => Task 1, Epoch 153/170 => Loss 2.347, Train_accy 81.500, Test_accy 76.350
2022-11-28 18:39:40,188 [bic.py] => bias_correction => Task 1, Epoch 154/170 => Loss 2.345, Train_accy 81.500, Test_accy 76.100
2022-11-28 18:39:43,252 [bic.py] => bias_correction => Task 1, Epoch 155/170 => Loss 2.386, Train_accy 79.000, Test_accy 75.600
2022-11-28 18:39:46,416 [bic.py] => bias_correction => Task 1, Epoch 156/170 => Loss 2.365, Train_accy 78.000, Test_accy 76.100
2022-11-28 18:39:49,636 [bic.py] => bias_correction => Task 1, Epoch 157/170 => Loss 2.347, Train_accy 81.250, Test_accy 76.100
2022-11-28 18:39:52,768 [bic.py] => bias_correction => Task 1, Epoch 158/170 => Loss 2.329, Train_accy 80.750, Test_accy 75.950
2022-11-28 18:39:55,986 [bic.py] => bias_correction => Task 1, Epoch 159/170 => Loss 2.364, Train_accy 79.000, Test_accy 75.800
2022-11-28 18:39:59,167 [bic.py] => bias_correction => Task 1, Epoch 160/170 => Loss 2.330, Train_accy 81.000, Test_accy 75.450
2022-11-28 18:40:02,211 [bic.py] => bias_correction => Task 1, Epoch 161/170 => Loss 2.315, Train_accy 78.000, Test_accy 75.650
2022-11-28 18:40:05,532 [bic.py] => bias_correction => Task 1, Epoch 162/170 => Loss 2.352, Train_accy 81.500, Test_accy 75.500
2022-11-28 18:40:08,743 [bic.py] => bias_correction => Task 1, Epoch 163/170 => Loss 2.346, Train_accy 79.000, Test_accy 76.000
2022-11-28 18:40:11,864 [bic.py] => bias_correction => Task 1, Epoch 164/170 => Loss 2.387, Train_accy 79.500, Test_accy 75.950
2022-11-28 18:40:15,026 [bic.py] => bias_correction => Task 1, Epoch 165/170 => Loss 2.368, Train_accy 80.500, Test_accy 76.000
2022-11-28 18:40:18,191 [bic.py] => bias_correction => Task 1, Epoch 166/170 => Loss 2.352, Train_accy 80.750, Test_accy 75.550
2022-11-28 18:40:21,376 [bic.py] => bias_correction => Task 1, Epoch 167/170 => Loss 2.350, Train_accy 82.000, Test_accy 75.950
2022-11-28 18:40:24,459 [bic.py] => bias_correction => Task 1, Epoch 168/170 => Loss 2.346, Train_accy 80.250, Test_accy 75.950
2022-11-28 18:40:27,620 [bic.py] => bias_correction => Task 1, Epoch 169/170 => Loss 2.344, Train_accy 81.000, Test_accy 75.800
2022-11-28 18:40:30,767 [bic.py] => bias_correction => Task 1, Epoch 170/170 => Loss 2.353, Train_accy 84.000, Test_accy 75.600
2022-11-28 18:40:30,768 [base.py] => Reducing exemplars...(100 per classes)
2022-11-28 18:40:35,253 [base.py] => Constructing exemplars...(100 per classes)
2022-11-28 18:40:45,219 [bic.py] => Parameters of bias layer:
2022-11-28 18:40:45,219 [bic.py] => 0 => 1.000, 0.000
2022-11-28 18:40:45,219 [bic.py] => 1 => 0.976, -1.640
2022-11-28 18:40:47,027 [bic.py] => Exemplar size: 2000
2022-11-28 18:40:47,027 [trainer.py] => CNN: {'total': 75.6, '00-09': 79.0, '10-19': 72.2, 'old': 79.0, 'new': 72.2}
2022-11-28 18:40:47,027 [trainer.py] => NME: {'total': 75.85, '00-09': 77.6, '10-19': 74.1, 'old': 77.6, 'new': 74.1}
2022-11-28 18:40:47,027 [trainer.py] => CNN top1 curve: [88.7, 75.6]
2022-11-28 18:40:47,027 [trainer.py] => CNN top5 curve: [99.4, 95.6]
2022-11-28 18:40:47,027 [trainer.py] => NME top1 curve: [88.5, 75.85]
2022-11-28 18:40:47,027 [trainer.py] => NME top5 curve: [99.4, 95.95]

2022-11-28 18:40:47,027 [trainer.py] => All params: 465458
2022-11-28 18:40:47,028 [trainer.py] => Trainable params: 465458
2022-11-28 18:40:47,029 [bic.py] => Learning on 20-30
2022-11-28 18:40:47,081 [bic.py] => Stage1 dset: 6700, Stage2 dset: 300
2022-11-28 18:40:47,081 [bic.py] => Lambda: 0.667
2022-11-28 18:40:47,089 [bic.py] => Parameters of bias layer:
2022-11-28 18:40:47,089 [bic.py] => 0 => 1.000, 0.000
2022-11-28 18:40:47,089 [bic.py] => 1 => 0.976, -1.640
2022-11-28 18:40:47,090 [bic.py] => 2 => 1.000, 0.000
2022-11-28 18:40:55,364 [bic.py] => training => Task 2, Epoch 1/170 => Loss 1.612, Train_accy 60.340, Test_accy 51.800
2022-11-28 18:41:03,217 [bic.py] => training => Task 2, Epoch 2/170 => Loss 1.305, Train_accy 70.360, Test_accy 55.670
2022-11-28 18:41:11,742 [bic.py] => training => Task 2, Epoch 3/170 => Loss 1.270, Train_accy 72.210, Test_accy 55.530
2022-11-28 18:41:20,214 [bic.py] => training => Task 2, Epoch 4/170 => Loss 1.221, Train_accy 73.570, Test_accy 54.970
2022-11-28 18:41:28,417 [bic.py] => training => Task 2, Epoch 5/170 => Loss 1.193, Train_accy 79.760, Test_accy 61.530
2022-11-28 18:41:36,405 [bic.py] => training => Task 2, Epoch 6/170 => Loss 1.171, Train_accy 79.900, Test_accy 59.900
2022-11-28 18:41:44,575 [bic.py] => training => Task 2, Epoch 7/170 => Loss 1.167, Train_accy 81.510, Test_accy 59.900
2022-11-28 18:41:52,343 [bic.py] => training => Task 2, Epoch 8/170 => Loss 1.144, Train_accy 79.630, Test_accy 60.970
2022-11-28 18:42:00,572 [bic.py] => training => Task 2, Epoch 9/170 => Loss 1.126, Train_accy 83.570, Test_accy 59.870
2022-11-28 18:42:08,766 [bic.py] => training => Task 2, Epoch 10/170 => Loss 1.131, Train_accy 85.090, Test_accy 61.830
2022-11-28 18:42:16,981 [bic.py] => training => Task 2, Epoch 11/170 => Loss 1.119, Train_accy 83.210, Test_accy 62.600
2022-11-28 18:42:25,255 [bic.py] => training => Task 2, Epoch 12/170 => Loss 1.112, Train_accy 84.160, Test_accy 62.300
2022-11-28 18:42:33,460 [bic.py] => training => Task 2, Epoch 13/170 => Loss 1.095, Train_accy 83.510, Test_accy 60.330
2022-11-28 18:42:41,578 [bic.py] => training => Task 2, Epoch 14/170 => Loss 1.115, Train_accy 85.720, Test_accy 64.070
2022-11-28 18:42:50,086 [bic.py] => training => Task 2, Epoch 15/170 => Loss 1.091, Train_accy 84.850, Test_accy 58.570
2022-11-28 18:42:58,553 [bic.py] => training => Task 2, Epoch 16/170 => Loss 1.084, Train_accy 87.420, Test_accy 62.130
2022-11-28 18:43:06,395 [bic.py] => training => Task 2, Epoch 17/170 => Loss 1.087, Train_accy 85.390, Test_accy 62.300
2022-11-28 18:43:14,524 [bic.py] => training => Task 2, Epoch 18/170 => Loss 1.090, Train_accy 88.880, Test_accy 62.270
2022-11-28 18:43:22,301 [bic.py] => training => Task 2, Epoch 19/170 => Loss 1.091, Train_accy 87.010, Test_accy 60.500
2022-11-28 18:43:30,707 [bic.py] => training => Task 2, Epoch 20/170 => Loss 1.085, Train_accy 86.550, Test_accy 61.270
2022-11-28 18:43:38,749 [bic.py] => training => Task 2, Epoch 21/170 => Loss 1.065, Train_accy 85.780, Test_accy 61.400
2022-11-28 18:43:47,074 [bic.py] => training => Task 2, Epoch 22/170 => Loss 1.071, Train_accy 88.930, Test_accy 62.000
2022-11-28 18:43:55,441 [bic.py] => training => Task 2, Epoch 23/170 => Loss 1.063, Train_accy 87.180, Test_accy 60.730
2022-11-28 18:44:03,336 [bic.py] => training => Task 2, Epoch 24/170 => Loss 1.074, Train_accy 84.270, Test_accy 59.630
2022-11-28 18:44:11,727 [bic.py] => training => Task 2, Epoch 25/170 => Loss 1.065, Train_accy 89.300, Test_accy 63.330
2022-11-28 18:44:20,033 [bic.py] => training => Task 2, Epoch 26/170 => Loss 1.062, Train_accy 84.360, Test_accy 58.370
2022-11-28 18:44:28,557 [bic.py] => training => Task 2, Epoch 27/170 => Loss 1.060, Train_accy 90.190, Test_accy 64.930
2022-11-28 18:44:36,516 [bic.py] => training => Task 2, Epoch 28/170 => Loss 1.048, Train_accy 90.490, Test_accy 62.270
2022-11-28 18:44:45,009 [bic.py] => training => Task 2, Epoch 29/170 => Loss 1.054, Train_accy 91.540, Test_accy 63.930
2022-11-28 18:44:53,561 [bic.py] => training => Task 2, Epoch 30/170 => Loss 1.055, Train_accy 89.120, Test_accy 62.970
2022-11-28 18:45:01,766 [bic.py] => training => Task 2, Epoch 31/170 => Loss 1.053, Train_accy 91.400, Test_accy 63.800
2022-11-28 18:45:09,889 [bic.py] => training => Task 2, Epoch 32/170 => Loss 1.040, Train_accy 90.150, Test_accy 63.470
2022-11-28 18:45:18,195 [bic.py] => training => Task 2, Epoch 33/170 => Loss 1.040, Train_accy 85.840, Test_accy 58.170
2022-11-28 18:45:26,247 [bic.py] => training => Task 2, Epoch 34/170 => Loss 1.030, Train_accy 89.370, Test_accy 60.970
2022-11-28 18:45:34,919 [bic.py] => training => Task 2, Epoch 35/170 => Loss 1.042, Train_accy 89.750, Test_accy 63.770
2022-11-28 18:45:42,709 [bic.py] => training => Task 2, Epoch 36/170 => Loss 1.043, Train_accy 90.190, Test_accy 60.870
2022-11-28 18:45:51,285 [bic.py] => training => Task 2, Epoch 37/170 => Loss 1.026, Train_accy 92.130, Test_accy 62.930
2022-11-28 18:45:59,551 [bic.py] => training => Task 2, Epoch 38/170 => Loss 1.032, Train_accy 92.760, Test_accy 64.430
2022-11-28 18:46:07,853 [bic.py] => training => Task 2, Epoch 39/170 => Loss 1.039, Train_accy 92.090, Test_accy 67.030
2022-11-28 18:46:16,318 [bic.py] => training => Task 2, Epoch 40/170 => Loss 1.032, Train_accy 88.760, Test_accy 62.170
2022-11-28 18:46:24,397 [bic.py] => training => Task 2, Epoch 41/170 => Loss 1.041, Train_accy 93.190, Test_accy 65.530
2022-11-28 18:46:32,587 [bic.py] => training => Task 2, Epoch 42/170 => Loss 1.022, Train_accy 94.360, Test_accy 64.230
2022-11-28 18:46:41,272 [bic.py] => training => Task 2, Epoch 43/170 => Loss 1.032, Train_accy 92.250, Test_accy 64.070
2022-11-28 18:46:49,430 [bic.py] => training => Task 2, Epoch 44/170 => Loss 1.030, Train_accy 94.490, Test_accy 65.870
2022-11-28 18:46:58,054 [bic.py] => training => Task 2, Epoch 45/170 => Loss 1.022, Train_accy 91.450, Test_accy 62.270
2022-11-28 18:47:06,495 [bic.py] => training => Task 2, Epoch 46/170 => Loss 1.027, Train_accy 91.430, Test_accy 63.300
2022-11-28 18:47:14,804 [bic.py] => training => Task 2, Epoch 47/170 => Loss 1.022, Train_accy 94.120, Test_accy 65.400
2022-11-28 18:47:22,991 [bic.py] => training => Task 2, Epoch 48/170 => Loss 1.029, Train_accy 90.280, Test_accy 62.400
2022-11-28 18:47:31,549 [bic.py] => training => Task 2, Epoch 49/170 => Loss 1.027, Train_accy 90.880, Test_accy 60.970
2022-11-28 18:47:39,762 [bic.py] => training => Task 2, Epoch 50/170 => Loss 1.021, Train_accy 89.760, Test_accy 60.900
2022-11-28 18:47:48,195 [bic.py] => training => Task 2, Epoch 51/170 => Loss 1.026, Train_accy 92.300, Test_accy 63.800
2022-11-28 18:47:56,392 [bic.py] => training => Task 2, Epoch 52/170 => Loss 1.011, Train_accy 91.730, Test_accy 64.900
2022-11-28 18:48:04,439 [bic.py] => training => Task 2, Epoch 53/170 => Loss 1.018, Train_accy 91.870, Test_accy 63.070
2022-11-28 18:48:12,583 [bic.py] => training => Task 2, Epoch 54/170 => Loss 1.023, Train_accy 92.270, Test_accy 61.100
2022-11-28 18:48:20,877 [bic.py] => training => Task 2, Epoch 55/170 => Loss 1.020, Train_accy 91.960, Test_accy 60.730
2022-11-28 18:48:29,309 [bic.py] => training => Task 2, Epoch 56/170 => Loss 1.019, Train_accy 93.840, Test_accy 63.330
2022-11-28 18:48:36,376 [bic.py] => training => Task 2, Epoch 57/170 => Loss 1.011, Train_accy 92.030, Test_accy 63.500
2022-11-28 18:48:43,639 [bic.py] => training => Task 2, Epoch 58/170 => Loss 1.025, Train_accy 93.190, Test_accy 62.600
2022-11-28 18:48:50,687 [bic.py] => training => Task 2, Epoch 59/170 => Loss 1.021, Train_accy 92.780, Test_accy 63.600
2022-11-28 18:48:58,271 [bic.py] => training => Task 2, Epoch 60/170 => Loss 1.036, Train_accy 91.460, Test_accy 62.670
2022-11-28 18:49:05,608 [bic.py] => training => Task 2, Epoch 61/170 => Loss 0.978, Train_accy 98.720, Test_accy 68.300
2022-11-28 18:49:13,002 [bic.py] => training => Task 2, Epoch 62/170 => Loss 0.947, Train_accy 99.160, Test_accy 68.670
2022-11-28 18:49:20,386 [bic.py] => training => Task 2, Epoch 63/170 => Loss 0.934, Train_accy 98.900, Test_accy 68.930
2022-11-28 18:49:27,773 [bic.py] => training => Task 2, Epoch 64/170 => Loss 0.939, Train_accy 98.990, Test_accy 69.030
2022-11-28 18:49:34,818 [bic.py] => training => Task 2, Epoch 65/170 => Loss 0.934, Train_accy 99.190, Test_accy 69.100
2022-11-28 18:49:42,280 [bic.py] => training => Task 2, Epoch 66/170 => Loss 0.927, Train_accy 99.370, Test_accy 69.200
2022-11-28 18:49:49,319 [bic.py] => training => Task 2, Epoch 67/170 => Loss 0.931, Train_accy 99.480, Test_accy 68.300
2022-11-28 18:49:56,658 [bic.py] => training => Task 2, Epoch 68/170 => Loss 0.927, Train_accy 99.340, Test_accy 69.170
2022-11-28 18:50:03,881 [bic.py] => training => Task 2, Epoch 69/170 => Loss 0.923, Train_accy 99.540, Test_accy 69.170
2022-11-28 18:50:11,274 [bic.py] => training => Task 2, Epoch 70/170 => Loss 0.920, Train_accy 99.370, Test_accy 69.030
2022-11-28 18:50:18,347 [bic.py] => training => Task 2, Epoch 71/170 => Loss 0.924, Train_accy 99.550, Test_accy 69.000
2022-11-28 18:50:25,452 [bic.py] => training => Task 2, Epoch 72/170 => Loss 0.920, Train_accy 99.570, Test_accy 68.970
2022-11-28 18:50:32,142 [bic.py] => training => Task 2, Epoch 73/170 => Loss 0.919, Train_accy 99.540, Test_accy 69.100
2022-11-28 18:50:39,351 [bic.py] => training => Task 2, Epoch 74/170 => Loss 0.920, Train_accy 99.570, Test_accy 68.670
2022-11-28 18:50:46,477 [bic.py] => training => Task 2, Epoch 75/170 => Loss 0.917, Train_accy 99.450, Test_accy 69.400
2022-11-28 18:50:53,993 [bic.py] => training => Task 2, Epoch 76/170 => Loss 0.914, Train_accy 99.630, Test_accy 69.530
2022-11-28 18:51:01,424 [bic.py] => training => Task 2, Epoch 77/170 => Loss 0.917, Train_accy 99.610, Test_accy 69.030
2022-11-28 18:51:08,466 [bic.py] => training => Task 2, Epoch 78/170 => Loss 0.916, Train_accy 99.630, Test_accy 68.900
2022-11-28 18:51:15,714 [bic.py] => training => Task 2, Epoch 79/170 => Loss 0.915, Train_accy 99.690, Test_accy 69.270
2022-11-28 18:51:23,210 [bic.py] => training => Task 2, Epoch 80/170 => Loss 0.918, Train_accy 99.720, Test_accy 69.470
2022-11-28 18:51:30,256 [bic.py] => training => Task 2, Epoch 81/170 => Loss 0.911, Train_accy 99.700, Test_accy 69.070
2022-11-28 18:51:37,394 [bic.py] => training => Task 2, Epoch 82/170 => Loss 0.912, Train_accy 99.700, Test_accy 69.030
2022-11-28 18:51:44,544 [bic.py] => training => Task 2, Epoch 83/170 => Loss 0.910, Train_accy 99.760, Test_accy 69.670
2022-11-28 18:51:51,506 [bic.py] => training => Task 2, Epoch 84/170 => Loss 0.917, Train_accy 99.670, Test_accy 69.300
2022-11-28 18:51:58,824 [bic.py] => training => Task 2, Epoch 85/170 => Loss 0.911, Train_accy 99.810, Test_accy 69.530
2022-11-28 18:52:05,815 [bic.py] => training => Task 2, Epoch 86/170 => Loss 0.912, Train_accy 99.640, Test_accy 69.530
2022-11-28 18:52:13,108 [bic.py] => training => Task 2, Epoch 87/170 => Loss 0.914, Train_accy 99.640, Test_accy 69.600
2022-11-28 18:52:20,312 [bic.py] => training => Task 2, Epoch 88/170 => Loss 0.909, Train_accy 99.730, Test_accy 69.700
2022-11-28 18:52:27,783 [bic.py] => training => Task 2, Epoch 89/170 => Loss 0.909, Train_accy 99.640, Test_accy 69.130
2022-11-28 18:52:34,883 [bic.py] => training => Task 2, Epoch 90/170 => Loss 0.907, Train_accy 99.690, Test_accy 68.630
2022-11-28 18:52:42,392 [bic.py] => training => Task 2, Epoch 91/170 => Loss 0.913, Train_accy 99.700, Test_accy 69.000
2022-11-28 18:52:49,708 [bic.py] => training => Task 2, Epoch 92/170 => Loss 0.909, Train_accy 99.750, Test_accy 69.230
2022-11-28 18:52:57,343 [bic.py] => training => Task 2, Epoch 93/170 => Loss 0.906, Train_accy 99.720, Test_accy 69.300
2022-11-28 18:53:04,703 [bic.py] => training => Task 2, Epoch 94/170 => Loss 0.907, Train_accy 99.760, Test_accy 69.700
2022-11-28 18:53:12,024 [bic.py] => training => Task 2, Epoch 95/170 => Loss 0.914, Train_accy 99.730, Test_accy 69.070
2022-11-28 18:53:19,294 [bic.py] => training => Task 2, Epoch 96/170 => Loss 0.909, Train_accy 99.810, Test_accy 69.030
2022-11-28 18:53:26,826 [bic.py] => training => Task 2, Epoch 97/170 => Loss 0.908, Train_accy 99.760, Test_accy 69.330
2022-11-28 18:53:34,175 [bic.py] => training => Task 2, Epoch 98/170 => Loss 0.906, Train_accy 99.610, Test_accy 69.500
2022-11-28 18:53:41,283 [bic.py] => training => Task 2, Epoch 99/170 => Loss 0.902, Train_accy 99.840, Test_accy 69.470
2022-11-28 18:53:48,751 [bic.py] => training => Task 2, Epoch 100/170 => Loss 0.902, Train_accy 99.780, Test_accy 69.070
2022-11-28 18:53:56,183 [bic.py] => training => Task 2, Epoch 101/170 => Loss 0.907, Train_accy 99.790, Test_accy 69.170
2022-11-28 18:54:03,058 [bic.py] => training => Task 2, Epoch 102/170 => Loss 0.901, Train_accy 99.720, Test_accy 69.330
2022-11-28 18:54:10,066 [bic.py] => training => Task 2, Epoch 103/170 => Loss 0.905, Train_accy 99.780, Test_accy 69.800
2022-11-28 18:54:16,996 [bic.py] => training => Task 2, Epoch 104/170 => Loss 0.902, Train_accy 99.880, Test_accy 69.030
2022-11-28 18:54:24,680 [bic.py] => training => Task 2, Epoch 105/170 => Loss 0.902, Train_accy 99.840, Test_accy 69.230
2022-11-28 18:54:31,819 [bic.py] => training => Task 2, Epoch 106/170 => Loss 0.904, Train_accy 99.820, Test_accy 69.030
2022-11-28 18:54:39,013 [bic.py] => training => Task 2, Epoch 107/170 => Loss 0.903, Train_accy 99.780, Test_accy 69.570
2022-11-28 18:54:46,073 [bic.py] => training => Task 2, Epoch 108/170 => Loss 0.899, Train_accy 99.780, Test_accy 69.030
2022-11-28 18:54:53,260 [bic.py] => training => Task 2, Epoch 109/170 => Loss 0.905, Train_accy 99.870, Test_accy 69.030
2022-11-28 18:55:00,884 [bic.py] => training => Task 2, Epoch 110/170 => Loss 0.898, Train_accy 99.900, Test_accy 69.070
2022-11-28 18:55:08,127 [bic.py] => training => Task 2, Epoch 111/170 => Loss 0.905, Train_accy 99.790, Test_accy 69.030
2022-11-28 18:55:15,361 [bic.py] => training => Task 2, Epoch 112/170 => Loss 0.904, Train_accy 99.790, Test_accy 68.800
2022-11-28 18:55:22,480 [bic.py] => training => Task 2, Epoch 113/170 => Loss 0.900, Train_accy 99.870, Test_accy 69.700
2022-11-28 18:55:29,661 [bic.py] => training => Task 2, Epoch 114/170 => Loss 0.908, Train_accy 99.790, Test_accy 69.970
2022-11-28 18:55:36,625 [bic.py] => training => Task 2, Epoch 115/170 => Loss 0.902, Train_accy 99.820, Test_accy 69.570
2022-11-28 18:55:43,873 [bic.py] => training => Task 2, Epoch 116/170 => Loss 0.901, Train_accy 99.790, Test_accy 69.470
2022-11-28 18:55:51,062 [bic.py] => training => Task 2, Epoch 117/170 => Loss 0.903, Train_accy 99.780, Test_accy 69.170
2022-11-28 18:55:58,768 [bic.py] => training => Task 2, Epoch 118/170 => Loss 0.899, Train_accy 99.870, Test_accy 69.070
2022-11-28 18:56:06,050 [bic.py] => training => Task 2, Epoch 119/170 => Loss 0.906, Train_accy 99.790, Test_accy 68.670
2022-11-28 18:56:13,308 [bic.py] => training => Task 2, Epoch 120/170 => Loss 0.899, Train_accy 99.810, Test_accy 69.130
2022-11-28 18:56:20,241 [bic.py] => training => Task 2, Epoch 121/170 => Loss 0.897, Train_accy 99.790, Test_accy 68.700
2022-11-28 18:56:27,537 [bic.py] => training => Task 2, Epoch 122/170 => Loss 0.901, Train_accy 99.840, Test_accy 69.430
2022-11-28 18:56:34,714 [bic.py] => training => Task 2, Epoch 123/170 => Loss 0.908, Train_accy 99.760, Test_accy 69.570
2022-11-28 18:56:42,063 [bic.py] => training => Task 2, Epoch 124/170 => Loss 0.906, Train_accy 99.810, Test_accy 68.800
2022-11-28 18:56:49,098 [bic.py] => training => Task 2, Epoch 125/170 => Loss 0.904, Train_accy 99.850, Test_accy 69.370
2022-11-28 18:56:56,615 [bic.py] => training => Task 2, Epoch 126/170 => Loss 0.904, Train_accy 99.820, Test_accy 69.070
2022-11-28 18:57:03,729 [bic.py] => training => Task 2, Epoch 127/170 => Loss 0.901, Train_accy 99.810, Test_accy 69.330
2022-11-28 18:57:11,456 [bic.py] => training => Task 2, Epoch 128/170 => Loss 0.905, Train_accy 99.820, Test_accy 69.470
2022-11-28 18:57:18,573 [bic.py] => training => Task 2, Epoch 129/170 => Loss 0.904, Train_accy 99.700, Test_accy 69.100
2022-11-28 18:57:25,914 [bic.py] => training => Task 2, Epoch 130/170 => Loss 0.898, Train_accy 99.850, Test_accy 69.400
2022-11-28 18:57:33,348 [bic.py] => training => Task 2, Epoch 131/170 => Loss 0.901, Train_accy 99.850, Test_accy 68.930
2022-11-28 18:57:40,659 [bic.py] => training => Task 2, Epoch 132/170 => Loss 0.903, Train_accy 99.820, Test_accy 69.570
2022-11-28 18:57:47,641 [bic.py] => training => Task 2, Epoch 133/170 => Loss 0.904, Train_accy 99.900, Test_accy 69.530
2022-11-28 18:57:55,134 [bic.py] => training => Task 2, Epoch 134/170 => Loss 0.901, Train_accy 99.870, Test_accy 69.230
2022-11-28 18:58:02,402 [bic.py] => training => Task 2, Epoch 135/170 => Loss 0.898, Train_accy 99.870, Test_accy 69.400
2022-11-28 18:58:09,829 [bic.py] => training => Task 2, Epoch 136/170 => Loss 0.898, Train_accy 99.810, Test_accy 69.170
2022-11-28 18:58:17,025 [bic.py] => training => Task 2, Epoch 137/170 => Loss 0.900, Train_accy 99.730, Test_accy 69.330
2022-11-28 18:58:24,296 [bic.py] => training => Task 2, Epoch 138/170 => Loss 0.900, Train_accy 99.850, Test_accy 69.270
2022-11-28 18:58:31,815 [bic.py] => training => Task 2, Epoch 139/170 => Loss 0.901, Train_accy 99.880, Test_accy 69.770
2022-11-28 18:58:38,896 [bic.py] => training => Task 2, Epoch 140/170 => Loss 0.898, Train_accy 99.810, Test_accy 68.600
2022-11-28 18:58:46,082 [bic.py] => training => Task 2, Epoch 141/170 => Loss 0.906, Train_accy 99.730, Test_accy 69.100
2022-11-28 18:58:53,488 [bic.py] => training => Task 2, Epoch 142/170 => Loss 0.905, Train_accy 99.900, Test_accy 69.430
2022-11-28 18:59:00,789 [bic.py] => training => Task 2, Epoch 143/170 => Loss 0.902, Train_accy 99.870, Test_accy 68.970
2022-11-28 18:59:08,192 [bic.py] => training => Task 2, Epoch 144/170 => Loss 0.896, Train_accy 99.820, Test_accy 69.270
2022-11-28 18:59:15,420 [bic.py] => training => Task 2, Epoch 145/170 => Loss 0.899, Train_accy 99.900, Test_accy 69.400
2022-11-28 18:59:23,016 [bic.py] => training => Task 2, Epoch 146/170 => Loss 0.899, Train_accy 99.810, Test_accy 69.230
2022-11-28 18:59:30,375 [bic.py] => training => Task 2, Epoch 147/170 => Loss 0.907, Train_accy 99.790, Test_accy 69.230
2022-11-28 18:59:37,802 [bic.py] => training => Task 2, Epoch 148/170 => Loss 0.902, Train_accy 99.870, Test_accy 69.430
2022-11-28 18:59:45,075 [bic.py] => training => Task 2, Epoch 149/170 => Loss 0.898, Train_accy 99.750, Test_accy 69.300
2022-11-28 18:59:52,223 [bic.py] => training => Task 2, Epoch 150/170 => Loss 0.903, Train_accy 99.810, Test_accy 68.970
2022-11-28 18:59:59,742 [bic.py] => training => Task 2, Epoch 151/170 => Loss 0.908, Train_accy 99.850, Test_accy 69.500
2022-11-28 19:00:07,023 [bic.py] => training => Task 2, Epoch 152/170 => Loss 0.901, Train_accy 99.810, Test_accy 69.030
2022-11-28 19:00:14,268 [bic.py] => training => Task 2, Epoch 153/170 => Loss 0.900, Train_accy 99.810, Test_accy 69.370
2022-11-28 19:00:21,491 [bic.py] => training => Task 2, Epoch 154/170 => Loss 0.897, Train_accy 99.810, Test_accy 69.370
2022-11-28 19:00:29,213 [bic.py] => training => Task 2, Epoch 155/170 => Loss 0.901, Train_accy 99.790, Test_accy 68.930
2022-11-28 19:00:36,495 [bic.py] => training => Task 2, Epoch 156/170 => Loss 0.903, Train_accy 99.810, Test_accy 69.270
2022-11-28 19:00:44,279 [bic.py] => training => Task 2, Epoch 157/170 => Loss 0.903, Train_accy 99.760, Test_accy 69.330
2022-11-28 19:00:51,755 [bic.py] => training => Task 2, Epoch 158/170 => Loss 0.905, Train_accy 99.930, Test_accy 69.100
2022-11-28 19:00:59,228 [bic.py] => training => Task 2, Epoch 159/170 => Loss 0.897, Train_accy 99.840, Test_accy 69.570
2022-11-28 19:01:06,666 [bic.py] => training => Task 2, Epoch 160/170 => Loss 0.896, Train_accy 99.880, Test_accy 69.100
2022-11-28 19:01:13,857 [bic.py] => training => Task 2, Epoch 161/170 => Loss 0.898, Train_accy 99.870, Test_accy 69.330
2022-11-28 19:01:21,199 [bic.py] => training => Task 2, Epoch 162/170 => Loss 0.906, Train_accy 99.780, Test_accy 69.000
2022-11-28 19:01:28,522 [bic.py] => training => Task 2, Epoch 163/170 => Loss 0.904, Train_accy 99.840, Test_accy 68.900
2022-11-28 19:01:35,812 [bic.py] => training => Task 2, Epoch 164/170 => Loss 0.893, Train_accy 99.780, Test_accy 69.000
2022-11-28 19:01:42,910 [bic.py] => training => Task 2, Epoch 165/170 => Loss 0.901, Train_accy 99.840, Test_accy 68.730
2022-11-28 19:01:50,108 [bic.py] => training => Task 2, Epoch 166/170 => Loss 0.898, Train_accy 99.840, Test_accy 69.170
2022-11-28 19:01:57,618 [bic.py] => training => Task 2, Epoch 167/170 => Loss 0.901, Train_accy 99.850, Test_accy 69.200
2022-11-28 19:02:05,255 [bic.py] => training => Task 2, Epoch 168/170 => Loss 0.901, Train_accy 99.840, Test_accy 68.770
2022-11-28 19:02:12,545 [bic.py] => training => Task 2, Epoch 169/170 => Loss 0.896, Train_accy 99.810, Test_accy 69.770
2022-11-28 19:02:19,880 [bic.py] => training => Task 2, Epoch 170/170 => Loss 0.908, Train_accy 99.750, Test_accy 68.700
2022-11-28 19:02:23,024 [bic.py] => bias_correction => Task 2, Epoch 1/170 => Loss 2.782, Train_accy 77.330, Test_accy 71.470
2022-11-28 19:02:26,066 [bic.py] => bias_correction => Task 2, Epoch 2/170 => Loss 2.746, Train_accy 80.670, Test_accy 68.730
2022-11-28 19:02:29,051 [bic.py] => bias_correction => Task 2, Epoch 3/170 => Loss 2.768, Train_accy 78.000, Test_accy 67.570
2022-11-28 19:02:32,098 [bic.py] => bias_correction => Task 2, Epoch 4/170 => Loss 2.766, Train_accy 84.000, Test_accy 71.700
2022-11-28 19:02:35,170 [bic.py] => bias_correction => Task 2, Epoch 5/170 => Loss 2.759, Train_accy 78.000, Test_accy 71.370
2022-11-28 19:02:38,312 [bic.py] => bias_correction => Task 2, Epoch 6/170 => Loss 2.766, Train_accy 80.330, Test_accy 71.900
2022-11-28 19:02:41,404 [bic.py] => bias_correction => Task 2, Epoch 7/170 => Loss 2.726, Train_accy 84.000, Test_accy 71.000
2022-11-28 19:02:44,459 [bic.py] => bias_correction => Task 2, Epoch 8/170 => Loss 2.747, Train_accy 81.000, Test_accy 69.170
2022-11-28 19:02:47,503 [bic.py] => bias_correction => Task 2, Epoch 9/170 => Loss 2.746, Train_accy 80.000, Test_accy 71.730
2022-11-28 19:02:50,412 [bic.py] => bias_correction => Task 2, Epoch 10/170 => Loss 2.737, Train_accy 78.000, Test_accy 72.070
2022-11-28 19:02:53,618 [bic.py] => bias_correction => Task 2, Epoch 11/170 => Loss 2.733, Train_accy 79.000, Test_accy 72.200
2022-11-28 19:02:56,653 [bic.py] => bias_correction => Task 2, Epoch 12/170 => Loss 2.760, Train_accy 79.330, Test_accy 71.870
2022-11-28 19:02:59,608 [bic.py] => bias_correction => Task 2, Epoch 13/170 => Loss 2.747, Train_accy 82.330, Test_accy 70.900
2022-11-28 19:03:02,541 [bic.py] => bias_correction => Task 2, Epoch 14/170 => Loss 2.696, Train_accy 79.670, Test_accy 72.070
2022-11-28 19:03:05,651 [bic.py] => bias_correction => Task 2, Epoch 15/170 => Loss 2.735, Train_accy 79.000, Test_accy 72.100
2022-11-28 19:03:08,626 [bic.py] => bias_correction => Task 2, Epoch 16/170 => Loss 2.749, Train_accy 83.000, Test_accy 71.900
2022-11-28 19:03:11,712 [bic.py] => bias_correction => Task 2, Epoch 17/170 => Loss 2.749, Train_accy 81.670, Test_accy 71.430
2022-11-28 19:03:14,745 [bic.py] => bias_correction => Task 2, Epoch 18/170 => Loss 2.758, Train_accy 81.330, Test_accy 72.100
2022-11-28 19:03:17,812 [bic.py] => bias_correction => Task 2, Epoch 19/170 => Loss 2.697, Train_accy 82.330, Test_accy 72.230
2022-11-28 19:03:20,934 [bic.py] => bias_correction => Task 2, Epoch 20/170 => Loss 2.739, Train_accy 79.670, Test_accy 72.300
2022-11-28 19:03:23,924 [bic.py] => bias_correction => Task 2, Epoch 21/170 => Loss 2.732, Train_accy 81.330, Test_accy 71.530
2022-11-28 19:03:27,054 [bic.py] => bias_correction => Task 2, Epoch 22/170 => Loss 2.728, Train_accy 82.330, Test_accy 71.600
2022-11-28 19:03:30,149 [bic.py] => bias_correction => Task 2, Epoch 23/170 => Loss 2.720, Train_accy 78.330, Test_accy 72.130
2022-11-28 19:03:33,137 [bic.py] => bias_correction => Task 2, Epoch 24/170 => Loss 2.731, Train_accy 80.670, Test_accy 72.000
2022-11-28 19:03:35,934 [bic.py] => bias_correction => Task 2, Epoch 25/170 => Loss 2.722, Train_accy 81.000, Test_accy 71.970
2022-11-28 19:03:38,928 [bic.py] => bias_correction => Task 2, Epoch 26/170 => Loss 2.720, Train_accy 81.670, Test_accy 71.630
2022-11-28 19:03:41,780 [bic.py] => bias_correction => Task 2, Epoch 27/170 => Loss 2.722, Train_accy 83.000, Test_accy 72.100
2022-11-28 19:03:44,675 [bic.py] => bias_correction => Task 2, Epoch 28/170 => Loss 2.737, Train_accy 82.670, Test_accy 72.170
2022-11-28 19:03:47,786 [bic.py] => bias_correction => Task 2, Epoch 29/170 => Loss 2.738, Train_accy 81.000, Test_accy 71.770
2022-11-28 19:03:50,889 [bic.py] => bias_correction => Task 2, Epoch 30/170 => Loss 2.728, Train_accy 81.330, Test_accy 72.600
2022-11-28 19:03:53,854 [bic.py] => bias_correction => Task 2, Epoch 31/170 => Loss 2.731, Train_accy 82.670, Test_accy 72.800
2022-11-28 19:03:57,000 [bic.py] => bias_correction => Task 2, Epoch 32/170 => Loss 2.722, Train_accy 82.000, Test_accy 72.570
2022-11-28 19:04:00,140 [bic.py] => bias_correction => Task 2, Epoch 33/170 => Loss 2.738, Train_accy 82.000, Test_accy 72.430
2022-11-28 19:04:03,124 [bic.py] => bias_correction => Task 2, Epoch 34/170 => Loss 2.715, Train_accy 82.330, Test_accy 72.070
2022-11-28 19:04:06,096 [bic.py] => bias_correction => Task 2, Epoch 35/170 => Loss 2.718, Train_accy 81.330, Test_accy 71.630
2022-11-28 19:04:09,215 [bic.py] => bias_correction => Task 2, Epoch 36/170 => Loss 2.744, Train_accy 81.330, Test_accy 72.100
2022-11-28 19:04:12,339 [bic.py] => bias_correction => Task 2, Epoch 37/170 => Loss 2.742, Train_accy 84.000, Test_accy 72.170
2022-11-28 19:04:15,331 [bic.py] => bias_correction => Task 2, Epoch 38/170 => Loss 2.730, Train_accy 80.670, Test_accy 72.070
2022-11-28 19:04:18,306 [bic.py] => bias_correction => Task 2, Epoch 39/170 => Loss 2.724, Train_accy 80.000, Test_accy 71.530
2022-11-28 19:04:21,326 [bic.py] => bias_correction => Task 2, Epoch 40/170 => Loss 2.726, Train_accy 83.670, Test_accy 72.030
2022-11-28 19:04:24,413 [bic.py] => bias_correction => Task 2, Epoch 41/170 => Loss 2.740, Train_accy 80.330, Test_accy 71.730
2022-11-28 19:04:27,521 [bic.py] => bias_correction => Task 2, Epoch 42/170 => Loss 2.720, Train_accy 81.000, Test_accy 72.270
2022-11-28 19:04:30,549 [bic.py] => bias_correction => Task 2, Epoch 43/170 => Loss 2.720, Train_accy 80.000, Test_accy 72.470
2022-11-28 19:04:33,561 [bic.py] => bias_correction => Task 2, Epoch 44/170 => Loss 2.766, Train_accy 81.670, Test_accy 72.400
2022-11-28 19:04:36,586 [bic.py] => bias_correction => Task 2, Epoch 45/170 => Loss 2.722, Train_accy 81.670, Test_accy 71.900
2022-11-28 19:04:39,630 [bic.py] => bias_correction => Task 2, Epoch 46/170 => Loss 2.758, Train_accy 80.000, Test_accy 71.930
2022-11-28 19:04:42,687 [bic.py] => bias_correction => Task 2, Epoch 47/170 => Loss 2.719, Train_accy 83.670, Test_accy 72.130
2022-11-28 19:04:45,628 [bic.py] => bias_correction => Task 2, Epoch 48/170 => Loss 2.731, Train_accy 78.670, Test_accy 72.170
2022-11-28 19:04:48,651 [bic.py] => bias_correction => Task 2, Epoch 49/170 => Loss 2.728, Train_accy 83.670, Test_accy 72.300
2022-11-28 19:04:51,821 [bic.py] => bias_correction => Task 2, Epoch 50/170 => Loss 2.734, Train_accy 80.330, Test_accy 72.500
2022-11-28 19:04:54,895 [bic.py] => bias_correction => Task 2, Epoch 51/170 => Loss 2.722, Train_accy 80.670, Test_accy 71.970
2022-11-28 19:04:57,975 [bic.py] => bias_correction => Task 2, Epoch 52/170 => Loss 2.735, Train_accy 82.000, Test_accy 72.230
2022-11-28 19:05:00,973 [bic.py] => bias_correction => Task 2, Epoch 53/170 => Loss 2.720, Train_accy 81.670, Test_accy 72.400
2022-11-28 19:05:03,893 [bic.py] => bias_correction => Task 2, Epoch 54/170 => Loss 2.719, Train_accy 81.670, Test_accy 72.270
2022-11-28 19:05:06,864 [bic.py] => bias_correction => Task 2, Epoch 55/170 => Loss 2.725, Train_accy 81.000, Test_accy 71.600
2022-11-28 19:05:09,919 [bic.py] => bias_correction => Task 2, Epoch 56/170 => Loss 2.732, Train_accy 81.000, Test_accy 71.170
2022-11-28 19:05:12,891 [bic.py] => bias_correction => Task 2, Epoch 57/170 => Loss 2.721, Train_accy 82.670, Test_accy 72.270
2022-11-28 19:05:15,865 [bic.py] => bias_correction => Task 2, Epoch 58/170 => Loss 2.720, Train_accy 80.670, Test_accy 72.670
2022-11-28 19:05:18,863 [bic.py] => bias_correction => Task 2, Epoch 59/170 => Loss 2.710, Train_accy 82.000, Test_accy 72.600
2022-11-28 19:05:21,830 [bic.py] => bias_correction => Task 2, Epoch 60/170 => Loss 2.726, Train_accy 83.670, Test_accy 72.330
2022-11-28 19:05:24,765 [bic.py] => bias_correction => Task 2, Epoch 61/170 => Loss 2.723, Train_accy 79.330, Test_accy 72.370
2022-11-28 19:05:27,814 [bic.py] => bias_correction => Task 2, Epoch 62/170 => Loss 2.716, Train_accy 81.670, Test_accy 72.630
2022-11-28 19:05:30,837 [bic.py] => bias_correction => Task 2, Epoch 63/170 => Loss 2.733, Train_accy 81.330, Test_accy 72.400
2022-11-28 19:05:33,850 [bic.py] => bias_correction => Task 2, Epoch 64/170 => Loss 2.741, Train_accy 84.330, Test_accy 72.470
2022-11-28 19:05:36,853 [bic.py] => bias_correction => Task 2, Epoch 65/170 => Loss 2.731, Train_accy 81.000, Test_accy 72.600
2022-11-28 19:05:39,830 [bic.py] => bias_correction => Task 2, Epoch 66/170 => Loss 2.729, Train_accy 81.330, Test_accy 72.570
2022-11-28 19:05:42,907 [bic.py] => bias_correction => Task 2, Epoch 67/170 => Loss 2.734, Train_accy 80.330, Test_accy 72.230
2022-11-28 19:05:45,817 [bic.py] => bias_correction => Task 2, Epoch 68/170 => Loss 2.698, Train_accy 80.330, Test_accy 72.400
2022-11-28 19:05:48,809 [bic.py] => bias_correction => Task 2, Epoch 69/170 => Loss 2.751, Train_accy 82.330, Test_accy 72.270
2022-11-28 19:05:51,866 [bic.py] => bias_correction => Task 2, Epoch 70/170 => Loss 2.706, Train_accy 82.000, Test_accy 72.130
2022-11-28 19:05:54,792 [bic.py] => bias_correction => Task 2, Epoch 71/170 => Loss 2.736, Train_accy 81.000, Test_accy 72.230
2022-11-28 19:05:57,652 [bic.py] => bias_correction => Task 2, Epoch 72/170 => Loss 2.727, Train_accy 81.330, Test_accy 72.270
2022-11-28 19:06:00,641 [bic.py] => bias_correction => Task 2, Epoch 73/170 => Loss 2.730, Train_accy 81.670, Test_accy 72.570
2022-11-28 19:06:03,684 [bic.py] => bias_correction => Task 2, Epoch 74/170 => Loss 2.716, Train_accy 82.330, Test_accy 72.100
2022-11-28 19:06:06,660 [bic.py] => bias_correction => Task 2, Epoch 75/170 => Loss 2.740, Train_accy 79.670, Test_accy 71.770
2022-11-28 19:06:09,690 [bic.py] => bias_correction => Task 2, Epoch 76/170 => Loss 2.696, Train_accy 80.330, Test_accy 72.130
2022-11-28 19:06:12,768 [bic.py] => bias_correction => Task 2, Epoch 77/170 => Loss 2.724, Train_accy 82.670, Test_accy 72.470
2022-11-28 19:06:15,774 [bic.py] => bias_correction => Task 2, Epoch 78/170 => Loss 2.712, Train_accy 83.330, Test_accy 72.530
2022-11-28 19:06:18,729 [bic.py] => bias_correction => Task 2, Epoch 79/170 => Loss 2.747, Train_accy 81.000, Test_accy 72.500
2022-11-28 19:06:21,788 [bic.py] => bias_correction => Task 2, Epoch 80/170 => Loss 2.729, Train_accy 81.000, Test_accy 72.300
2022-11-28 19:06:24,691 [bic.py] => bias_correction => Task 2, Epoch 81/170 => Loss 2.705, Train_accy 84.670, Test_accy 72.230
2022-11-28 19:06:27,692 [bic.py] => bias_correction => Task 2, Epoch 82/170 => Loss 2.727, Train_accy 80.330, Test_accy 72.100
2022-11-28 19:06:30,624 [bic.py] => bias_correction => Task 2, Epoch 83/170 => Loss 2.711, Train_accy 81.000, Test_accy 72.470
2022-11-28 19:06:33,658 [bic.py] => bias_correction => Task 2, Epoch 84/170 => Loss 2.721, Train_accy 80.670, Test_accy 72.330
2022-11-28 19:06:36,846 [bic.py] => bias_correction => Task 2, Epoch 85/170 => Loss 2.734, Train_accy 83.000, Test_accy 72.370
2022-11-28 19:06:39,930 [bic.py] => bias_correction => Task 2, Epoch 86/170 => Loss 2.743, Train_accy 83.330, Test_accy 72.170
2022-11-28 19:06:42,856 [bic.py] => bias_correction => Task 2, Epoch 87/170 => Loss 2.724, Train_accy 81.000, Test_accy 72.500
2022-11-28 19:06:45,927 [bic.py] => bias_correction => Task 2, Epoch 88/170 => Loss 2.734, Train_accy 81.670, Test_accy 72.570
2022-11-28 19:06:48,912 [bic.py] => bias_correction => Task 2, Epoch 89/170 => Loss 2.727, Train_accy 84.000, Test_accy 72.600
2022-11-28 19:06:51,875 [bic.py] => bias_correction => Task 2, Epoch 90/170 => Loss 2.741, Train_accy 83.330, Test_accy 72.630
2022-11-28 19:06:54,904 [bic.py] => bias_correction => Task 2, Epoch 91/170 => Loss 2.737, Train_accy 81.670, Test_accy 72.230
2022-11-28 19:06:57,944 [bic.py] => bias_correction => Task 2, Epoch 92/170 => Loss 2.722, Train_accy 80.330, Test_accy 72.130
2022-11-28 19:07:00,897 [bic.py] => bias_correction => Task 2, Epoch 93/170 => Loss 2.729, Train_accy 79.000, Test_accy 72.400
2022-11-28 19:07:03,893 [bic.py] => bias_correction => Task 2, Epoch 94/170 => Loss 2.709, Train_accy 84.000, Test_accy 72.400
2022-11-28 19:07:07,006 [bic.py] => bias_correction => Task 2, Epoch 95/170 => Loss 2.748, Train_accy 82.000, Test_accy 72.370
2022-11-28 19:07:09,916 [bic.py] => bias_correction => Task 2, Epoch 96/170 => Loss 2.727, Train_accy 82.670, Test_accy 72.170
2022-11-28 19:07:12,887 [bic.py] => bias_correction => Task 2, Epoch 97/170 => Loss 2.708, Train_accy 80.670, Test_accy 72.270
2022-11-28 19:07:15,928 [bic.py] => bias_correction => Task 2, Epoch 98/170 => Loss 2.730, Train_accy 81.670, Test_accy 72.470
2022-11-28 19:07:18,902 [bic.py] => bias_correction => Task 2, Epoch 99/170 => Loss 2.713, Train_accy 83.000, Test_accy 72.370
2022-11-28 19:07:21,832 [bic.py] => bias_correction => Task 2, Epoch 100/170 => Loss 2.713, Train_accy 80.330, Test_accy 72.000
2022-11-28 19:07:24,960 [bic.py] => bias_correction => Task 2, Epoch 101/170 => Loss 2.741, Train_accy 79.670, Test_accy 72.030
2022-11-28 19:07:27,954 [bic.py] => bias_correction => Task 2, Epoch 102/170 => Loss 2.714, Train_accy 82.000, Test_accy 71.870
2022-11-28 19:07:30,982 [bic.py] => bias_correction => Task 2, Epoch 103/170 => Loss 2.707, Train_accy 81.670, Test_accy 72.270
2022-11-28 19:07:34,161 [bic.py] => bias_correction => Task 2, Epoch 104/170 => Loss 2.715, Train_accy 81.330, Test_accy 72.030
2022-11-28 19:07:37,144 [bic.py] => bias_correction => Task 2, Epoch 105/170 => Loss 2.716, Train_accy 82.330, Test_accy 71.930
2022-11-28 19:07:40,252 [bic.py] => bias_correction => Task 2, Epoch 106/170 => Loss 2.739, Train_accy 81.000, Test_accy 71.900
2022-11-28 19:07:43,275 [bic.py] => bias_correction => Task 2, Epoch 107/170 => Loss 2.731, Train_accy 84.000, Test_accy 71.770
2022-11-28 19:07:46,398 [bic.py] => bias_correction => Task 2, Epoch 108/170 => Loss 2.733, Train_accy 81.000, Test_accy 72.430
2022-11-28 19:07:49,450 [bic.py] => bias_correction => Task 2, Epoch 109/170 => Loss 2.725, Train_accy 85.000, Test_accy 72.600
2022-11-28 19:07:52,443 [bic.py] => bias_correction => Task 2, Epoch 110/170 => Loss 2.735, Train_accy 81.000, Test_accy 72.400
2022-11-28 19:07:55,480 [bic.py] => bias_correction => Task 2, Epoch 111/170 => Loss 2.704, Train_accy 82.670, Test_accy 72.300
2022-11-28 19:07:58,551 [bic.py] => bias_correction => Task 2, Epoch 112/170 => Loss 2.722, Train_accy 81.330, Test_accy 72.530
2022-11-28 19:08:01,754 [bic.py] => bias_correction => Task 2, Epoch 113/170 => Loss 2.728, Train_accy 81.330, Test_accy 72.200
2022-11-28 19:08:04,638 [bic.py] => bias_correction => Task 2, Epoch 114/170 => Loss 2.716, Train_accy 81.670, Test_accy 72.330
2022-11-28 19:08:07,639 [bic.py] => bias_correction => Task 2, Epoch 115/170 => Loss 2.738, Train_accy 82.330, Test_accy 72.530
2022-11-28 19:08:10,629 [bic.py] => bias_correction => Task 2, Epoch 116/170 => Loss 2.705, Train_accy 79.330, Test_accy 72.330
2022-11-28 19:08:13,737 [bic.py] => bias_correction => Task 2, Epoch 117/170 => Loss 2.710, Train_accy 84.000, Test_accy 72.270
2022-11-28 19:08:16,892 [bic.py] => bias_correction => Task 2, Epoch 118/170 => Loss 2.715, Train_accy 81.670, Test_accy 72.200
2022-11-28 19:08:19,802 [bic.py] => bias_correction => Task 2, Epoch 119/170 => Loss 2.740, Train_accy 81.670, Test_accy 71.770
2022-11-28 19:08:22,965 [bic.py] => bias_correction => Task 2, Epoch 120/170 => Loss 2.723, Train_accy 84.000, Test_accy 72.100
2022-11-28 19:08:26,030 [bic.py] => bias_correction => Task 2, Epoch 121/170 => Loss 2.739, Train_accy 82.670, Test_accy 72.130
2022-11-28 19:08:29,106 [bic.py] => bias_correction => Task 2, Epoch 122/170 => Loss 2.693, Train_accy 84.330, Test_accy 72.400
2022-11-28 19:08:32,061 [bic.py] => bias_correction => Task 2, Epoch 123/170 => Loss 2.719, Train_accy 78.670, Test_accy 72.470
2022-11-28 19:08:35,042 [bic.py] => bias_correction => Task 2, Epoch 124/170 => Loss 2.722, Train_accy 79.330, Test_accy 72.800
2022-11-28 19:08:38,133 [bic.py] => bias_correction => Task 2, Epoch 125/170 => Loss 2.719, Train_accy 80.000, Test_accy 72.300
2022-11-28 19:08:41,080 [bic.py] => bias_correction => Task 2, Epoch 126/170 => Loss 2.705, Train_accy 80.000, Test_accy 72.370
2022-11-28 19:08:43,993 [bic.py] => bias_correction => Task 2, Epoch 127/170 => Loss 2.728, Train_accy 83.000, Test_accy 72.570
2022-11-28 19:08:46,949 [bic.py] => bias_correction => Task 2, Epoch 128/170 => Loss 2.701, Train_accy 84.000, Test_accy 72.500
2022-11-28 19:08:49,989 [bic.py] => bias_correction => Task 2, Epoch 129/170 => Loss 2.723, Train_accy 82.330, Test_accy 72.330
2022-11-28 19:08:53,050 [bic.py] => bias_correction => Task 2, Epoch 130/170 => Loss 2.722, Train_accy 81.000, Test_accy 72.600
2022-11-28 19:08:56,132 [bic.py] => bias_correction => Task 2, Epoch 131/170 => Loss 2.731, Train_accy 82.330, Test_accy 72.730
2022-11-28 19:08:59,220 [bic.py] => bias_correction => Task 2, Epoch 132/170 => Loss 2.711, Train_accy 79.670, Test_accy 72.570
2022-11-28 19:09:02,186 [bic.py] => bias_correction => Task 2, Epoch 133/170 => Loss 2.731, Train_accy 82.670, Test_accy 72.100
2022-11-28 19:09:05,268 [bic.py] => bias_correction => Task 2, Epoch 134/170 => Loss 2.720, Train_accy 81.330, Test_accy 72.400
2022-11-28 19:09:08,306 [bic.py] => bias_correction => Task 2, Epoch 135/170 => Loss 2.730, Train_accy 80.670, Test_accy 72.300
2022-11-28 19:09:11,319 [bic.py] => bias_correction => Task 2, Epoch 136/170 => Loss 2.721, Train_accy 80.000, Test_accy 72.630
2022-11-28 19:09:14,230 [bic.py] => bias_correction => Task 2, Epoch 137/170 => Loss 2.725, Train_accy 81.670, Test_accy 72.470
2022-11-28 19:09:17,254 [bic.py] => bias_correction => Task 2, Epoch 138/170 => Loss 2.737, Train_accy 84.330, Test_accy 72.400
2022-11-28 19:09:20,254 [bic.py] => bias_correction => Task 2, Epoch 139/170 => Loss 2.731, Train_accy 80.000, Test_accy 72.200
2022-11-28 19:09:23,303 [bic.py] => bias_correction => Task 2, Epoch 140/170 => Loss 2.694, Train_accy 83.330, Test_accy 72.670
2022-11-28 19:09:26,453 [bic.py] => bias_correction => Task 2, Epoch 141/170 => Loss 2.730, Train_accy 82.330, Test_accy 72.770
2022-11-28 19:09:29,477 [bic.py] => bias_correction => Task 2, Epoch 142/170 => Loss 2.705, Train_accy 78.670, Test_accy 72.970
2022-11-28 19:09:32,527 [bic.py] => bias_correction => Task 2, Epoch 143/170 => Loss 2.707, Train_accy 80.330, Test_accy 72.670
2022-11-28 19:09:35,651 [bic.py] => bias_correction => Task 2, Epoch 144/170 => Loss 2.688, Train_accy 80.000, Test_accy 72.900
2022-11-28 19:09:38,617 [bic.py] => bias_correction => Task 2, Epoch 145/170 => Loss 2.734, Train_accy 80.330, Test_accy 72.970
2022-11-28 19:09:41,463 [bic.py] => bias_correction => Task 2, Epoch 146/170 => Loss 2.724, Train_accy 82.000, Test_accy 72.670
2022-11-28 19:09:44,550 [bic.py] => bias_correction => Task 2, Epoch 147/170 => Loss 2.724, Train_accy 82.000, Test_accy 72.600
2022-11-28 19:09:47,703 [bic.py] => bias_correction => Task 2, Epoch 148/170 => Loss 2.715, Train_accy 82.000, Test_accy 72.830
2022-11-28 19:09:50,703 [bic.py] => bias_correction => Task 2, Epoch 149/170 => Loss 2.740, Train_accy 81.000, Test_accy 72.870
2022-11-28 19:09:53,723 [bic.py] => bias_correction => Task 2, Epoch 150/170 => Loss 2.714, Train_accy 79.330, Test_accy 72.470
2022-11-28 19:09:56,905 [bic.py] => bias_correction => Task 2, Epoch 151/170 => Loss 2.734, Train_accy 83.000, Test_accy 72.700
2022-11-28 19:09:59,976 [bic.py] => bias_correction => Task 2, Epoch 152/170 => Loss 2.725, Train_accy 81.000, Test_accy 72.530
2022-11-28 19:10:02,912 [bic.py] => bias_correction => Task 2, Epoch 153/170 => Loss 2.729, Train_accy 81.670, Test_accy 72.630
2022-11-28 19:10:05,931 [bic.py] => bias_correction => Task 2, Epoch 154/170 => Loss 2.716, Train_accy 84.000, Test_accy 72.370
2022-11-28 19:10:08,927 [bic.py] => bias_correction => Task 2, Epoch 155/170 => Loss 2.713, Train_accy 85.000, Test_accy 72.270
2022-11-28 19:10:11,900 [bic.py] => bias_correction => Task 2, Epoch 156/170 => Loss 2.728, Train_accy 83.670, Test_accy 72.030
2022-11-28 19:10:14,835 [bic.py] => bias_correction => Task 2, Epoch 157/170 => Loss 2.741, Train_accy 82.000, Test_accy 72.770
2022-11-28 19:10:17,942 [bic.py] => bias_correction => Task 2, Epoch 158/170 => Loss 2.722, Train_accy 82.330, Test_accy 72.400
2022-11-28 19:10:20,939 [bic.py] => bias_correction => Task 2, Epoch 159/170 => Loss 2.726, Train_accy 83.670, Test_accy 72.530
2022-11-28 19:10:23,957 [bic.py] => bias_correction => Task 2, Epoch 160/170 => Loss 2.732, Train_accy 81.670, Test_accy 72.230
2022-11-28 19:10:27,028 [bic.py] => bias_correction => Task 2, Epoch 161/170 => Loss 2.718, Train_accy 80.330, Test_accy 72.270
2022-11-28 19:10:30,143 [bic.py] => bias_correction => Task 2, Epoch 162/170 => Loss 2.721, Train_accy 80.330, Test_accy 72.030
2022-11-28 19:10:33,173 [bic.py] => bias_correction => Task 2, Epoch 163/170 => Loss 2.735, Train_accy 81.670, Test_accy 72.270
2022-11-28 19:10:36,149 [bic.py] => bias_correction => Task 2, Epoch 164/170 => Loss 2.723, Train_accy 81.330, Test_accy 72.430
2022-11-28 19:10:39,250 [bic.py] => bias_correction => Task 2, Epoch 165/170 => Loss 2.715, Train_accy 81.330, Test_accy 72.400
2022-11-28 19:10:42,306 [bic.py] => bias_correction => Task 2, Epoch 166/170 => Loss 2.697, Train_accy 81.000, Test_accy 71.970
2022-11-28 19:10:45,325 [bic.py] => bias_correction => Task 2, Epoch 167/170 => Loss 2.717, Train_accy 81.330, Test_accy 72.100
2022-11-28 19:10:48,321 [bic.py] => bias_correction => Task 2, Epoch 168/170 => Loss 2.731, Train_accy 82.000, Test_accy 72.300
2022-11-28 19:10:51,340 [bic.py] => bias_correction => Task 2, Epoch 169/170 => Loss 2.748, Train_accy 82.670, Test_accy 72.330
2022-11-28 19:10:54,270 [bic.py] => bias_correction => Task 2, Epoch 170/170 => Loss 2.723, Train_accy 83.000, Test_accy 72.300
2022-11-28 19:10:54,271 [base.py] => Reducing exemplars...(66 per classes)
2022-11-28 19:11:02,389 [base.py] => Constructing exemplars...(66 per classes)
2022-11-28 19:11:11,676 [bic.py] => Parameters of bias layer:
2022-11-28 19:11:11,676 [bic.py] => 0 => 1.000, 0.000
2022-11-28 19:11:11,676 [bic.py] => 1 => 0.976, -1.640
2022-11-28 19:11:11,677 [bic.py] => 2 => 0.847, -1.789
2022-11-28 19:11:13,447 [bic.py] => Exemplar size: 1980
2022-11-28 19:11:13,447 [trainer.py] => CNN: {'total': 72.3, '00-09': 76.4, '10-19': 65.5, '20-29': 75.0, 'old': 70.95, 'new': 75.0}
2022-11-28 19:11:13,447 [trainer.py] => NME: {'total': 72.47, '00-09': 75.6, '10-19': 62.6, '20-29': 79.2, 'old': 69.1, 'new': 79.2}
2022-11-28 19:11:13,447 [trainer.py] => CNN top1 curve: [88.7, 75.6, 72.3]
2022-11-28 19:11:13,447 [trainer.py] => CNN top5 curve: [99.4, 95.6, 93.5]
2022-11-28 19:11:13,447 [trainer.py] => NME top1 curve: [88.5, 75.85, 72.47]
2022-11-28 19:11:13,447 [trainer.py] => NME top5 curve: [99.4, 95.95, 93.8]

2022-11-28 19:11:13,448 [trainer.py] => All params: 466110
2022-11-28 19:11:13,448 [trainer.py] => Trainable params: 466110
2022-11-28 19:11:13,449 [bic.py] => Learning on 30-40
2022-11-28 19:11:13,489 [bic.py] => Stage1 dset: 6740, Stage2 dset: 240
2022-11-28 19:11:13,489 [bic.py] => Lambda: 0.750
2022-11-28 19:11:13,497 [bic.py] => Parameters of bias layer:
2022-11-28 19:11:13,498 [bic.py] => 0 => 1.000, 0.000
2022-11-28 19:11:13,498 [bic.py] => 1 => 0.976, -1.640
2022-11-28 19:11:13,498 [bic.py] => 2 => 0.847, -1.789
2022-11-28 19:11:13,498 [bic.py] => 3 => 1.000, 0.000
2022-11-28 19:11:20,817 [bic.py] => training => Task 3, Epoch 1/170 => Loss 1.899, Train_accy 63.460, Test_accy 47.450
2022-11-28 19:11:28,481 [bic.py] => training => Task 3, Epoch 2/170 => Loss 1.659, Train_accy 64.990, Test_accy 46.800
2022-11-28 19:11:35,693 [bic.py] => training => Task 3, Epoch 3/170 => Loss 1.612, Train_accy 72.700, Test_accy 50.400
2022-11-28 19:11:43,170 [bic.py] => training => Task 3, Epoch 4/170 => Loss 1.597, Train_accy 68.090, Test_accy 50.020
2022-11-28 19:11:50,375 [bic.py] => training => Task 3, Epoch 5/170 => Loss 1.574, Train_accy 76.470, Test_accy 52.420
2022-11-28 19:11:58,330 [bic.py] => training => Task 3, Epoch 6/170 => Loss 1.570, Train_accy 76.470, Test_accy 50.920
2022-11-28 19:12:05,538 [bic.py] => training => Task 3, Epoch 7/170 => Loss 1.566, Train_accy 77.080, Test_accy 52.700
2022-11-28 19:12:13,133 [bic.py] => training => Task 3, Epoch 8/170 => Loss 1.556, Train_accy 79.510, Test_accy 54.220
2022-11-28 19:12:20,981 [bic.py] => training => Task 3, Epoch 9/170 => Loss 1.551, Train_accy 78.590, Test_accy 50.320
2022-11-28 19:12:29,021 [bic.py] => training => Task 3, Epoch 10/170 => Loss 1.546, Train_accy 79.870, Test_accy 53.280
2022-11-28 19:12:36,300 [bic.py] => training => Task 3, Epoch 11/170 => Loss 1.533, Train_accy 82.570, Test_accy 51.220
2022-11-28 19:12:43,919 [bic.py] => training => Task 3, Epoch 12/170 => Loss 1.522, Train_accy 81.990, Test_accy 52.720
2022-11-28 19:12:51,315 [bic.py] => training => Task 3, Epoch 13/170 => Loss 1.511, Train_accy 81.440, Test_accy 54.180
2022-11-28 19:12:58,932 [bic.py] => training => Task 3, Epoch 14/170 => Loss 1.519, Train_accy 83.520, Test_accy 57.600
2022-11-28 19:13:06,083 [bic.py] => training => Task 3, Epoch 15/170 => Loss 1.517, Train_accy 81.800, Test_accy 53.200
2022-11-28 19:13:13,774 [bic.py] => training => Task 3, Epoch 16/170 => Loss 1.513, Train_accy 86.570, Test_accy 58.250
2022-11-28 19:13:20,839 [bic.py] => training => Task 3, Epoch 17/170 => Loss 1.514, Train_accy 83.650, Test_accy 51.780
2022-11-28 19:13:28,634 [bic.py] => training => Task 3, Epoch 18/170 => Loss 1.504, Train_accy 87.720, Test_accy 55.020
2022-11-28 19:13:36,153 [bic.py] => training => Task 3, Epoch 19/170 => Loss 1.500, Train_accy 86.680, Test_accy 56.720
2022-11-28 19:13:43,736 [bic.py] => training => Task 3, Epoch 20/170 => Loss 1.504, Train_accy 85.270, Test_accy 56.820
2022-11-28 19:13:51,150 [bic.py] => training => Task 3, Epoch 21/170 => Loss 1.497, Train_accy 84.930, Test_accy 53.700
2022-11-28 19:13:58,874 [bic.py] => training => Task 3, Epoch 22/170 => Loss 1.502, Train_accy 84.580, Test_accy 56.120
2022-11-28 19:14:06,508 [bic.py] => training => Task 3, Epoch 23/170 => Loss 1.498, Train_accy 85.250, Test_accy 54.520
2022-11-28 19:14:13,971 [bic.py] => training => Task 3, Epoch 24/170 => Loss 1.496, Train_accy 87.280, Test_accy 53.620
2022-11-28 19:14:21,290 [bic.py] => training => Task 3, Epoch 25/170 => Loss 1.498, Train_accy 85.850, Test_accy 56.520
2022-11-28 19:14:29,109 [bic.py] => training => Task 3, Epoch 26/170 => Loss 1.494, Train_accy 89.550, Test_accy 56.150
2022-11-28 19:14:36,423 [bic.py] => training => Task 3, Epoch 27/170 => Loss 1.481, Train_accy 88.370, Test_accy 55.220
2022-11-28 19:14:43,761 [bic.py] => training => Task 3, Epoch 28/170 => Loss 1.484, Train_accy 84.140, Test_accy 51.700
2022-11-28 19:14:51,118 [bic.py] => training => Task 3, Epoch 29/170 => Loss 1.482, Train_accy 87.310, Test_accy 52.450
2022-11-28 19:14:59,017 [bic.py] => training => Task 3, Epoch 30/170 => Loss 1.478, Train_accy 84.380, Test_accy 51.780
2022-11-28 19:15:06,527 [bic.py] => training => Task 3, Epoch 31/170 => Loss 1.493, Train_accy 88.660, Test_accy 53.900
2022-11-28 19:15:13,762 [bic.py] => training => Task 3, Epoch 32/170 => Loss 1.490, Train_accy 85.730, Test_accy 55.080
2022-11-28 19:15:21,620 [bic.py] => training => Task 3, Epoch 33/170 => Loss 1.474, Train_accy 89.070, Test_accy 54.320
2022-11-28 19:15:30,080 [bic.py] => training => Task 3, Epoch 34/170 => Loss 1.480, Train_accy 86.590, Test_accy 55.480
2022-11-28 19:15:37,690 [bic.py] => training => Task 3, Epoch 35/170 => Loss 1.479, Train_accy 87.430, Test_accy 55.280
2022-11-28 19:15:45,311 [bic.py] => training => Task 3, Epoch 36/170 => Loss 1.476, Train_accy 89.510, Test_accy 57.180
2022-11-28 19:15:52,961 [bic.py] => training => Task 3, Epoch 37/170 => Loss 1.472, Train_accy 87.630, Test_accy 53.020
2022-11-28 19:16:00,554 [bic.py] => training => Task 3, Epoch 38/170 => Loss 1.470, Train_accy 85.460, Test_accy 52.480
2022-11-28 19:16:08,298 [bic.py] => training => Task 3, Epoch 39/170 => Loss 1.477, Train_accy 86.880, Test_accy 52.700
2022-11-28 19:16:15,476 [bic.py] => training => Task 3, Epoch 40/170 => Loss 1.471, Train_accy 89.670, Test_accy 54.400
2022-11-28 19:16:23,064 [bic.py] => training => Task 3, Epoch 41/170 => Loss 1.475, Train_accy 87.630, Test_accy 55.800
2022-11-28 19:16:30,729 [bic.py] => training => Task 3, Epoch 42/170 => Loss 1.473, Train_accy 89.910, Test_accy 54.280
2022-11-28 19:16:38,015 [bic.py] => training => Task 3, Epoch 43/170 => Loss 1.461, Train_accy 89.970, Test_accy 58.600
2022-11-28 19:16:45,428 [bic.py] => training => Task 3, Epoch 44/170 => Loss 1.459, Train_accy 90.880, Test_accy 55.100
2022-11-28 19:16:53,145 [bic.py] => training => Task 3, Epoch 45/170 => Loss 1.473, Train_accy 87.740, Test_accy 51.580
2022-11-28 19:17:00,714 [bic.py] => training => Task 3, Epoch 46/170 => Loss 1.477, Train_accy 89.540, Test_accy 55.700
2022-11-28 19:17:08,402 [bic.py] => training => Task 3, Epoch 47/170 => Loss 1.457, Train_accy 90.620, Test_accy 58.080
2022-11-28 19:17:16,189 [bic.py] => training => Task 3, Epoch 48/170 => Loss 1.461, Train_accy 86.960, Test_accy 52.500
2022-11-28 19:17:23,889 [bic.py] => training => Task 3, Epoch 49/170 => Loss 1.468, Train_accy 87.490, Test_accy 53.350
2022-11-28 19:17:31,260 [bic.py] => training => Task 3, Epoch 50/170 => Loss 1.470, Train_accy 87.910, Test_accy 53.520
2022-11-28 19:17:38,563 [bic.py] => training => Task 3, Epoch 51/170 => Loss 1.479, Train_accy 89.270, Test_accy 55.100
2022-11-28 19:17:46,338 [bic.py] => training => Task 3, Epoch 52/170 => Loss 1.464, Train_accy 87.050, Test_accy 53.820
2022-11-28 19:17:53,867 [bic.py] => training => Task 3, Epoch 53/170 => Loss 1.464, Train_accy 89.780, Test_accy 56.250
2022-11-28 19:18:01,761 [bic.py] => training => Task 3, Epoch 54/170 => Loss 1.461, Train_accy 86.010, Test_accy 47.420
2022-11-28 19:18:09,215 [bic.py] => training => Task 3, Epoch 55/170 => Loss 1.472, Train_accy 90.330, Test_accy 54.250
2022-11-28 19:18:17,247 [bic.py] => training => Task 3, Epoch 56/170 => Loss 1.462, Train_accy 92.580, Test_accy 59.200
2022-11-28 19:18:24,568 [bic.py] => training => Task 3, Epoch 57/170 => Loss 1.457, Train_accy 88.770, Test_accy 55.300
2022-11-28 19:18:32,000 [bic.py] => training => Task 3, Epoch 58/170 => Loss 1.451, Train_accy 91.720, Test_accy 54.620
2022-11-28 19:18:39,656 [bic.py] => training => Task 3, Epoch 59/170 => Loss 1.456, Train_accy 89.320, Test_accy 57.700
2022-11-28 19:18:46,965 [bic.py] => training => Task 3, Epoch 60/170 => Loss 1.456, Train_accy 90.470, Test_accy 52.500
2022-11-28 19:18:54,364 [bic.py] => training => Task 3, Epoch 61/170 => Loss 1.415, Train_accy 98.190, Test_accy 60.220
2022-11-28 19:19:02,119 [bic.py] => training => Task 3, Epoch 62/170 => Loss 1.389, Train_accy 98.410, Test_accy 60.480
2022-11-28 19:19:09,640 [bic.py] => training => Task 3, Epoch 63/170 => Loss 1.385, Train_accy 98.690, Test_accy 60.750
2022-11-28 19:19:17,083 [bic.py] => training => Task 3, Epoch 64/170 => Loss 1.386, Train_accy 98.960, Test_accy 60.780
2022-11-28 19:19:24,598 [bic.py] => training => Task 3, Epoch 65/170 => Loss 1.379, Train_accy 98.810, Test_accy 61.200
2022-11-28 19:19:32,200 [bic.py] => training => Task 3, Epoch 66/170 => Loss 1.374, Train_accy 98.870, Test_accy 61.650
2022-11-28 19:19:39,573 [bic.py] => training => Task 3, Epoch 67/170 => Loss 1.377, Train_accy 98.930, Test_accy 61.150
2022-11-28 19:19:47,183 [bic.py] => training => Task 3, Epoch 68/170 => Loss 1.368, Train_accy 99.040, Test_accy 61.220
2022-11-28 19:19:54,977 [bic.py] => training => Task 3, Epoch 69/170 => Loss 1.374, Train_accy 99.210, Test_accy 60.950
2022-11-28 19:20:02,618 [bic.py] => training => Task 3, Epoch 70/170 => Loss 1.372, Train_accy 99.270, Test_accy 61.500
2022-11-28 19:20:10,378 [bic.py] => training => Task 3, Epoch 71/170 => Loss 1.373, Train_accy 99.230, Test_accy 61.920
2022-11-28 19:20:18,090 [bic.py] => training => Task 3, Epoch 72/170 => Loss 1.367, Train_accy 99.230, Test_accy 60.720
2022-11-28 19:20:25,351 [bic.py] => training => Task 3, Epoch 73/170 => Loss 1.370, Train_accy 99.260, Test_accy 60.200
2022-11-28 19:20:32,762 [bic.py] => training => Task 3, Epoch 74/170 => Loss 1.370, Train_accy 99.500, Test_accy 60.650
2022-11-28 19:20:40,346 [bic.py] => training => Task 3, Epoch 75/170 => Loss 1.365, Train_accy 99.390, Test_accy 60.780
2022-11-28 19:20:48,034 [bic.py] => training => Task 3, Epoch 76/170 => Loss 1.363, Train_accy 99.330, Test_accy 61.900
2022-11-28 19:20:55,872 [bic.py] => training => Task 3, Epoch 77/170 => Loss 1.369, Train_accy 99.300, Test_accy 61.700
2022-11-28 19:21:03,862 [bic.py] => training => Task 3, Epoch 78/170 => Loss 1.361, Train_accy 99.440, Test_accy 61.180
2022-11-28 19:21:11,774 [bic.py] => training => Task 3, Epoch 79/170 => Loss 1.364, Train_accy 99.410, Test_accy 61.300
2022-11-28 19:21:19,303 [bic.py] => training => Task 3, Epoch 80/170 => Loss 1.365, Train_accy 99.330, Test_accy 61.500
2022-11-28 19:21:27,245 [bic.py] => training => Task 3, Epoch 81/170 => Loss 1.367, Train_accy 99.440, Test_accy 60.820
2022-11-28 19:21:34,887 [bic.py] => training => Task 3, Epoch 82/170 => Loss 1.366, Train_accy 99.510, Test_accy 60.620
2022-11-28 19:21:42,706 [bic.py] => training => Task 3, Epoch 83/170 => Loss 1.362, Train_accy 99.530, Test_accy 61.720
2022-11-28 19:21:50,104 [bic.py] => training => Task 3, Epoch 84/170 => Loss 1.360, Train_accy 99.380, Test_accy 61.620
2022-11-28 19:21:58,224 [bic.py] => training => Task 3, Epoch 85/170 => Loss 1.365, Train_accy 99.380, Test_accy 61.080
2022-11-28 19:22:06,058 [bic.py] => training => Task 3, Epoch 86/170 => Loss 1.357, Train_accy 99.540, Test_accy 60.950
2022-11-28 19:22:13,456 [bic.py] => training => Task 3, Epoch 87/170 => Loss 1.363, Train_accy 99.510, Test_accy 61.050
2022-11-28 19:22:21,056 [bic.py] => training => Task 3, Epoch 88/170 => Loss 1.357, Train_accy 99.480, Test_accy 61.620
2022-11-28 19:22:28,997 [bic.py] => training => Task 3, Epoch 89/170 => Loss 1.355, Train_accy 99.610, Test_accy 61.720
2022-11-28 19:22:36,675 [bic.py] => training => Task 3, Epoch 90/170 => Loss 1.359, Train_accy 99.440, Test_accy 61.920
2022-11-28 19:22:44,109 [bic.py] => training => Task 3, Epoch 91/170 => Loss 1.355, Train_accy 99.510, Test_accy 61.700
2022-11-28 19:22:51,896 [bic.py] => training => Task 3, Epoch 92/170 => Loss 1.361, Train_accy 99.570, Test_accy 61.250
2022-11-28 19:22:59,756 [bic.py] => training => Task 3, Epoch 93/170 => Loss 1.358, Train_accy 99.500, Test_accy 61.780
2022-11-28 19:23:07,154 [bic.py] => training => Task 3, Epoch 94/170 => Loss 1.352, Train_accy 99.480, Test_accy 61.720
2022-11-28 19:23:14,710 [bic.py] => training => Task 3, Epoch 95/170 => Loss 1.357, Train_accy 99.550, Test_accy 61.480
2022-11-28 19:23:21,909 [bic.py] => training => Task 3, Epoch 96/170 => Loss 1.353, Train_accy 99.670, Test_accy 61.500
2022-11-28 19:23:29,519 [bic.py] => training => Task 3, Epoch 97/170 => Loss 1.357, Train_accy 99.690, Test_accy 61.220
2022-11-28 19:23:37,147 [bic.py] => training => Task 3, Epoch 98/170 => Loss 1.356, Train_accy 99.630, Test_accy 61.680
2022-11-28 19:23:44,651 [bic.py] => training => Task 3, Epoch 99/170 => Loss 1.354, Train_accy 99.600, Test_accy 61.300
2022-11-28 19:23:52,349 [bic.py] => training => Task 3, Epoch 100/170 => Loss 1.353, Train_accy 99.470, Test_accy 61.520
2022-11-28 19:23:59,947 [bic.py] => training => Task 3, Epoch 101/170 => Loss 1.355, Train_accy 99.670, Test_accy 61.420
2022-11-28 19:24:07,663 [bic.py] => training => Task 3, Epoch 102/170 => Loss 1.354, Train_accy 99.640, Test_accy 61.550
2022-11-28 19:24:15,403 [bic.py] => training => Task 3, Epoch 103/170 => Loss 1.353, Train_accy 99.570, Test_accy 61.500
2022-11-28 19:24:22,754 [bic.py] => training => Task 3, Epoch 104/170 => Loss 1.352, Train_accy 99.730, Test_accy 61.520
2022-11-28 19:24:30,012 [bic.py] => training => Task 3, Epoch 105/170 => Loss 1.354, Train_accy 99.660, Test_accy 61.550
2022-11-28 19:24:37,210 [bic.py] => training => Task 3, Epoch 106/170 => Loss 1.356, Train_accy 99.750, Test_accy 61.600
2022-11-28 19:24:44,914 [bic.py] => training => Task 3, Epoch 107/170 => Loss 1.351, Train_accy 99.610, Test_accy 61.300
2022-11-28 19:24:52,553 [bic.py] => training => Task 3, Epoch 108/170 => Loss 1.350, Train_accy 99.700, Test_accy 61.380
2022-11-28 19:25:00,049 [bic.py] => training => Task 3, Epoch 109/170 => Loss 1.351, Train_accy 99.750, Test_accy 61.820
2022-11-28 19:25:07,324 [bic.py] => training => Task 3, Epoch 110/170 => Loss 1.357, Train_accy 99.630, Test_accy 61.620
2022-11-28 19:25:14,981 [bic.py] => training => Task 3, Epoch 111/170 => Loss 1.352, Train_accy 99.540, Test_accy 61.400
2022-11-28 19:25:22,957 [bic.py] => training => Task 3, Epoch 112/170 => Loss 1.349, Train_accy 99.700, Test_accy 61.550
2022-11-28 19:25:30,378 [bic.py] => training => Task 3, Epoch 113/170 => Loss 1.355, Train_accy 99.580, Test_accy 61.300
2022-11-28 19:25:38,012 [bic.py] => training => Task 3, Epoch 114/170 => Loss 1.346, Train_accy 99.510, Test_accy 61.720
2022-11-28 19:25:45,187 [bic.py] => training => Task 3, Epoch 115/170 => Loss 1.352, Train_accy 99.690, Test_accy 61.880
2022-11-28 19:25:52,989 [bic.py] => training => Task 3, Epoch 116/170 => Loss 1.350, Train_accy 99.580, Test_accy 61.650
2022-11-28 19:26:00,567 [bic.py] => training => Task 3, Epoch 117/170 => Loss 1.355, Train_accy 99.630, Test_accy 61.920
2022-11-28 19:26:08,499 [bic.py] => training => Task 3, Epoch 118/170 => Loss 1.350, Train_accy 99.550, Test_accy 61.680
2022-11-28 19:26:15,703 [bic.py] => training => Task 3, Epoch 119/170 => Loss 1.352, Train_accy 99.600, Test_accy 61.550
2022-11-28 19:26:23,369 [bic.py] => training => Task 3, Epoch 120/170 => Loss 1.352, Train_accy 99.580, Test_accy 61.300
2022-11-28 19:26:30,811 [bic.py] => training => Task 3, Epoch 121/170 => Loss 1.351, Train_accy 99.550, Test_accy 61.600
2022-11-28 19:26:37,927 [bic.py] => training => Task 3, Epoch 122/170 => Loss 1.358, Train_accy 99.670, Test_accy 61.450
2022-11-28 19:26:45,443 [bic.py] => training => Task 3, Epoch 123/170 => Loss 1.353, Train_accy 99.630, Test_accy 61.750
2022-11-28 19:26:53,106 [bic.py] => training => Task 3, Epoch 124/170 => Loss 1.352, Train_accy 99.610, Test_accy 61.820
2022-11-28 19:27:00,661 [bic.py] => training => Task 3, Epoch 125/170 => Loss 1.353, Train_accy 99.730, Test_accy 61.700
2022-11-28 19:27:08,312 [bic.py] => training => Task 3, Epoch 126/170 => Loss 1.349, Train_accy 99.640, Test_accy 61.450
2022-11-28 19:27:16,163 [bic.py] => training => Task 3, Epoch 127/170 => Loss 1.352, Train_accy 99.750, Test_accy 61.550
2022-11-28 19:27:23,384 [bic.py] => training => Task 3, Epoch 128/170 => Loss 1.353, Train_accy 99.550, Test_accy 61.650
2022-11-28 19:27:31,008 [bic.py] => training => Task 3, Epoch 129/170 => Loss 1.350, Train_accy 99.630, Test_accy 61.800
2022-11-28 19:27:38,715 [bic.py] => training => Task 3, Epoch 130/170 => Loss 1.353, Train_accy 99.760, Test_accy 61.320
2022-11-28 19:27:45,991 [bic.py] => training => Task 3, Epoch 131/170 => Loss 1.355, Train_accy 99.640, Test_accy 61.800
2022-11-28 19:27:53,425 [bic.py] => training => Task 3, Epoch 132/170 => Loss 1.340, Train_accy 99.610, Test_accy 61.920
2022-11-28 19:28:01,196 [bic.py] => training => Task 3, Epoch 133/170 => Loss 1.351, Train_accy 99.700, Test_accy 61.850
2022-11-28 19:28:08,672 [bic.py] => training => Task 3, Epoch 134/170 => Loss 1.352, Train_accy 99.670, Test_accy 61.520
2022-11-28 19:28:16,200 [bic.py] => training => Task 3, Epoch 135/170 => Loss 1.354, Train_accy 99.760, Test_accy 61.700
2022-11-28 19:28:23,867 [bic.py] => training => Task 3, Epoch 136/170 => Loss 1.355, Train_accy 99.700, Test_accy 61.450
2022-11-28 19:28:31,311 [bic.py] => training => Task 3, Epoch 137/170 => Loss 1.346, Train_accy 99.700, Test_accy 61.980
2022-11-28 19:28:38,883 [bic.py] => training => Task 3, Epoch 138/170 => Loss 1.354, Train_accy 99.640, Test_accy 61.920
2022-11-28 19:28:46,122 [bic.py] => training => Task 3, Epoch 139/170 => Loss 1.355, Train_accy 99.780, Test_accy 61.820
2022-11-28 19:28:53,872 [bic.py] => training => Task 3, Epoch 140/170 => Loss 1.353, Train_accy 99.670, Test_accy 61.620
2022-11-28 19:29:01,446 [bic.py] => training => Task 3, Epoch 141/170 => Loss 1.350, Train_accy 99.750, Test_accy 61.980
2022-11-28 19:29:09,234 [bic.py] => training => Task 3, Epoch 142/170 => Loss 1.353, Train_accy 99.600, Test_accy 61.380
2022-11-28 19:29:16,595 [bic.py] => training => Task 3, Epoch 143/170 => Loss 1.347, Train_accy 99.670, Test_accy 62.300
2022-11-28 19:29:24,213 [bic.py] => training => Task 3, Epoch 144/170 => Loss 1.357, Train_accy 99.810, Test_accy 61.820
2022-11-28 19:29:31,956 [bic.py] => training => Task 3, Epoch 145/170 => Loss 1.351, Train_accy 99.580, Test_accy 61.980
2022-11-28 19:29:39,478 [bic.py] => training => Task 3, Epoch 146/170 => Loss 1.354, Train_accy 99.600, Test_accy 62.080
2022-11-28 19:29:46,979 [bic.py] => training => Task 3, Epoch 147/170 => Loss 1.352, Train_accy 99.610, Test_accy 61.550
2022-11-28 19:29:54,682 [bic.py] => training => Task 3, Epoch 148/170 => Loss 1.351, Train_accy 99.690, Test_accy 61.820
2022-11-28 19:30:02,024 [bic.py] => training => Task 3, Epoch 149/170 => Loss 1.352, Train_accy 99.700, Test_accy 61.620
2022-11-28 19:30:09,460 [bic.py] => training => Task 3, Epoch 150/170 => Loss 1.357, Train_accy 99.810, Test_accy 62.080
2022-11-28 19:30:16,868 [bic.py] => training => Task 3, Epoch 151/170 => Loss 1.347, Train_accy 99.690, Test_accy 61.820
2022-11-28 19:30:24,847 [bic.py] => training => Task 3, Epoch 152/170 => Loss 1.354, Train_accy 99.690, Test_accy 61.850
2022-11-28 19:30:32,524 [bic.py] => training => Task 3, Epoch 153/170 => Loss 1.357, Train_accy 99.780, Test_accy 61.950
2022-11-28 19:30:40,304 [bic.py] => training => Task 3, Epoch 154/170 => Loss 1.348, Train_accy 99.780, Test_accy 61.620
2022-11-28 19:30:47,531 [bic.py] => training => Task 3, Epoch 155/170 => Loss 1.353, Train_accy 99.660, Test_accy 62.380
2022-11-28 19:30:54,986 [bic.py] => training => Task 3, Epoch 156/170 => Loss 1.350, Train_accy 99.670, Test_accy 62.050
2022-11-28 19:31:02,646 [bic.py] => training => Task 3, Epoch 157/170 => Loss 1.353, Train_accy 99.660, Test_accy 62.020
2022-11-28 19:31:10,213 [bic.py] => training => Task 3, Epoch 158/170 => Loss 1.352, Train_accy 99.570, Test_accy 61.750
2022-11-28 19:31:17,883 [bic.py] => training => Task 3, Epoch 159/170 => Loss 1.352, Train_accy 99.690, Test_accy 61.750
2022-11-28 19:31:25,377 [bic.py] => training => Task 3, Epoch 160/170 => Loss 1.347, Train_accy 99.670, Test_accy 62.100
2022-11-28 19:31:32,905 [bic.py] => training => Task 3, Epoch 161/170 => Loss 1.353, Train_accy 99.730, Test_accy 61.850
2022-11-28 19:31:40,126 [bic.py] => training => Task 3, Epoch 162/170 => Loss 1.348, Train_accy 99.640, Test_accy 61.880
2022-11-28 19:31:47,424 [bic.py] => training => Task 3, Epoch 163/170 => Loss 1.348, Train_accy 99.760, Test_accy 61.780
2022-11-28 19:31:54,773 [bic.py] => training => Task 3, Epoch 164/170 => Loss 1.352, Train_accy 99.630, Test_accy 61.750
2022-11-28 19:32:02,079 [bic.py] => training => Task 3, Epoch 165/170 => Loss 1.358, Train_accy 99.580, Test_accy 62.280
2022-11-28 19:32:09,834 [bic.py] => training => Task 3, Epoch 166/170 => Loss 1.349, Train_accy 99.820, Test_accy 61.550
2022-11-28 19:32:17,571 [bic.py] => training => Task 3, Epoch 167/170 => Loss 1.351, Train_accy 99.660, Test_accy 62.100
2022-11-28 19:32:24,986 [bic.py] => training => Task 3, Epoch 168/170 => Loss 1.350, Train_accy 99.670, Test_accy 61.800
2022-11-28 19:32:32,483 [bic.py] => training => Task 3, Epoch 169/170 => Loss 1.351, Train_accy 99.630, Test_accy 61.600
2022-11-28 19:32:40,173 [bic.py] => training => Task 3, Epoch 170/170 => Loss 1.350, Train_accy 99.720, Test_accy 61.420
2022-11-28 19:32:43,296 [bic.py] => bias_correction => Task 3, Epoch 1/170 => Loss 3.162, Train_accy 68.750, Test_accy 64.250
2022-11-28 19:32:46,518 [bic.py] => bias_correction => Task 3, Epoch 2/170 => Loss 3.099, Train_accy 79.170, Test_accy 67.120
2022-11-28 19:32:49,620 [bic.py] => bias_correction => Task 3, Epoch 3/170 => Loss 3.060, Train_accy 75.830, Test_accy 62.400
2022-11-28 19:32:52,827 [bic.py] => bias_correction => Task 3, Epoch 4/170 => Loss 3.112, Train_accy 75.000, Test_accy 57.750
2022-11-28 19:32:56,060 [bic.py] => bias_correction => Task 3, Epoch 5/170 => Loss 3.089, Train_accy 73.330, Test_accy 58.620
2022-11-28 19:32:59,250 [bic.py] => bias_correction => Task 3, Epoch 6/170 => Loss 3.091, Train_accy 80.420, Test_accy 64.050
2022-11-28 19:33:02,435 [bic.py] => bias_correction => Task 3, Epoch 7/170 => Loss 3.074, Train_accy 77.080, Test_accy 66.880
2022-11-28 19:33:05,513 [bic.py] => bias_correction => Task 3, Epoch 8/170 => Loss 3.063, Train_accy 74.170, Test_accy 66.420
2022-11-28 19:33:08,822 [bic.py] => bias_correction => Task 3, Epoch 9/170 => Loss 3.064, Train_accy 75.830, Test_accy 66.650
2022-11-28 19:33:12,133 [bic.py] => bias_correction => Task 3, Epoch 10/170 => Loss 3.057, Train_accy 80.000, Test_accy 66.620
2022-11-28 19:33:15,218 [bic.py] => bias_correction => Task 3, Epoch 11/170 => Loss 3.039, Train_accy 81.670, Test_accy 65.600
2022-11-28 19:33:18,395 [bic.py] => bias_correction => Task 3, Epoch 12/170 => Loss 3.062, Train_accy 78.750, Test_accy 64.820
2022-11-28 19:33:21,680 [bic.py] => bias_correction => Task 3, Epoch 13/170 => Loss 3.056, Train_accy 81.670, Test_accy 65.220
2022-11-28 19:33:24,940 [bic.py] => bias_correction => Task 3, Epoch 14/170 => Loss 3.074, Train_accy 83.330, Test_accy 66.300
2022-11-28 19:33:28,096 [bic.py] => bias_correction => Task 3, Epoch 15/170 => Loss 3.055, Train_accy 78.750, Test_accy 66.950
2022-11-28 19:33:31,415 [bic.py] => bias_correction => Task 3, Epoch 16/170 => Loss 3.047, Train_accy 80.420, Test_accy 66.820
2022-11-28 19:33:34,547 [bic.py] => bias_correction => Task 3, Epoch 17/170 => Loss 3.057, Train_accy 83.330, Test_accy 66.800
2022-11-28 19:33:37,648 [bic.py] => bias_correction => Task 3, Epoch 18/170 => Loss 3.056, Train_accy 77.080, Test_accy 66.600
2022-11-28 19:33:40,715 [bic.py] => bias_correction => Task 3, Epoch 19/170 => Loss 3.060, Train_accy 79.580, Test_accy 65.750
2022-11-28 19:33:43,912 [bic.py] => bias_correction => Task 3, Epoch 20/170 => Loss 3.047, Train_accy 81.250, Test_accy 65.650
2022-11-28 19:33:47,064 [bic.py] => bias_correction => Task 3, Epoch 21/170 => Loss 3.052, Train_accy 79.170, Test_accy 66.180
2022-11-28 19:33:50,236 [bic.py] => bias_correction => Task 3, Epoch 22/170 => Loss 3.046, Train_accy 81.250, Test_accy 66.600
2022-11-28 19:33:53,407 [bic.py] => bias_correction => Task 3, Epoch 23/170 => Loss 3.050, Train_accy 76.670, Test_accy 66.700
2022-11-28 19:33:56,686 [bic.py] => bias_correction => Task 3, Epoch 24/170 => Loss 3.055, Train_accy 81.670, Test_accy 66.720
2022-11-28 19:33:59,735 [bic.py] => bias_correction => Task 3, Epoch 25/170 => Loss 3.045, Train_accy 79.170, Test_accy 66.650
2022-11-28 19:34:02,978 [bic.py] => bias_correction => Task 3, Epoch 26/170 => Loss 3.055, Train_accy 79.580, Test_accy 66.030
2022-11-28 19:34:06,106 [bic.py] => bias_correction => Task 3, Epoch 27/170 => Loss 3.028, Train_accy 79.580, Test_accy 65.880
2022-11-28 19:34:09,361 [bic.py] => bias_correction => Task 3, Epoch 28/170 => Loss 3.055, Train_accy 79.170, Test_accy 66.400
2022-11-28 19:34:12,579 [bic.py] => bias_correction => Task 3, Epoch 29/170 => Loss 3.052, Train_accy 81.670, Test_accy 66.780
2022-11-28 19:34:15,676 [bic.py] => bias_correction => Task 3, Epoch 30/170 => Loss 3.052, Train_accy 78.750, Test_accy 66.650
2022-11-28 19:34:18,761 [bic.py] => bias_correction => Task 3, Epoch 31/170 => Loss 3.034, Train_accy 81.250, Test_accy 66.720
2022-11-28 19:34:22,023 [bic.py] => bias_correction => Task 3, Epoch 32/170 => Loss 3.059, Train_accy 78.330, Test_accy 67.050
2022-11-28 19:34:25,178 [bic.py] => bias_correction => Task 3, Epoch 33/170 => Loss 3.046, Train_accy 82.080, Test_accy 67.050
2022-11-28 19:34:28,304 [bic.py] => bias_correction => Task 3, Epoch 34/170 => Loss 3.056, Train_accy 80.420, Test_accy 66.200
2022-11-28 19:34:31,495 [bic.py] => bias_correction => Task 3, Epoch 35/170 => Loss 3.066, Train_accy 80.420, Test_accy 66.100
2022-11-28 19:34:34,603 [bic.py] => bias_correction => Task 3, Epoch 36/170 => Loss 3.041, Train_accy 78.750, Test_accy 66.080
2022-11-28 19:34:37,888 [bic.py] => bias_correction => Task 3, Epoch 37/170 => Loss 3.042, Train_accy 76.250, Test_accy 66.650
2022-11-28 19:34:41,017 [bic.py] => bias_correction => Task 3, Epoch 38/170 => Loss 3.025, Train_accy 79.580, Test_accy 66.950
2022-11-28 19:34:44,215 [bic.py] => bias_correction => Task 3, Epoch 39/170 => Loss 3.048, Train_accy 80.000, Test_accy 66.970
2022-11-28 19:34:47,273 [bic.py] => bias_correction => Task 3, Epoch 40/170 => Loss 3.036, Train_accy 78.750, Test_accy 66.600
2022-11-28 19:34:50,364 [bic.py] => bias_correction => Task 3, Epoch 41/170 => Loss 3.042, Train_accy 79.170, Test_accy 66.680
2022-11-28 19:34:53,483 [bic.py] => bias_correction => Task 3, Epoch 42/170 => Loss 3.045, Train_accy 81.670, Test_accy 66.280
2022-11-28 19:34:56,665 [bic.py] => bias_correction => Task 3, Epoch 43/170 => Loss 3.057, Train_accy 79.580, Test_accy 66.420
2022-11-28 19:34:59,829 [bic.py] => bias_correction => Task 3, Epoch 44/170 => Loss 3.047, Train_accy 78.330, Test_accy 66.600
2022-11-28 19:35:03,098 [bic.py] => bias_correction => Task 3, Epoch 45/170 => Loss 3.046, Train_accy 81.250, Test_accy 66.750
2022-11-28 19:35:06,261 [bic.py] => bias_correction => Task 3, Epoch 46/170 => Loss 3.040, Train_accy 78.750, Test_accy 66.820
2022-11-28 19:35:09,300 [bic.py] => bias_correction => Task 3, Epoch 47/170 => Loss 3.050, Train_accy 78.750, Test_accy 66.620
2022-11-28 19:35:12,542 [bic.py] => bias_correction => Task 3, Epoch 48/170 => Loss 3.052, Train_accy 80.420, Test_accy 66.470
2022-11-28 19:35:15,709 [bic.py] => bias_correction => Task 3, Epoch 49/170 => Loss 3.037, Train_accy 81.670, Test_accy 66.680
2022-11-28 19:35:18,930 [bic.py] => bias_correction => Task 3, Epoch 50/170 => Loss 3.050, Train_accy 82.080, Test_accy 66.470
2022-11-28 19:35:22,056 [bic.py] => bias_correction => Task 3, Epoch 51/170 => Loss 3.051, Train_accy 81.250, Test_accy 66.920
2022-11-28 19:35:25,229 [bic.py] => bias_correction => Task 3, Epoch 52/170 => Loss 3.043, Train_accy 78.750, Test_accy 67.050
2022-11-28 19:35:28,390 [bic.py] => bias_correction => Task 3, Epoch 53/170 => Loss 3.048, Train_accy 79.170, Test_accy 66.950
2022-11-28 19:35:31,455 [bic.py] => bias_correction => Task 3, Epoch 54/170 => Loss 3.051, Train_accy 80.830, Test_accy 66.750
2022-11-28 19:35:34,692 [bic.py] => bias_correction => Task 3, Epoch 55/170 => Loss 3.041, Train_accy 80.420, Test_accy 66.500
2022-11-28 19:35:37,860 [bic.py] => bias_correction => Task 3, Epoch 56/170 => Loss 3.052, Train_accy 80.830, Test_accy 66.100
2022-11-28 19:35:41,041 [bic.py] => bias_correction => Task 3, Epoch 57/170 => Loss 3.040, Train_accy 81.670, Test_accy 66.650
2022-11-28 19:35:44,289 [bic.py] => bias_correction => Task 3, Epoch 58/170 => Loss 3.037, Train_accy 80.830, Test_accy 66.680
2022-11-28 19:35:47,470 [bic.py] => bias_correction => Task 3, Epoch 59/170 => Loss 3.059, Train_accy 78.750, Test_accy 66.970
2022-11-28 19:35:50,674 [bic.py] => bias_correction => Task 3, Epoch 60/170 => Loss 3.049, Train_accy 80.000, Test_accy 66.720
2022-11-28 19:35:53,934 [bic.py] => bias_correction => Task 3, Epoch 61/170 => Loss 3.049, Train_accy 80.000, Test_accy 66.620
2022-11-28 19:35:57,088 [bic.py] => bias_correction => Task 3, Epoch 62/170 => Loss 3.063, Train_accy 80.000, Test_accy 66.550
2022-11-28 19:36:00,201 [bic.py] => bias_correction => Task 3, Epoch 63/170 => Loss 3.053, Train_accy 79.580, Test_accy 66.580
2022-11-28 19:36:03,430 [bic.py] => bias_correction => Task 3, Epoch 64/170 => Loss 3.035, Train_accy 77.080, Test_accy 66.450
2022-11-28 19:36:06,611 [bic.py] => bias_correction => Task 3, Epoch 65/170 => Loss 3.053, Train_accy 81.250, Test_accy 66.450
2022-11-28 19:36:09,867 [bic.py] => bias_correction => Task 3, Epoch 66/170 => Loss 3.042, Train_accy 80.830, Test_accy 66.580
2022-11-28 19:36:13,070 [bic.py] => bias_correction => Task 3, Epoch 67/170 => Loss 3.047, Train_accy 82.920, Test_accy 66.470
2022-11-28 19:36:16,268 [bic.py] => bias_correction => Task 3, Epoch 68/170 => Loss 3.044, Train_accy 79.580, Test_accy 66.470
2022-11-28 19:36:19,570 [bic.py] => bias_correction => Task 3, Epoch 69/170 => Loss 3.021, Train_accy 80.830, Test_accy 66.350
2022-11-28 19:36:22,841 [bic.py] => bias_correction => Task 3, Epoch 70/170 => Loss 3.032, Train_accy 80.420, Test_accy 66.720
2022-11-28 19:36:26,007 [bic.py] => bias_correction => Task 3, Epoch 71/170 => Loss 3.063, Train_accy 80.000, Test_accy 66.470
2022-11-28 19:36:29,104 [bic.py] => bias_correction => Task 3, Epoch 72/170 => Loss 3.030, Train_accy 80.420, Test_accy 66.400
2022-11-28 19:36:32,217 [bic.py] => bias_correction => Task 3, Epoch 73/170 => Loss 3.035, Train_accy 81.670, Test_accy 66.300
2022-11-28 19:36:35,294 [bic.py] => bias_correction => Task 3, Epoch 74/170 => Loss 3.049, Train_accy 79.170, Test_accy 66.280
2022-11-28 19:36:38,630 [bic.py] => bias_correction => Task 3, Epoch 75/170 => Loss 3.029, Train_accy 76.670, Test_accy 66.500
2022-11-28 19:36:41,787 [bic.py] => bias_correction => Task 3, Epoch 76/170 => Loss 3.042, Train_accy 80.830, Test_accy 66.700
2022-11-28 19:36:44,930 [bic.py] => bias_correction => Task 3, Epoch 77/170 => Loss 3.042, Train_accy 80.830, Test_accy 66.850
2022-11-28 19:36:48,241 [bic.py] => bias_correction => Task 3, Epoch 78/170 => Loss 3.048, Train_accy 79.170, Test_accy 66.600
2022-11-28 19:36:51,240 [bic.py] => bias_correction => Task 3, Epoch 79/170 => Loss 3.043, Train_accy 79.170, Test_accy 66.380
2022-11-28 19:36:54,381 [bic.py] => bias_correction => Task 3, Epoch 80/170 => Loss 3.057, Train_accy 81.250, Test_accy 66.350
2022-11-28 19:36:57,553 [bic.py] => bias_correction => Task 3, Epoch 81/170 => Loss 3.036, Train_accy 78.330, Test_accy 66.300
2022-11-28 19:37:00,816 [bic.py] => bias_correction => Task 3, Epoch 82/170 => Loss 3.028, Train_accy 80.420, Test_accy 66.680
2022-11-28 19:37:04,027 [bic.py] => bias_correction => Task 3, Epoch 83/170 => Loss 3.053, Train_accy 80.000, Test_accy 66.680
2022-11-28 19:37:07,021 [bic.py] => bias_correction => Task 3, Epoch 84/170 => Loss 3.047, Train_accy 80.420, Test_accy 66.450
2022-11-28 19:37:10,155 [bic.py] => bias_correction => Task 3, Epoch 85/170 => Loss 3.058, Train_accy 81.670, Test_accy 66.420
2022-11-28 19:37:13,276 [bic.py] => bias_correction => Task 3, Epoch 86/170 => Loss 3.046, Train_accy 80.000, Test_accy 66.650
2022-11-28 19:37:16,520 [bic.py] => bias_correction => Task 3, Epoch 87/170 => Loss 3.043, Train_accy 81.250, Test_accy 67.050
2022-11-28 19:37:19,719 [bic.py] => bias_correction => Task 3, Epoch 88/170 => Loss 3.059, Train_accy 78.750, Test_accy 66.950
2022-11-28 19:37:23,023 [bic.py] => bias_correction => Task 3, Epoch 89/170 => Loss 3.047, Train_accy 81.670, Test_accy 66.530
2022-11-28 19:37:26,243 [bic.py] => bias_correction => Task 3, Epoch 90/170 => Loss 3.039, Train_accy 78.330, Test_accy 66.700
2022-11-28 19:37:29,448 [bic.py] => bias_correction => Task 3, Epoch 91/170 => Loss 3.041, Train_accy 80.000, Test_accy 66.580
2022-11-28 19:37:32,511 [bic.py] => bias_correction => Task 3, Epoch 92/170 => Loss 3.038, Train_accy 81.250, Test_accy 66.580
2022-11-28 19:37:35,658 [bic.py] => bias_correction => Task 3, Epoch 93/170 => Loss 3.031, Train_accy 82.080, Test_accy 66.500
2022-11-28 19:37:38,730 [bic.py] => bias_correction => Task 3, Epoch 94/170 => Loss 3.036, Train_accy 77.920, Test_accy 66.750
2022-11-28 19:37:41,833 [bic.py] => bias_correction => Task 3, Epoch 95/170 => Loss 3.060, Train_accy 78.750, Test_accy 66.920
2022-11-28 19:37:44,894 [bic.py] => bias_correction => Task 3, Epoch 96/170 => Loss 3.046, Train_accy 80.420, Test_accy 67.120
2022-11-28 19:37:48,088 [bic.py] => bias_correction => Task 3, Epoch 97/170 => Loss 3.058, Train_accy 79.580, Test_accy 66.900
2022-11-28 19:37:51,180 [bic.py] => bias_correction => Task 3, Epoch 98/170 => Loss 3.039, Train_accy 80.830, Test_accy 66.850
2022-11-28 19:37:54,496 [bic.py] => bias_correction => Task 3, Epoch 99/170 => Loss 3.056, Train_accy 80.000, Test_accy 66.700
2022-11-28 19:37:57,661 [bic.py] => bias_correction => Task 3, Epoch 100/170 => Loss 3.044, Train_accy 80.000, Test_accy 66.880
2022-11-28 19:38:00,843 [bic.py] => bias_correction => Task 3, Epoch 101/170 => Loss 3.067, Train_accy 77.920, Test_accy 66.970
2022-11-28 19:38:04,055 [bic.py] => bias_correction => Task 3, Epoch 102/170 => Loss 3.037, Train_accy 79.580, Test_accy 66.750
2022-11-28 19:38:07,317 [bic.py] => bias_correction => Task 3, Epoch 103/170 => Loss 3.039, Train_accy 77.080, Test_accy 67.000
2022-11-28 19:38:10,582 [bic.py] => bias_correction => Task 3, Epoch 104/170 => Loss 3.046, Train_accy 80.830, Test_accy 66.920
2022-11-28 19:38:13,829 [bic.py] => bias_correction => Task 3, Epoch 105/170 => Loss 3.042, Train_accy 82.500, Test_accy 66.880
2022-11-28 19:38:17,018 [bic.py] => bias_correction => Task 3, Epoch 106/170 => Loss 3.031, Train_accy 78.750, Test_accy 66.780
2022-11-28 19:38:20,209 [bic.py] => bias_correction => Task 3, Epoch 107/170 => Loss 3.026, Train_accy 79.170, Test_accy 66.700
2022-11-28 19:38:23,465 [bic.py] => bias_correction => Task 3, Epoch 108/170 => Loss 3.043, Train_accy 79.580, Test_accy 66.880
2022-11-28 19:38:26,758 [bic.py] => bias_correction => Task 3, Epoch 109/170 => Loss 3.039, Train_accy 81.250, Test_accy 66.580
2022-11-28 19:38:29,983 [bic.py] => bias_correction => Task 3, Epoch 110/170 => Loss 3.036, Train_accy 79.170, Test_accy 66.600
2022-11-28 19:38:33,084 [bic.py] => bias_correction => Task 3, Epoch 111/170 => Loss 3.049, Train_accy 79.580, Test_accy 66.880
2022-11-28 19:38:36,281 [bic.py] => bias_correction => Task 3, Epoch 112/170 => Loss 3.046, Train_accy 80.830, Test_accy 67.030
2022-11-28 19:38:39,351 [bic.py] => bias_correction => Task 3, Epoch 113/170 => Loss 3.049, Train_accy 79.580, Test_accy 66.970
2022-11-28 19:38:42,385 [bic.py] => bias_correction => Task 3, Epoch 114/170 => Loss 3.047, Train_accy 80.420, Test_accy 66.920
2022-11-28 19:38:45,438 [bic.py] => bias_correction => Task 3, Epoch 115/170 => Loss 3.047, Train_accy 75.830, Test_accy 66.970
2022-11-28 19:38:48,680 [bic.py] => bias_correction => Task 3, Epoch 116/170 => Loss 3.039, Train_accy 80.000, Test_accy 66.970
2022-11-28 19:38:51,854 [bic.py] => bias_correction => Task 3, Epoch 117/170 => Loss 3.050, Train_accy 79.580, Test_accy 66.650
2022-11-28 19:38:54,939 [bic.py] => bias_correction => Task 3, Epoch 118/170 => Loss 3.027, Train_accy 83.750, Test_accy 66.920
2022-11-28 19:38:57,942 [bic.py] => bias_correction => Task 3, Epoch 119/170 => Loss 3.050, Train_accy 79.580, Test_accy 66.580
2022-11-28 19:39:01,087 [bic.py] => bias_correction => Task 3, Epoch 120/170 => Loss 3.057, Train_accy 83.330, Test_accy 66.750
2022-11-28 19:39:04,307 [bic.py] => bias_correction => Task 3, Epoch 121/170 => Loss 3.051, Train_accy 79.580, Test_accy 66.880
2022-11-28 19:39:07,335 [bic.py] => bias_correction => Task 3, Epoch 122/170 => Loss 3.053, Train_accy 77.920, Test_accy 66.600
2022-11-28 19:39:10,599 [bic.py] => bias_correction => Task 3, Epoch 123/170 => Loss 3.025, Train_accy 82.080, Test_accy 66.530
2022-11-28 19:39:13,723 [bic.py] => bias_correction => Task 3, Epoch 124/170 => Loss 3.035, Train_accy 79.580, Test_accy 66.780
2022-11-28 19:39:16,808 [bic.py] => bias_correction => Task 3, Epoch 125/170 => Loss 3.043, Train_accy 77.920, Test_accy 66.720
2022-11-28 19:39:19,896 [bic.py] => bias_correction => Task 3, Epoch 126/170 => Loss 3.031, Train_accy 81.250, Test_accy 66.780
2022-11-28 19:39:23,318 [bic.py] => bias_correction => Task 3, Epoch 127/170 => Loss 3.055, Train_accy 80.420, Test_accy 66.970
2022-11-28 19:39:26,465 [bic.py] => bias_correction => Task 3, Epoch 128/170 => Loss 3.040, Train_accy 77.500, Test_accy 67.000
2022-11-28 19:39:29,492 [bic.py] => bias_correction => Task 3, Epoch 129/170 => Loss 3.045, Train_accy 77.500, Test_accy 66.800
2022-11-28 19:39:32,609 [bic.py] => bias_correction => Task 3, Epoch 130/170 => Loss 3.046, Train_accy 79.580, Test_accy 66.720
2022-11-28 19:39:35,800 [bic.py] => bias_correction => Task 3, Epoch 131/170 => Loss 3.044, Train_accy 77.920, Test_accy 66.720
2022-11-28 19:39:38,930 [bic.py] => bias_correction => Task 3, Epoch 132/170 => Loss 3.052, Train_accy 81.670, Test_accy 66.800
2022-11-28 19:39:42,181 [bic.py] => bias_correction => Task 3, Epoch 133/170 => Loss 3.035, Train_accy 81.670, Test_accy 66.850
2022-11-28 19:39:45,339 [bic.py] => bias_correction => Task 3, Epoch 134/170 => Loss 3.026, Train_accy 80.830, Test_accy 66.650
2022-11-28 19:39:48,521 [bic.py] => bias_correction => Task 3, Epoch 135/170 => Loss 3.027, Train_accy 79.580, Test_accy 66.750
2022-11-28 19:39:51,709 [bic.py] => bias_correction => Task 3, Epoch 136/170 => Loss 3.037, Train_accy 79.170, Test_accy 66.380
2022-11-28 19:39:54,894 [bic.py] => bias_correction => Task 3, Epoch 137/170 => Loss 3.038, Train_accy 77.920, Test_accy 66.380
2022-11-28 19:39:57,893 [bic.py] => bias_correction => Task 3, Epoch 138/170 => Loss 3.026, Train_accy 79.170, Test_accy 66.380
2022-11-28 19:40:01,071 [bic.py] => bias_correction => Task 3, Epoch 139/170 => Loss 3.037, Train_accy 80.830, Test_accy 66.530
2022-11-28 19:40:04,267 [bic.py] => bias_correction => Task 3, Epoch 140/170 => Loss 3.024, Train_accy 82.920, Test_accy 66.750
2022-11-28 19:40:07,361 [bic.py] => bias_correction => Task 3, Epoch 141/170 => Loss 3.044, Train_accy 80.830, Test_accy 66.450
2022-11-28 19:40:10,389 [bic.py] => bias_correction => Task 3, Epoch 142/170 => Loss 3.049, Train_accy 80.000, Test_accy 66.780
2022-11-28 19:40:13,452 [bic.py] => bias_correction => Task 3, Epoch 143/170 => Loss 3.046, Train_accy 80.420, Test_accy 66.750
2022-11-28 19:40:16,739 [bic.py] => bias_correction => Task 3, Epoch 144/170 => Loss 3.046, Train_accy 82.500, Test_accy 66.750
2022-11-28 19:40:19,909 [bic.py] => bias_correction => Task 3, Epoch 145/170 => Loss 3.047, Train_accy 79.580, Test_accy 66.620
2022-11-28 19:40:23,147 [bic.py] => bias_correction => Task 3, Epoch 146/170 => Loss 3.024, Train_accy 81.250, Test_accy 66.620
2022-11-28 19:40:26,386 [bic.py] => bias_correction => Task 3, Epoch 147/170 => Loss 3.050, Train_accy 80.830, Test_accy 66.800
2022-11-28 19:40:29,350 [bic.py] => bias_correction => Task 3, Epoch 148/170 => Loss 3.044, Train_accy 75.000, Test_accy 66.600
2022-11-28 19:40:32,570 [bic.py] => bias_correction => Task 3, Epoch 149/170 => Loss 3.048, Train_accy 81.250, Test_accy 66.680
2022-11-28 19:40:35,748 [bic.py] => bias_correction => Task 3, Epoch 150/170 => Loss 3.037, Train_accy 79.580, Test_accy 66.470
2022-11-28 19:40:38,903 [bic.py] => bias_correction => Task 3, Epoch 151/170 => Loss 3.033, Train_accy 80.420, Test_accy 66.580
2022-11-28 19:40:42,292 [bic.py] => bias_correction => Task 3, Epoch 152/170 => Loss 3.037, Train_accy 82.080, Test_accy 66.550
2022-11-28 19:40:45,410 [bic.py] => bias_correction => Task 3, Epoch 153/170 => Loss 3.051, Train_accy 79.170, Test_accy 66.470
2022-11-28 19:40:48,613 [bic.py] => bias_correction => Task 3, Epoch 154/170 => Loss 3.028, Train_accy 80.830, Test_accy 66.550
2022-11-28 19:40:51,764 [bic.py] => bias_correction => Task 3, Epoch 155/170 => Loss 3.016, Train_accy 78.750, Test_accy 66.530
2022-11-28 19:40:54,947 [bic.py] => bias_correction => Task 3, Epoch 156/170 => Loss 3.066, Train_accy 79.170, Test_accy 66.350
2022-11-28 19:40:58,194 [bic.py] => bias_correction => Task 3, Epoch 157/170 => Loss 3.039, Train_accy 82.080, Test_accy 66.350
2022-11-28 19:41:01,511 [bic.py] => bias_correction => Task 3, Epoch 158/170 => Loss 3.062, Train_accy 80.000, Test_accy 66.350
2022-11-28 19:41:04,710 [bic.py] => bias_correction => Task 3, Epoch 159/170 => Loss 3.039, Train_accy 80.830, Test_accy 66.600
2022-11-28 19:41:08,014 [bic.py] => bias_correction => Task 3, Epoch 160/170 => Loss 3.031, Train_accy 79.580, Test_accy 66.280
2022-11-28 19:41:11,201 [bic.py] => bias_correction => Task 3, Epoch 161/170 => Loss 3.045, Train_accy 77.920, Test_accy 66.470
2022-11-28 19:41:14,441 [bic.py] => bias_correction => Task 3, Epoch 162/170 => Loss 3.052, Train_accy 77.080, Test_accy 66.420
2022-11-28 19:41:17,517 [bic.py] => bias_correction => Task 3, Epoch 163/170 => Loss 3.042, Train_accy 80.000, Test_accy 66.350
2022-11-28 19:41:20,705 [bic.py] => bias_correction => Task 3, Epoch 164/170 => Loss 3.034, Train_accy 80.830, Test_accy 66.120
2022-11-28 19:41:23,922 [bic.py] => bias_correction => Task 3, Epoch 165/170 => Loss 3.050, Train_accy 79.170, Test_accy 66.320
2022-11-28 19:41:27,207 [bic.py] => bias_correction => Task 3, Epoch 166/170 => Loss 3.053, Train_accy 79.580, Test_accy 66.550
2022-11-28 19:41:30,367 [bic.py] => bias_correction => Task 3, Epoch 167/170 => Loss 3.053, Train_accy 80.420, Test_accy 66.680
2022-11-28 19:41:33,563 [bic.py] => bias_correction => Task 3, Epoch 168/170 => Loss 3.034, Train_accy 80.000, Test_accy 66.530
2022-11-28 19:41:36,796 [bic.py] => bias_correction => Task 3, Epoch 169/170 => Loss 3.045, Train_accy 79.580, Test_accy 66.820
2022-11-28 19:41:39,867 [bic.py] => bias_correction => Task 3, Epoch 170/170 => Loss 3.040, Train_accy 81.250, Test_accy 66.600
2022-11-28 19:41:39,868 [base.py] => Reducing exemplars...(50 per classes)
2022-11-28 19:41:52,278 [base.py] => Constructing exemplars...(50 per classes)
2022-11-28 19:42:01,376 [bic.py] => Parameters of bias layer:
2022-11-28 19:42:01,377 [bic.py] => 0 => 1.000, 0.000
2022-11-28 19:42:01,377 [bic.py] => 1 => 0.976, -1.640
2022-11-28 19:42:01,377 [bic.py] => 2 => 0.847, -1.789
2022-11-28 19:42:01,377 [bic.py] => 3 => 0.728, -1.453
2022-11-28 19:42:03,400 [bic.py] => Exemplar size: 2000
2022-11-28 19:42:03,400 [trainer.py] => CNN: {'total': 66.6, '00-09': 72.4, '10-19': 61.4, '20-29': 69.4, '30-39': 63.2, 'old': 67.73, 'new': 63.2}
2022-11-28 19:42:03,400 [trainer.py] => NME: {'total': 66.72, '00-09': 69.3, '10-19': 56.4, '20-29': 69.7, '30-39': 71.5, 'old': 65.13, 'new': 71.5}
2022-11-28 19:42:03,400 [trainer.py] => CNN top1 curve: [88.7, 75.6, 72.3, 66.6]
2022-11-28 19:42:03,400 [trainer.py] => CNN top5 curve: [99.4, 95.6, 93.5, 91.42]
2022-11-28 19:42:03,400 [trainer.py] => NME top1 curve: [88.5, 75.85, 72.47, 66.72]
2022-11-28 19:42:03,401 [trainer.py] => NME top5 curve: [99.4, 95.95, 93.8, 91.2]

2022-11-28 19:42:03,401 [trainer.py] => All params: 466762
2022-11-28 19:42:03,401 [trainer.py] => Trainable params: 466762
2022-11-28 19:42:03,402 [bic.py] => Learning on 40-50
2022-11-28 19:42:03,440 [bic.py] => Stage1 dset: 6750, Stage2 dset: 250
2022-11-28 19:42:03,440 [bic.py] => Lambda: 0.800
2022-11-28 19:42:03,450 [bic.py] => Parameters of bias layer:
2022-11-28 19:42:03,450 [bic.py] => 0 => 1.000, 0.000
2022-11-28 19:42:03,450 [bic.py] => 1 => 0.976, -1.640
2022-11-28 19:42:03,450 [bic.py] => 2 => 0.847, -1.789
2022-11-28 19:42:03,450 [bic.py] => 3 => 0.728, -1.453
2022-11-28 19:42:03,450 [bic.py] => 4 => 1.000, 0.000
2022-11-28 19:42:10,817 [bic.py] => training => Task 4, Epoch 1/170 => Loss 2.121, Train_accy 73.570, Test_accy 46.300
2022-11-28 19:42:18,787 [bic.py] => training => Task 4, Epoch 2/170 => Loss 1.930, Train_accy 76.340, Test_accy 47.500
2022-11-28 19:42:26,591 [bic.py] => training => Task 4, Epoch 3/170 => Loss 1.903, Train_accy 81.080, Test_accy 47.980
2022-11-28 19:42:34,167 [bic.py] => training => Task 4, Epoch 4/170 => Loss 1.887, Train_accy 82.460, Test_accy 51.540
2022-11-28 19:42:42,114 [bic.py] => training => Task 4, Epoch 5/170 => Loss 1.882, Train_accy 82.250, Test_accy 51.280
2022-11-28 19:42:49,949 [bic.py] => training => Task 4, Epoch 6/170 => Loss 1.865, Train_accy 85.190, Test_accy 50.140
2022-11-28 19:42:58,128 [bic.py] => training => Task 4, Epoch 7/170 => Loss 1.868, Train_accy 85.290, Test_accy 48.920
2022-11-28 19:43:06,149 [bic.py] => training => Task 4, Epoch 8/170 => Loss 1.870, Train_accy 84.760, Test_accy 50.960
2022-11-28 19:43:14,035 [bic.py] => training => Task 4, Epoch 9/170 => Loss 1.859, Train_accy 86.500, Test_accy 50.040
2022-11-28 19:43:21,778 [bic.py] => training => Task 4, Epoch 10/170 => Loss 1.854, Train_accy 85.970, Test_accy 49.700
2022-11-28 19:43:29,655 [bic.py] => training => Task 4, Epoch 11/170 => Loss 1.854, Train_accy 87.200, Test_accy 51.520
2022-11-28 19:43:37,883 [bic.py] => training => Task 4, Epoch 12/170 => Loss 1.846, Train_accy 86.120, Test_accy 49.660
2022-11-28 19:43:45,414 [bic.py] => training => Task 4, Epoch 13/170 => Loss 1.849, Train_accy 87.990, Test_accy 51.040
2022-11-28 19:43:53,166 [bic.py] => training => Task 4, Epoch 14/170 => Loss 1.843, Train_accy 87.160, Test_accy 52.040
2022-11-28 19:44:00,986 [bic.py] => training => Task 4, Epoch 15/170 => Loss 1.842, Train_accy 89.410, Test_accy 53.380
2022-11-28 19:44:08,515 [bic.py] => training => Task 4, Epoch 16/170 => Loss 1.837, Train_accy 89.300, Test_accy 52.120
2022-11-28 19:44:16,380 [bic.py] => training => Task 4, Epoch 17/170 => Loss 1.832, Train_accy 88.620, Test_accy 51.580
2022-11-28 19:44:24,409 [bic.py] => training => Task 4, Epoch 18/170 => Loss 1.829, Train_accy 89.670, Test_accy 52.860
2022-11-28 19:44:31,938 [bic.py] => training => Task 4, Epoch 19/170 => Loss 1.833, Train_accy 91.100, Test_accy 52.000
2022-11-28 19:44:39,977 [bic.py] => training => Task 4, Epoch 20/170 => Loss 1.826, Train_accy 90.220, Test_accy 51.560
2022-11-28 19:44:48,122 [bic.py] => training => Task 4, Epoch 21/170 => Loss 1.839, Train_accy 90.550, Test_accy 53.240
2022-11-28 19:44:55,831 [bic.py] => training => Task 4, Epoch 22/170 => Loss 1.832, Train_accy 89.100, Test_accy 51.360
2022-11-28 19:45:03,691 [bic.py] => training => Task 4, Epoch 23/170 => Loss 1.831, Train_accy 91.480, Test_accy 52.900
2022-11-28 19:45:11,511 [bic.py] => training => Task 4, Epoch 24/170 => Loss 1.826, Train_accy 89.480, Test_accy 51.520
2022-11-28 19:45:19,380 [bic.py] => training => Task 4, Epoch 25/170 => Loss 1.835, Train_accy 89.760, Test_accy 52.240
2022-11-28 19:45:27,450 [bic.py] => training => Task 4, Epoch 26/170 => Loss 1.830, Train_accy 89.010, Test_accy 50.480
2022-11-28 19:45:35,273 [bic.py] => training => Task 4, Epoch 27/170 => Loss 1.832, Train_accy 89.240, Test_accy 49.780
2022-11-28 19:45:42,917 [bic.py] => training => Task 4, Epoch 28/170 => Loss 1.828, Train_accy 91.420, Test_accy 51.540
2022-11-28 19:45:50,800 [bic.py] => training => Task 4, Epoch 29/170 => Loss 1.829, Train_accy 91.850, Test_accy 53.780
2022-11-28 19:45:58,869 [bic.py] => training => Task 4, Epoch 30/170 => Loss 1.830, Train_accy 91.590, Test_accy 53.000
2022-11-28 19:46:06,925 [bic.py] => training => Task 4, Epoch 31/170 => Loss 1.828, Train_accy 92.620, Test_accy 53.040
2022-11-28 19:46:14,813 [bic.py] => training => Task 4, Epoch 32/170 => Loss 1.821, Train_accy 91.570, Test_accy 53.340
2022-11-28 19:46:22,985 [bic.py] => training => Task 4, Epoch 33/170 => Loss 1.819, Train_accy 91.360, Test_accy 50.140
2022-11-28 19:46:31,056 [bic.py] => training => Task 4, Epoch 34/170 => Loss 1.815, Train_accy 93.010, Test_accy 54.440
2022-11-28 19:46:38,885 [bic.py] => training => Task 4, Epoch 35/170 => Loss 1.820, Train_accy 91.390, Test_accy 51.420
2022-11-28 19:46:46,538 [bic.py] => training => Task 4, Epoch 36/170 => Loss 1.819, Train_accy 92.560, Test_accy 53.840
2022-11-28 19:46:54,979 [bic.py] => training => Task 4, Epoch 37/170 => Loss 1.821, Train_accy 92.250, Test_accy 50.600
2022-11-28 19:47:02,867 [bic.py] => training => Task 4, Epoch 38/170 => Loss 1.817, Train_accy 92.030, Test_accy 51.600
2022-11-28 19:47:10,831 [bic.py] => training => Task 4, Epoch 39/170 => Loss 1.816, Train_accy 92.860, Test_accy 52.380
2022-11-28 19:47:18,786 [bic.py] => training => Task 4, Epoch 40/170 => Loss 1.817, Train_accy 91.160, Test_accy 52.360
2022-11-28 19:47:26,943 [bic.py] => training => Task 4, Epoch 41/170 => Loss 1.819, Train_accy 92.870, Test_accy 53.180
2022-11-28 19:47:34,644 [bic.py] => training => Task 4, Epoch 42/170 => Loss 1.817, Train_accy 91.960, Test_accy 51.320
2022-11-28 19:47:42,459 [bic.py] => training => Task 4, Epoch 43/170 => Loss 1.818, Train_accy 91.410, Test_accy 51.080
2022-11-28 19:47:50,627 [bic.py] => training => Task 4, Epoch 44/170 => Loss 1.824, Train_accy 92.010, Test_accy 53.640
2022-11-28 19:47:58,680 [bic.py] => training => Task 4, Epoch 45/170 => Loss 1.818, Train_accy 93.530, Test_accy 53.320
2022-11-28 19:48:06,233 [bic.py] => training => Task 4, Epoch 46/170 => Loss 1.819, Train_accy 89.240, Test_accy 49.980
2022-11-28 19:48:14,277 [bic.py] => training => Task 4, Epoch 47/170 => Loss 1.818, Train_accy 91.970, Test_accy 51.440
2022-11-28 19:48:21,633 [bic.py] => training => Task 4, Epoch 48/170 => Loss 1.818, Train_accy 93.750, Test_accy 53.420
2022-11-28 19:48:29,757 [bic.py] => training => Task 4, Epoch 49/170 => Loss 1.823, Train_accy 92.030, Test_accy 54.400
2022-11-28 19:48:37,364 [bic.py] => training => Task 4, Epoch 50/170 => Loss 1.819, Train_accy 93.200, Test_accy 54.380
2022-11-28 19:48:45,144 [bic.py] => training => Task 4, Epoch 51/170 => Loss 1.812, Train_accy 89.790, Test_accy 50.120
2022-11-28 19:48:53,212 [bic.py] => training => Task 4, Epoch 52/170 => Loss 1.812, Train_accy 93.530, Test_accy 53.660
2022-11-28 19:49:01,216 [bic.py] => training => Task 4, Epoch 53/170 => Loss 1.816, Train_accy 93.160, Test_accy 52.260
2022-11-28 19:49:08,898 [bic.py] => training => Task 4, Epoch 54/170 => Loss 1.819, Train_accy 90.000, Test_accy 49.400
2022-11-28 19:49:16,545 [bic.py] => training => Task 4, Epoch 55/170 => Loss 1.821, Train_accy 90.410, Test_accy 50.540
2022-11-28 19:49:24,773 [bic.py] => training => Task 4, Epoch 56/170 => Loss 1.821, Train_accy 89.900, Test_accy 48.800
2022-11-28 19:49:32,183 [bic.py] => training => Task 4, Epoch 57/170 => Loss 1.816, Train_accy 93.390, Test_accy 51.500
2022-11-28 19:49:39,979 [bic.py] => training => Task 4, Epoch 58/170 => Loss 1.811, Train_accy 93.390, Test_accy 52.800
2022-11-28 19:49:48,169 [bic.py] => training => Task 4, Epoch 59/170 => Loss 1.815, Train_accy 93.820, Test_accy 51.740
2022-11-28 19:49:55,696 [bic.py] => training => Task 4, Epoch 60/170 => Loss 1.815, Train_accy 93.880, Test_accy 52.960
2022-11-28 19:50:03,546 [bic.py] => training => Task 4, Epoch 61/170 => Loss 1.787, Train_accy 98.220, Test_accy 57.040
2022-11-28 19:50:11,253 [bic.py] => training => Task 4, Epoch 62/170 => Loss 1.763, Train_accy 98.210, Test_accy 57.520
2022-11-28 19:50:19,360 [bic.py] => training => Task 4, Epoch 63/170 => Loss 1.759, Train_accy 98.590, Test_accy 57.480
2022-11-28 19:50:27,396 [bic.py] => training => Task 4, Epoch 64/170 => Loss 1.759, Train_accy 98.650, Test_accy 56.520
2022-11-28 19:50:35,177 [bic.py] => training => Task 4, Epoch 65/170 => Loss 1.747, Train_accy 98.860, Test_accy 57.000
2022-11-28 19:50:42,937 [bic.py] => training => Task 4, Epoch 66/170 => Loss 1.755, Train_accy 98.890, Test_accy 57.380
2022-11-28 19:50:50,479 [bic.py] => training => Task 4, Epoch 67/170 => Loss 1.754, Train_accy 99.050, Test_accy 56.620
2022-11-28 19:50:58,622 [bic.py] => training => Task 4, Epoch 68/170 => Loss 1.748, Train_accy 98.870, Test_accy 57.080
2022-11-28 19:51:06,782 [bic.py] => training => Task 4, Epoch 69/170 => Loss 1.750, Train_accy 98.920, Test_accy 57.260
2022-11-28 19:51:14,842 [bic.py] => training => Task 4, Epoch 70/170 => Loss 1.748, Train_accy 98.920, Test_accy 57.320
2022-11-28 19:51:22,825 [bic.py] => training => Task 4, Epoch 71/170 => Loss 1.746, Train_accy 99.100, Test_accy 57.080
2022-11-28 19:51:31,040 [bic.py] => training => Task 4, Epoch 72/170 => Loss 1.745, Train_accy 98.990, Test_accy 57.200
2022-11-28 19:51:38,821 [bic.py] => training => Task 4, Epoch 73/170 => Loss 1.742, Train_accy 99.210, Test_accy 56.800
2022-11-28 19:51:46,790 [bic.py] => training => Task 4, Epoch 74/170 => Loss 1.749, Train_accy 99.200, Test_accy 57.640
2022-11-28 19:51:54,290 [bic.py] => training => Task 4, Epoch 75/170 => Loss 1.743, Train_accy 99.040, Test_accy 56.840
2022-11-28 19:52:01,853 [bic.py] => training => Task 4, Epoch 76/170 => Loss 1.747, Train_accy 99.130, Test_accy 57.100
2022-11-28 19:52:09,663 [bic.py] => training => Task 4, Epoch 77/170 => Loss 1.741, Train_accy 99.190, Test_accy 57.420
2022-11-28 19:52:17,474 [bic.py] => training => Task 4, Epoch 78/170 => Loss 1.744, Train_accy 99.010, Test_accy 56.880
2022-11-28 19:52:25,298 [bic.py] => training => Task 4, Epoch 79/170 => Loss 1.741, Train_accy 99.100, Test_accy 57.660
2022-11-28 19:52:33,522 [bic.py] => training => Task 4, Epoch 80/170 => Loss 1.747, Train_accy 99.240, Test_accy 57.580
2022-11-28 19:52:41,523 [bic.py] => training => Task 4, Epoch 81/170 => Loss 1.740, Train_accy 99.100, Test_accy 56.980
2022-11-28 19:52:49,458 [bic.py] => training => Task 4, Epoch 82/170 => Loss 1.743, Train_accy 99.320, Test_accy 57.960
2022-11-28 19:52:57,353 [bic.py] => training => Task 4, Epoch 83/170 => Loss 1.740, Train_accy 99.470, Test_accy 57.560
2022-11-28 19:53:05,160 [bic.py] => training => Task 4, Epoch 84/170 => Loss 1.740, Train_accy 99.320, Test_accy 57.440
2022-11-28 19:53:13,074 [bic.py] => training => Task 4, Epoch 85/170 => Loss 1.744, Train_accy 99.260, Test_accy 57.280
2022-11-28 19:53:20,856 [bic.py] => training => Task 4, Epoch 86/170 => Loss 1.746, Train_accy 99.290, Test_accy 57.520
2022-11-28 19:53:29,106 [bic.py] => training => Task 4, Epoch 87/170 => Loss 1.744, Train_accy 99.420, Test_accy 57.400
2022-11-28 19:53:36,836 [bic.py] => training => Task 4, Epoch 88/170 => Loss 1.743, Train_accy 99.330, Test_accy 57.340
2022-11-28 19:53:44,762 [bic.py] => training => Task 4, Epoch 89/170 => Loss 1.741, Train_accy 99.500, Test_accy 57.400
2022-11-28 19:53:52,244 [bic.py] => training => Task 4, Epoch 90/170 => Loss 1.743, Train_accy 99.470, Test_accy 57.420
2022-11-28 19:54:00,206 [bic.py] => training => Task 4, Epoch 91/170 => Loss 1.739, Train_accy 99.320, Test_accy 57.300
2022-11-28 19:54:08,112 [bic.py] => training => Task 4, Epoch 92/170 => Loss 1.737, Train_accy 99.360, Test_accy 57.260
2022-11-28 19:54:16,202 [bic.py] => training => Task 4, Epoch 93/170 => Loss 1.742, Train_accy 99.360, Test_accy 57.540
2022-11-28 19:54:24,063 [bic.py] => training => Task 4, Epoch 94/170 => Loss 1.737, Train_accy 99.270, Test_accy 57.680
2022-11-28 19:54:31,872 [bic.py] => training => Task 4, Epoch 95/170 => Loss 1.740, Train_accy 99.410, Test_accy 57.020
2022-11-28 19:54:40,084 [bic.py] => training => Task 4, Epoch 96/170 => Loss 1.741, Train_accy 99.450, Test_accy 57.480
2022-11-28 19:54:47,672 [bic.py] => training => Task 4, Epoch 97/170 => Loss 1.741, Train_accy 99.290, Test_accy 57.480
2022-11-28 19:54:55,812 [bic.py] => training => Task 4, Epoch 98/170 => Loss 1.738, Train_accy 99.480, Test_accy 57.360
2022-11-28 19:55:03,516 [bic.py] => training => Task 4, Epoch 99/170 => Loss 1.741, Train_accy 99.330, Test_accy 57.400
2022-11-28 19:55:11,252 [bic.py] => training => Task 4, Epoch 100/170 => Loss 1.738, Train_accy 99.420, Test_accy 58.120
2022-11-28 19:55:19,006 [bic.py] => training => Task 4, Epoch 101/170 => Loss 1.740, Train_accy 99.450, Test_accy 57.760
2022-11-28 19:55:27,411 [bic.py] => training => Task 4, Epoch 102/170 => Loss 1.736, Train_accy 99.390, Test_accy 57.880
2022-11-28 19:55:35,476 [bic.py] => training => Task 4, Epoch 103/170 => Loss 1.738, Train_accy 99.380, Test_accy 57.840
2022-11-28 19:55:43,327 [bic.py] => training => Task 4, Epoch 104/170 => Loss 1.737, Train_accy 99.570, Test_accy 57.640
2022-11-28 19:55:50,991 [bic.py] => training => Task 4, Epoch 105/170 => Loss 1.733, Train_accy 99.420, Test_accy 57.340
2022-11-28 19:55:58,997 [bic.py] => training => Task 4, Epoch 106/170 => Loss 1.734, Train_accy 99.330, Test_accy 57.420
2022-11-28 19:56:06,867 [bic.py] => training => Task 4, Epoch 107/170 => Loss 1.738, Train_accy 99.390, Test_accy 57.120
2022-11-28 19:56:14,894 [bic.py] => training => Task 4, Epoch 108/170 => Loss 1.742, Train_accy 99.570, Test_accy 57.740
2022-11-28 19:56:22,706 [bic.py] => training => Task 4, Epoch 109/170 => Loss 1.739, Train_accy 99.470, Test_accy 58.120
2022-11-28 19:56:30,523 [bic.py] => training => Task 4, Epoch 110/170 => Loss 1.737, Train_accy 99.470, Test_accy 57.900
2022-11-28 19:56:38,286 [bic.py] => training => Task 4, Epoch 111/170 => Loss 1.738, Train_accy 99.470, Test_accy 57.480
2022-11-28 19:56:46,055 [bic.py] => training => Task 4, Epoch 112/170 => Loss 1.734, Train_accy 99.530, Test_accy 57.840
2022-11-28 19:56:53,884 [bic.py] => training => Task 4, Epoch 113/170 => Loss 1.741, Train_accy 99.470, Test_accy 57.540
2022-11-28 19:57:01,671 [bic.py] => training => Task 4, Epoch 114/170 => Loss 1.735, Train_accy 99.450, Test_accy 58.020
2022-11-28 19:57:09,254 [bic.py] => training => Task 4, Epoch 115/170 => Loss 1.733, Train_accy 99.480, Test_accy 57.740
2022-11-28 19:57:16,862 [bic.py] => training => Task 4, Epoch 116/170 => Loss 1.733, Train_accy 99.480, Test_accy 57.980
2022-11-28 19:57:24,880 [bic.py] => training => Task 4, Epoch 117/170 => Loss 1.735, Train_accy 99.470, Test_accy 57.420
2022-11-28 19:57:32,692 [bic.py] => training => Task 4, Epoch 118/170 => Loss 1.735, Train_accy 99.450, Test_accy 57.900
2022-11-28 19:57:40,702 [bic.py] => training => Task 4, Epoch 119/170 => Loss 1.730, Train_accy 99.480, Test_accy 57.300
2022-11-28 19:57:48,068 [bic.py] => training => Task 4, Epoch 120/170 => Loss 1.736, Train_accy 99.500, Test_accy 58.160
2022-11-28 19:57:56,192 [bic.py] => training => Task 4, Epoch 121/170 => Loss 1.735, Train_accy 99.570, Test_accy 57.560
2022-11-28 19:58:03,762 [bic.py] => training => Task 4, Epoch 122/170 => Loss 1.735, Train_accy 99.450, Test_accy 57.260
2022-11-28 19:58:11,395 [bic.py] => training => Task 4, Epoch 123/170 => Loss 1.742, Train_accy 99.500, Test_accy 57.740
2022-11-28 19:58:19,147 [bic.py] => training => Task 4, Epoch 124/170 => Loss 1.737, Train_accy 99.390, Test_accy 57.220
2022-11-28 19:58:27,153 [bic.py] => training => Task 4, Epoch 125/170 => Loss 1.740, Train_accy 99.560, Test_accy 57.660
2022-11-28 19:58:34,830 [bic.py] => training => Task 4, Epoch 126/170 => Loss 1.734, Train_accy 99.510, Test_accy 57.780
2022-11-28 19:58:43,072 [bic.py] => training => Task 4, Epoch 127/170 => Loss 1.736, Train_accy 99.450, Test_accy 57.320
2022-11-28 19:58:50,903 [bic.py] => training => Task 4, Epoch 128/170 => Loss 1.733, Train_accy 99.420, Test_accy 57.880
2022-11-28 19:58:59,135 [bic.py] => training => Task 4, Epoch 129/170 => Loss 1.735, Train_accy 99.560, Test_accy 57.820
2022-11-28 19:59:06,705 [bic.py] => training => Task 4, Epoch 130/170 => Loss 1.738, Train_accy 99.510, Test_accy 57.820
2022-11-28 19:59:14,524 [bic.py] => training => Task 4, Epoch 131/170 => Loss 1.734, Train_accy 99.570, Test_accy 57.500
2022-11-28 19:59:22,495 [bic.py] => training => Task 4, Epoch 132/170 => Loss 1.734, Train_accy 99.510, Test_accy 58.160
2022-11-28 19:59:30,531 [bic.py] => training => Task 4, Epoch 133/170 => Loss 1.738, Train_accy 99.540, Test_accy 58.020
2022-11-28 19:59:38,230 [bic.py] => training => Task 4, Epoch 134/170 => Loss 1.731, Train_accy 99.560, Test_accy 57.720
2022-11-28 19:59:46,283 [bic.py] => training => Task 4, Epoch 135/170 => Loss 1.733, Train_accy 99.480, Test_accy 57.940
2022-11-28 19:59:54,319 [bic.py] => training => Task 4, Epoch 136/170 => Loss 1.735, Train_accy 99.530, Test_accy 58.000
2022-11-28 20:00:01,949 [bic.py] => training => Task 4, Epoch 137/170 => Loss 1.728, Train_accy 99.510, Test_accy 57.580
2022-11-28 20:00:09,666 [bic.py] => training => Task 4, Epoch 138/170 => Loss 1.736, Train_accy 99.540, Test_accy 58.100
2022-11-28 20:00:17,379 [bic.py] => training => Task 4, Epoch 139/170 => Loss 1.731, Train_accy 99.420, Test_accy 57.420
2022-11-28 20:00:25,364 [bic.py] => training => Task 4, Epoch 140/170 => Loss 1.735, Train_accy 99.640, Test_accy 57.740
2022-11-28 20:00:33,231 [bic.py] => training => Task 4, Epoch 141/170 => Loss 1.738, Train_accy 99.300, Test_accy 57.300
2022-11-28 20:00:40,851 [bic.py] => training => Task 4, Epoch 142/170 => Loss 1.736, Train_accy 99.570, Test_accy 57.100
2022-11-28 20:00:48,440 [bic.py] => training => Task 4, Epoch 143/170 => Loss 1.735, Train_accy 99.480, Test_accy 57.680
2022-11-28 20:00:56,096 [bic.py] => training => Task 4, Epoch 144/170 => Loss 1.733, Train_accy 99.500, Test_accy 57.680
2022-11-28 20:01:03,584 [bic.py] => training => Task 4, Epoch 145/170 => Loss 1.740, Train_accy 99.470, Test_accy 58.500
2022-11-28 20:01:11,361 [bic.py] => training => Task 4, Epoch 146/170 => Loss 1.737, Train_accy 99.500, Test_accy 57.840
2022-11-28 20:01:18,972 [bic.py] => training => Task 4, Epoch 147/170 => Loss 1.735, Train_accy 99.420, Test_accy 57.440
2022-11-28 20:01:26,819 [bic.py] => training => Task 4, Epoch 148/170 => Loss 1.736, Train_accy 99.610, Test_accy 57.860
2022-11-28 20:01:34,502 [bic.py] => training => Task 4, Epoch 149/170 => Loss 1.731, Train_accy 99.540, Test_accy 58.200
2022-11-28 20:01:41,973 [bic.py] => training => Task 4, Epoch 150/170 => Loss 1.736, Train_accy 99.480, Test_accy 58.060
2022-11-28 20:01:49,410 [bic.py] => training => Task 4, Epoch 151/170 => Loss 1.734, Train_accy 99.670, Test_accy 58.000
2022-11-28 20:01:57,653 [bic.py] => training => Task 4, Epoch 152/170 => Loss 1.737, Train_accy 99.560, Test_accy 57.840
2022-11-28 20:02:05,476 [bic.py] => training => Task 4, Epoch 153/170 => Loss 1.736, Train_accy 99.590, Test_accy 58.040
2022-11-28 20:02:13,306 [bic.py] => training => Task 4, Epoch 154/170 => Loss 1.731, Train_accy 99.590, Test_accy 57.960
2022-11-28 20:02:21,097 [bic.py] => training => Task 4, Epoch 155/170 => Loss 1.737, Train_accy 99.630, Test_accy 57.460
2022-11-28 20:02:29,390 [bic.py] => training => Task 4, Epoch 156/170 => Loss 1.738, Train_accy 99.510, Test_accy 57.960
2022-11-28 20:02:37,041 [bic.py] => training => Task 4, Epoch 157/170 => Loss 1.732, Train_accy 99.420, Test_accy 58.040
2022-11-28 20:02:44,654 [bic.py] => training => Task 4, Epoch 158/170 => Loss 1.740, Train_accy 99.540, Test_accy 58.160
2022-11-28 20:02:52,594 [bic.py] => training => Task 4, Epoch 159/170 => Loss 1.735, Train_accy 99.440, Test_accy 57.620
2022-11-28 20:03:01,176 [bic.py] => training => Task 4, Epoch 160/170 => Loss 1.732, Train_accy 99.450, Test_accy 57.620
2022-11-28 20:03:09,155 [bic.py] => training => Task 4, Epoch 161/170 => Loss 1.736, Train_accy 99.480, Test_accy 57.720
2022-11-28 20:03:16,961 [bic.py] => training => Task 4, Epoch 162/170 => Loss 1.729, Train_accy 99.530, Test_accy 58.160
2022-11-28 20:03:24,896 [bic.py] => training => Task 4, Epoch 163/170 => Loss 1.734, Train_accy 99.510, Test_accy 57.680
2022-11-28 20:03:32,556 [bic.py] => training => Task 4, Epoch 164/170 => Loss 1.734, Train_accy 99.440, Test_accy 57.260
2022-11-28 20:03:40,088 [bic.py] => training => Task 4, Epoch 165/170 => Loss 1.734, Train_accy 99.590, Test_accy 58.340
2022-11-28 20:03:48,110 [bic.py] => training => Task 4, Epoch 166/170 => Loss 1.729, Train_accy 99.480, Test_accy 57.680
2022-11-28 20:03:56,153 [bic.py] => training => Task 4, Epoch 167/170 => Loss 1.734, Train_accy 99.380, Test_accy 57.960
2022-11-28 20:04:04,177 [bic.py] => training => Task 4, Epoch 168/170 => Loss 1.737, Train_accy 99.610, Test_accy 57.640
2022-11-28 20:04:11,973 [bic.py] => training => Task 4, Epoch 169/170 => Loss 1.734, Train_accy 99.500, Test_accy 57.820
2022-11-28 20:04:19,534 [bic.py] => training => Task 4, Epoch 170/170 => Loss 1.733, Train_accy 99.560, Test_accy 57.940
2022-11-28 20:04:23,110 [bic.py] => bias_correction => Task 4, Epoch 1/170 => Loss 3.366, Train_accy 70.400, Test_accy 60.940
2022-11-28 20:04:26,612 [bic.py] => bias_correction => Task 4, Epoch 2/170 => Loss 3.315, Train_accy 78.400, Test_accy 64.560
2022-11-28 20:04:29,846 [bic.py] => bias_correction => Task 4, Epoch 3/170 => Loss 3.253, Train_accy 79.200, Test_accy 62.200
2022-11-28 20:04:33,196 [bic.py] => bias_correction => Task 4, Epoch 4/170 => Loss 3.282, Train_accy 76.400, Test_accy 58.800
2022-11-28 20:04:36,415 [bic.py] => bias_correction => Task 4, Epoch 5/170 => Loss 3.296, Train_accy 76.000, Test_accy 57.960
2022-11-28 20:04:39,783 [bic.py] => bias_correction => Task 4, Epoch 6/170 => Loss 3.289, Train_accy 76.800, Test_accy 59.360
2022-11-28 20:04:43,153 [bic.py] => bias_correction => Task 4, Epoch 7/170 => Loss 3.292, Train_accy 79.200, Test_accy 62.120
2022-11-28 20:04:46,493 [bic.py] => bias_correction => Task 4, Epoch 8/170 => Loss 3.272, Train_accy 82.000, Test_accy 64.120
2022-11-28 20:04:49,749 [bic.py] => bias_correction => Task 4, Epoch 9/170 => Loss 3.282, Train_accy 78.800, Test_accy 63.980
2022-11-28 20:04:53,179 [bic.py] => bias_correction => Task 4, Epoch 10/170 => Loss 3.311, Train_accy 75.600, Test_accy 63.520
2022-11-28 20:04:56,664 [bic.py] => bias_correction => Task 4, Epoch 11/170 => Loss 3.286, Train_accy 80.800, Test_accy 64.120
2022-11-28 20:05:00,039 [bic.py] => bias_correction => Task 4, Epoch 12/170 => Loss 3.268, Train_accy 78.000, Test_accy 63.660
2022-11-28 20:05:03,492 [bic.py] => bias_correction => Task 4, Epoch 13/170 => Loss 3.277, Train_accy 80.800, Test_accy 62.260
2022-11-28 20:05:06,894 [bic.py] => bias_correction => Task 4, Epoch 14/170 => Loss 3.273, Train_accy 78.800, Test_accy 61.960
2022-11-28 20:05:10,151 [bic.py] => bias_correction => Task 4, Epoch 15/170 => Loss 3.283, Train_accy 76.400, Test_accy 61.960
2022-11-28 20:05:13,605 [bic.py] => bias_correction => Task 4, Epoch 16/170 => Loss 3.287, Train_accy 80.800, Test_accy 62.920
2022-11-28 20:05:16,972 [bic.py] => bias_correction => Task 4, Epoch 17/170 => Loss 3.263, Train_accy 78.000, Test_accy 64.220
2022-11-28 20:05:20,274 [bic.py] => bias_correction => Task 4, Epoch 18/170 => Loss 3.268, Train_accy 78.000, Test_accy 64.440
2022-11-28 20:05:23,748 [bic.py] => bias_correction => Task 4, Epoch 19/170 => Loss 3.267, Train_accy 78.400, Test_accy 64.260
2022-11-28 20:05:27,129 [bic.py] => bias_correction => Task 4, Epoch 20/170 => Loss 3.261, Train_accy 78.800, Test_accy 64.120
2022-11-28 20:05:30,537 [bic.py] => bias_correction => Task 4, Epoch 21/170 => Loss 3.253, Train_accy 77.600, Test_accy 63.840
2022-11-28 20:05:33,980 [bic.py] => bias_correction => Task 4, Epoch 22/170 => Loss 3.272, Train_accy 78.000, Test_accy 63.720
2022-11-28 20:05:37,325 [bic.py] => bias_correction => Task 4, Epoch 23/170 => Loss 3.275, Train_accy 80.000, Test_accy 63.820
2022-11-28 20:05:40,637 [bic.py] => bias_correction => Task 4, Epoch 24/170 => Loss 3.267, Train_accy 79.600, Test_accy 64.160
2022-11-28 20:05:43,962 [bic.py] => bias_correction => Task 4, Epoch 25/170 => Loss 3.271, Train_accy 80.400, Test_accy 64.280
2022-11-28 20:05:47,429 [bic.py] => bias_correction => Task 4, Epoch 26/170 => Loss 3.254, Train_accy 78.800, Test_accy 64.240
2022-11-28 20:05:50,716 [bic.py] => bias_correction => Task 4, Epoch 27/170 => Loss 3.274, Train_accy 79.200, Test_accy 64.180
2022-11-28 20:05:54,067 [bic.py] => bias_correction => Task 4, Epoch 28/170 => Loss 3.268, Train_accy 79.200, Test_accy 64.040
2022-11-28 20:05:57,375 [bic.py] => bias_correction => Task 4, Epoch 29/170 => Loss 3.275, Train_accy 78.800, Test_accy 63.940
2022-11-28 20:06:00,630 [bic.py] => bias_correction => Task 4, Epoch 30/170 => Loss 3.276, Train_accy 76.400, Test_accy 63.700
2022-11-28 20:06:03,924 [bic.py] => bias_correction => Task 4, Epoch 31/170 => Loss 3.272, Train_accy 79.600, Test_accy 63.900
2022-11-28 20:06:07,274 [bic.py] => bias_correction => Task 4, Epoch 32/170 => Loss 3.285, Train_accy 79.200, Test_accy 64.100
2022-11-28 20:06:10,549 [bic.py] => bias_correction => Task 4, Epoch 33/170 => Loss 3.276, Train_accy 79.600, Test_accy 64.360
2022-11-28 20:06:13,743 [bic.py] => bias_correction => Task 4, Epoch 34/170 => Loss 3.255, Train_accy 77.600, Test_accy 64.380
2022-11-28 20:06:16,987 [bic.py] => bias_correction => Task 4, Epoch 35/170 => Loss 3.271, Train_accy 78.000, Test_accy 64.460
2022-11-28 20:06:20,378 [bic.py] => bias_correction => Task 4, Epoch 36/170 => Loss 3.278, Train_accy 80.000, Test_accy 64.460
2022-11-28 20:06:23,965 [bic.py] => bias_correction => Task 4, Epoch 37/170 => Loss 3.276, Train_accy 78.800, Test_accy 64.400
2022-11-28 20:06:27,256 [bic.py] => bias_correction => Task 4, Epoch 38/170 => Loss 3.276, Train_accy 80.400, Test_accy 64.480
2022-11-28 20:06:30,673 [bic.py] => bias_correction => Task 4, Epoch 39/170 => Loss 3.276, Train_accy 79.600, Test_accy 64.480
2022-11-28 20:06:33,994 [bic.py] => bias_correction => Task 4, Epoch 40/170 => Loss 3.267, Train_accy 79.600, Test_accy 64.120
2022-11-28 20:06:37,308 [bic.py] => bias_correction => Task 4, Epoch 41/170 => Loss 3.261, Train_accy 78.000, Test_accy 63.660
2022-11-28 20:06:40,688 [bic.py] => bias_correction => Task 4, Epoch 42/170 => Loss 3.263, Train_accy 77.600, Test_accy 63.440
2022-11-28 20:06:44,147 [bic.py] => bias_correction => Task 4, Epoch 43/170 => Loss 3.273, Train_accy 77.600, Test_accy 63.440
2022-11-28 20:06:47,402 [bic.py] => bias_correction => Task 4, Epoch 44/170 => Loss 3.257, Train_accy 80.400, Test_accy 64.020
2022-11-28 20:06:50,763 [bic.py] => bias_correction => Task 4, Epoch 45/170 => Loss 3.265, Train_accy 76.000, Test_accy 64.340
2022-11-28 20:06:54,103 [bic.py] => bias_correction => Task 4, Epoch 46/170 => Loss 3.272, Train_accy 80.800, Test_accy 64.380
2022-11-28 20:06:57,426 [bic.py] => bias_correction => Task 4, Epoch 47/170 => Loss 3.282, Train_accy 77.200, Test_accy 64.320
2022-11-28 20:07:00,937 [bic.py] => bias_correction => Task 4, Epoch 48/170 => Loss 3.265, Train_accy 78.400, Test_accy 64.180
2022-11-28 20:07:04,224 [bic.py] => bias_correction => Task 4, Epoch 49/170 => Loss 3.265, Train_accy 80.800, Test_accy 64.380
2022-11-28 20:07:07,449 [bic.py] => bias_correction => Task 4, Epoch 50/170 => Loss 3.263, Train_accy 78.000, Test_accy 64.080
2022-11-28 20:07:10,616 [bic.py] => bias_correction => Task 4, Epoch 51/170 => Loss 3.255, Train_accy 77.200, Test_accy 64.120
2022-11-28 20:07:13,828 [bic.py] => bias_correction => Task 4, Epoch 52/170 => Loss 3.281, Train_accy 78.000, Test_accy 63.940
2022-11-28 20:07:17,131 [bic.py] => bias_correction => Task 4, Epoch 53/170 => Loss 3.265, Train_accy 80.800, Test_accy 63.940
2022-11-28 20:07:20,394 [bic.py] => bias_correction => Task 4, Epoch 54/170 => Loss 3.266, Train_accy 79.200, Test_accy 64.240
2022-11-28 20:07:23,667 [bic.py] => bias_correction => Task 4, Epoch 55/170 => Loss 3.261, Train_accy 80.000, Test_accy 64.560
2022-11-28 20:07:26,960 [bic.py] => bias_correction => Task 4, Epoch 56/170 => Loss 3.276, Train_accy 77.200, Test_accy 64.620
2022-11-28 20:07:30,384 [bic.py] => bias_correction => Task 4, Epoch 57/170 => Loss 3.267, Train_accy 79.600, Test_accy 64.420
2022-11-28 20:07:33,817 [bic.py] => bias_correction => Task 4, Epoch 58/170 => Loss 3.264, Train_accy 77.200, Test_accy 64.500
2022-11-28 20:07:37,168 [bic.py] => bias_correction => Task 4, Epoch 59/170 => Loss 3.275, Train_accy 80.800, Test_accy 64.360
2022-11-28 20:07:40,421 [bic.py] => bias_correction => Task 4, Epoch 60/170 => Loss 3.281, Train_accy 77.600, Test_accy 64.340
2022-11-28 20:07:43,781 [bic.py] => bias_correction => Task 4, Epoch 61/170 => Loss 3.264, Train_accy 78.400, Test_accy 64.520
2022-11-28 20:07:47,025 [bic.py] => bias_correction => Task 4, Epoch 62/170 => Loss 3.249, Train_accy 80.400, Test_accy 64.520
2022-11-28 20:07:50,301 [bic.py] => bias_correction => Task 4, Epoch 63/170 => Loss 3.251, Train_accy 76.400, Test_accy 64.400
2022-11-28 20:07:53,838 [bic.py] => bias_correction => Task 4, Epoch 64/170 => Loss 3.275, Train_accy 79.200, Test_accy 64.640
2022-11-28 20:07:57,098 [bic.py] => bias_correction => Task 4, Epoch 65/170 => Loss 3.264, Train_accy 81.200, Test_accy 64.720
2022-11-28 20:08:00,406 [bic.py] => bias_correction => Task 4, Epoch 66/170 => Loss 3.266, Train_accy 78.400, Test_accy 64.520
2022-11-28 20:08:03,644 [bic.py] => bias_correction => Task 4, Epoch 67/170 => Loss 3.264, Train_accy 77.600, Test_accy 64.840
2022-11-28 20:08:06,903 [bic.py] => bias_correction => Task 4, Epoch 68/170 => Loss 3.260, Train_accy 81.600, Test_accy 64.880
2022-11-28 20:08:10,302 [bic.py] => bias_correction => Task 4, Epoch 69/170 => Loss 3.259, Train_accy 78.000, Test_accy 64.440
2022-11-28 20:08:13,531 [bic.py] => bias_correction => Task 4, Epoch 70/170 => Loss 3.265, Train_accy 80.800, Test_accy 64.460
2022-11-28 20:08:16,913 [bic.py] => bias_correction => Task 4, Epoch 71/170 => Loss 3.273, Train_accy 78.400, Test_accy 64.420
2022-11-28 20:08:20,246 [bic.py] => bias_correction => Task 4, Epoch 72/170 => Loss 3.263, Train_accy 80.800, Test_accy 64.420
2022-11-28 20:08:23,578 [bic.py] => bias_correction => Task 4, Epoch 73/170 => Loss 3.264, Train_accy 80.400, Test_accy 64.280
2022-11-28 20:08:26,812 [bic.py] => bias_correction => Task 4, Epoch 74/170 => Loss 3.279, Train_accy 77.600, Test_accy 64.260
2022-11-28 20:08:30,159 [bic.py] => bias_correction => Task 4, Epoch 75/170 => Loss 3.273, Train_accy 81.600, Test_accy 64.040
2022-11-28 20:08:33,424 [bic.py] => bias_correction => Task 4, Epoch 76/170 => Loss 3.264, Train_accy 80.000, Test_accy 64.200
2022-11-28 20:08:36,711 [bic.py] => bias_correction => Task 4, Epoch 77/170 => Loss 3.271, Train_accy 79.600, Test_accy 64.040
2022-11-28 20:08:40,207 [bic.py] => bias_correction => Task 4, Epoch 78/170 => Loss 3.256, Train_accy 77.600, Test_accy 64.360
2022-11-28 20:08:43,656 [bic.py] => bias_correction => Task 4, Epoch 79/170 => Loss 3.251, Train_accy 79.200, Test_accy 64.500
2022-11-28 20:08:47,163 [bic.py] => bias_correction => Task 4, Epoch 80/170 => Loss 3.258, Train_accy 78.000, Test_accy 64.440
2022-11-28 20:08:50,631 [bic.py] => bias_correction => Task 4, Epoch 81/170 => Loss 3.274, Train_accy 80.000, Test_accy 64.300
2022-11-28 20:08:54,039 [bic.py] => bias_correction => Task 4, Epoch 82/170 => Loss 3.265, Train_accy 77.600, Test_accy 64.600
2022-11-28 20:08:57,462 [bic.py] => bias_correction => Task 4, Epoch 83/170 => Loss 3.263, Train_accy 79.200, Test_accy 64.620
2022-11-28 20:09:01,009 [bic.py] => bias_correction => Task 4, Epoch 84/170 => Loss 3.260, Train_accy 78.800, Test_accy 64.580
2022-11-28 20:09:04,528 [bic.py] => bias_correction => Task 4, Epoch 85/170 => Loss 3.269, Train_accy 80.400, Test_accy 64.540
2022-11-28 20:09:07,788 [bic.py] => bias_correction => Task 4, Epoch 86/170 => Loss 3.260, Train_accy 78.400, Test_accy 64.500
2022-11-28 20:09:11,132 [bic.py] => bias_correction => Task 4, Epoch 87/170 => Loss 3.265, Train_accy 81.200, Test_accy 64.500
2022-11-28 20:09:14,477 [bic.py] => bias_correction => Task 4, Epoch 88/170 => Loss 3.284, Train_accy 77.600, Test_accy 64.400
2022-11-28 20:09:17,781 [bic.py] => bias_correction => Task 4, Epoch 89/170 => Loss 3.273, Train_accy 79.600, Test_accy 64.400
2022-11-28 20:09:21,082 [bic.py] => bias_correction => Task 4, Epoch 90/170 => Loss 3.274, Train_accy 78.000, Test_accy 64.280
2022-11-28 20:09:24,438 [bic.py] => bias_correction => Task 4, Epoch 91/170 => Loss 3.246, Train_accy 77.600, Test_accy 64.500
2022-11-28 20:09:27,746 [bic.py] => bias_correction => Task 4, Epoch 92/170 => Loss 3.264, Train_accy 79.600, Test_accy 64.240
2022-11-28 20:09:31,060 [bic.py] => bias_correction => Task 4, Epoch 93/170 => Loss 3.268, Train_accy 78.800, Test_accy 64.280
2022-11-28 20:09:34,559 [bic.py] => bias_correction => Task 4, Epoch 94/170 => Loss 3.276, Train_accy 79.200, Test_accy 64.660
2022-11-28 20:09:37,985 [bic.py] => bias_correction => Task 4, Epoch 95/170 => Loss 3.264, Train_accy 82.000, Test_accy 64.540
2022-11-28 20:09:41,188 [bic.py] => bias_correction => Task 4, Epoch 96/170 => Loss 3.260, Train_accy 80.000, Test_accy 64.360
2022-11-28 20:09:44,572 [bic.py] => bias_correction => Task 4, Epoch 97/170 => Loss 3.272, Train_accy 79.200, Test_accy 64.500
2022-11-28 20:09:47,901 [bic.py] => bias_correction => Task 4, Epoch 98/170 => Loss 3.263, Train_accy 78.000, Test_accy 64.420
2022-11-28 20:09:51,129 [bic.py] => bias_correction => Task 4, Epoch 99/170 => Loss 3.240, Train_accy 81.200, Test_accy 64.260
2022-11-28 20:09:54,475 [bic.py] => bias_correction => Task 4, Epoch 100/170 => Loss 3.256, Train_accy 79.600, Test_accy 64.120
2022-11-28 20:09:57,902 [bic.py] => bias_correction => Task 4, Epoch 101/170 => Loss 3.269, Train_accy 78.400, Test_accy 64.260
2022-11-28 20:10:01,257 [bic.py] => bias_correction => Task 4, Epoch 102/170 => Loss 3.264, Train_accy 78.400, Test_accy 64.260
2022-11-28 20:10:04,637 [bic.py] => bias_correction => Task 4, Epoch 103/170 => Loss 3.259, Train_accy 78.400, Test_accy 64.480
2022-11-28 20:10:08,096 [bic.py] => bias_correction => Task 4, Epoch 104/170 => Loss 3.249, Train_accy 78.800, Test_accy 64.240
2022-11-28 20:10:11,439 [bic.py] => bias_correction => Task 4, Epoch 105/170 => Loss 3.274, Train_accy 78.400, Test_accy 64.400
2022-11-28 20:10:14,656 [bic.py] => bias_correction => Task 4, Epoch 106/170 => Loss 3.267, Train_accy 78.000, Test_accy 64.380
2022-11-28 20:10:17,914 [bic.py] => bias_correction => Task 4, Epoch 107/170 => Loss 3.269, Train_accy 81.200, Test_accy 64.520
2022-11-28 20:10:21,238 [bic.py] => bias_correction => Task 4, Epoch 108/170 => Loss 3.255, Train_accy 78.800, Test_accy 64.540
2022-11-28 20:10:24,405 [bic.py] => bias_correction => Task 4, Epoch 109/170 => Loss 3.265, Train_accy 79.600, Test_accy 64.500
2022-11-28 20:10:27,775 [bic.py] => bias_correction => Task 4, Epoch 110/170 => Loss 3.274, Train_accy 80.800, Test_accy 64.460
2022-11-28 20:10:31,163 [bic.py] => bias_correction => Task 4, Epoch 111/170 => Loss 3.274, Train_accy 82.400, Test_accy 64.500
2022-11-28 20:10:34,484 [bic.py] => bias_correction => Task 4, Epoch 112/170 => Loss 3.254, Train_accy 78.000, Test_accy 64.440
2022-11-28 20:10:37,892 [bic.py] => bias_correction => Task 4, Epoch 113/170 => Loss 3.268, Train_accy 78.000, Test_accy 64.420
2022-11-28 20:10:41,175 [bic.py] => bias_correction => Task 4, Epoch 114/170 => Loss 3.270, Train_accy 79.200, Test_accy 64.280
2022-11-28 20:10:44,459 [bic.py] => bias_correction => Task 4, Epoch 115/170 => Loss 3.263, Train_accy 79.200, Test_accy 64.260
2022-11-28 20:10:47,976 [bic.py] => bias_correction => Task 4, Epoch 116/170 => Loss 3.262, Train_accy 80.000, Test_accy 64.500
2022-11-28 20:10:51,309 [bic.py] => bias_correction => Task 4, Epoch 117/170 => Loss 3.270, Train_accy 77.600, Test_accy 64.300
2022-11-28 20:10:54,747 [bic.py] => bias_correction => Task 4, Epoch 118/170 => Loss 3.255, Train_accy 75.600, Test_accy 64.320
2022-11-28 20:10:58,034 [bic.py] => bias_correction => Task 4, Epoch 119/170 => Loss 3.281, Train_accy 78.800, Test_accy 64.340
2022-11-28 20:11:01,205 [bic.py] => bias_correction => Task 4, Epoch 120/170 => Loss 3.272, Train_accy 80.000, Test_accy 64.540
2022-11-28 20:11:04,577 [bic.py] => bias_correction => Task 4, Epoch 121/170 => Loss 3.257, Train_accy 78.000, Test_accy 64.320
2022-11-28 20:11:08,089 [bic.py] => bias_correction => Task 4, Epoch 122/170 => Loss 3.257, Train_accy 76.800, Test_accy 64.200
2022-11-28 20:11:11,538 [bic.py] => bias_correction => Task 4, Epoch 123/170 => Loss 3.278, Train_accy 80.400, Test_accy 64.240
2022-11-28 20:11:14,821 [bic.py] => bias_correction => Task 4, Epoch 124/170 => Loss 3.282, Train_accy 78.400, Test_accy 64.300
2022-11-28 20:11:18,181 [bic.py] => bias_correction => Task 4, Epoch 125/170 => Loss 3.268, Train_accy 79.200, Test_accy 64.320
2022-11-28 20:11:21,492 [bic.py] => bias_correction => Task 4, Epoch 126/170 => Loss 3.246, Train_accy 79.600, Test_accy 64.360
2022-11-28 20:11:24,701 [bic.py] => bias_correction => Task 4, Epoch 127/170 => Loss 3.253, Train_accy 77.200, Test_accy 64.460
2022-11-28 20:11:27,965 [bic.py] => bias_correction => Task 4, Epoch 128/170 => Loss 3.267, Train_accy 77.200, Test_accy 64.580
2022-11-28 20:11:31,146 [bic.py] => bias_correction => Task 4, Epoch 129/170 => Loss 3.268, Train_accy 79.600, Test_accy 64.380
2022-11-28 20:11:34,321 [bic.py] => bias_correction => Task 4, Epoch 130/170 => Loss 3.256, Train_accy 78.000, Test_accy 64.400
2022-11-28 20:11:37,761 [bic.py] => bias_correction => Task 4, Epoch 131/170 => Loss 3.266, Train_accy 80.000, Test_accy 64.380
2022-11-28 20:11:41,022 [bic.py] => bias_correction => Task 4, Epoch 132/170 => Loss 3.258, Train_accy 78.800, Test_accy 64.380
2022-11-28 20:11:44,399 [bic.py] => bias_correction => Task 4, Epoch 133/170 => Loss 3.262, Train_accy 78.800, Test_accy 64.260
2022-11-28 20:11:47,742 [bic.py] => bias_correction => Task 4, Epoch 134/170 => Loss 3.261, Train_accy 77.600, Test_accy 64.300
2022-11-28 20:11:51,243 [bic.py] => bias_correction => Task 4, Epoch 135/170 => Loss 3.247, Train_accy 78.000, Test_accy 64.140
2022-11-28 20:11:54,671 [bic.py] => bias_correction => Task 4, Epoch 136/170 => Loss 3.260, Train_accy 81.600, Test_accy 64.180
2022-11-28 20:11:58,354 [bic.py] => bias_correction => Task 4, Epoch 137/170 => Loss 3.264, Train_accy 79.200, Test_accy 64.240
2022-11-28 20:12:01,710 [bic.py] => bias_correction => Task 4, Epoch 138/170 => Loss 3.273, Train_accy 79.600, Test_accy 64.180
2022-11-28 20:12:05,279 [bic.py] => bias_correction => Task 4, Epoch 139/170 => Loss 3.258, Train_accy 80.400, Test_accy 64.420
2022-11-28 20:12:08,687 [bic.py] => bias_correction => Task 4, Epoch 140/170 => Loss 3.257, Train_accy 79.200, Test_accy 64.320
2022-11-28 20:12:11,874 [bic.py] => bias_correction => Task 4, Epoch 141/170 => Loss 3.282, Train_accy 80.400, Test_accy 64.300
2022-11-28 20:12:15,279 [bic.py] => bias_correction => Task 4, Epoch 142/170 => Loss 3.263, Train_accy 79.600, Test_accy 64.340
2022-11-28 20:12:18,623 [bic.py] => bias_correction => Task 4, Epoch 143/170 => Loss 3.275, Train_accy 80.400, Test_accy 64.500
2022-11-28 20:12:21,963 [bic.py] => bias_correction => Task 4, Epoch 144/170 => Loss 3.262, Train_accy 77.600, Test_accy 64.280
2022-11-28 20:12:25,102 [bic.py] => bias_correction => Task 4, Epoch 145/170 => Loss 3.262, Train_accy 78.800, Test_accy 64.320
2022-11-28 20:12:28,467 [bic.py] => bias_correction => Task 4, Epoch 146/170 => Loss 3.271, Train_accy 81.200, Test_accy 64.360
2022-11-28 20:12:31,810 [bic.py] => bias_correction => Task 4, Epoch 147/170 => Loss 3.270, Train_accy 79.600, Test_accy 64.520
2022-11-28 20:12:35,288 [bic.py] => bias_correction => Task 4, Epoch 148/170 => Loss 3.277, Train_accy 79.200, Test_accy 64.540
2022-11-28 20:12:38,670 [bic.py] => bias_correction => Task 4, Epoch 149/170 => Loss 3.259, Train_accy 78.800, Test_accy 64.460
2022-11-28 20:12:42,000 [bic.py] => bias_correction => Task 4, Epoch 150/170 => Loss 3.262, Train_accy 76.400, Test_accy 64.320
2022-11-28 20:12:45,503 [bic.py] => bias_correction => Task 4, Epoch 151/170 => Loss 3.272, Train_accy 80.000, Test_accy 64.320
2022-11-28 20:12:48,887 [bic.py] => bias_correction => Task 4, Epoch 152/170 => Loss 3.271, Train_accy 78.400, Test_accy 64.460
2022-11-28 20:12:52,512 [bic.py] => bias_correction => Task 4, Epoch 153/170 => Loss 3.250, Train_accy 79.200, Test_accy 64.500
2022-11-28 20:12:55,849 [bic.py] => bias_correction => Task 4, Epoch 154/170 => Loss 3.259, Train_accy 79.200, Test_accy 64.400
2022-11-28 20:12:59,224 [bic.py] => bias_correction => Task 4, Epoch 155/170 => Loss 3.274, Train_accy 79.600, Test_accy 64.560
2022-11-28 20:13:02,383 [bic.py] => bias_correction => Task 4, Epoch 156/170 => Loss 3.258, Train_accy 81.600, Test_accy 64.340
2022-11-28 20:13:05,920 [bic.py] => bias_correction => Task 4, Epoch 157/170 => Loss 3.277, Train_accy 79.200, Test_accy 64.320
2022-11-28 20:13:09,469 [bic.py] => bias_correction => Task 4, Epoch 158/170 => Loss 3.266, Train_accy 78.800, Test_accy 64.220
2022-11-28 20:13:12,904 [bic.py] => bias_correction => Task 4, Epoch 159/170 => Loss 3.266, Train_accy 80.800, Test_accy 64.120
2022-11-28 20:13:16,184 [bic.py] => bias_correction => Task 4, Epoch 160/170 => Loss 3.256, Train_accy 79.600, Test_accy 64.120
2022-11-28 20:13:19,530 [bic.py] => bias_correction => Task 4, Epoch 161/170 => Loss 3.252, Train_accy 76.800, Test_accy 64.260
2022-11-28 20:13:23,093 [bic.py] => bias_correction => Task 4, Epoch 162/170 => Loss 3.260, Train_accy 79.600, Test_accy 64.260
2022-11-28 20:13:26,457 [bic.py] => bias_correction => Task 4, Epoch 163/170 => Loss 3.255, Train_accy 80.000, Test_accy 64.720
2022-11-28 20:13:29,826 [bic.py] => bias_correction => Task 4, Epoch 164/170 => Loss 3.268, Train_accy 79.600, Test_accy 64.620
2022-11-28 20:13:33,370 [bic.py] => bias_correction => Task 4, Epoch 165/170 => Loss 3.248, Train_accy 78.000, Test_accy 64.640
2022-11-28 20:13:36,738 [bic.py] => bias_correction => Task 4, Epoch 166/170 => Loss 3.258, Train_accy 80.800, Test_accy 64.460
2022-11-28 20:13:40,049 [bic.py] => bias_correction => Task 4, Epoch 167/170 => Loss 3.271, Train_accy 80.800, Test_accy 64.580
2022-11-28 20:13:43,440 [bic.py] => bias_correction => Task 4, Epoch 168/170 => Loss 3.261, Train_accy 77.600, Test_accy 64.260
2022-11-28 20:13:46,740 [bic.py] => bias_correction => Task 4, Epoch 169/170 => Loss 3.273, Train_accy 78.000, Test_accy 64.400
2022-11-28 20:13:50,158 [bic.py] => bias_correction => Task 4, Epoch 170/170 => Loss 3.265, Train_accy 76.800, Test_accy 64.420
2022-11-28 20:13:50,159 [base.py] => Reducing exemplars...(40 per classes)
2022-11-28 20:14:06,647 [base.py] => Constructing exemplars...(40 per classes)
2022-11-28 20:14:15,955 [bic.py] => Parameters of bias layer:
2022-11-28 20:14:15,955 [bic.py] => 0 => 1.000, 0.000
2022-11-28 20:14:15,955 [bic.py] => 1 => 0.976, -1.640
2022-11-28 20:14:15,956 [bic.py] => 2 => 0.847, -1.789
2022-11-28 20:14:15,956 [bic.py] => 3 => 0.728, -1.453
2022-11-28 20:14:15,956 [bic.py] => 4 => 0.739, -1.271
2022-11-28 20:14:17,941 [bic.py] => Exemplar size: 2000
2022-11-28 20:14:17,941 [trainer.py] => CNN: {'total': 64.42, '00-09': 70.2, '10-19': 56.7, '20-29': 68.2, '30-39': 58.0, '40-49': 69.0, 'old': 63.28, 'new': 69.0}
2022-11-28 20:14:17,941 [trainer.py] => NME: {'total': 64.22, '00-09': 66.3, '10-19': 49.4, '20-29': 65.8, '30-39': 61.9, '40-49': 77.7, 'old': 60.85, 'new': 77.7}
2022-11-28 20:14:17,941 [trainer.py] => CNN top1 curve: [88.7, 75.6, 72.3, 66.6, 64.42]
2022-11-28 20:14:17,941 [trainer.py] => CNN top5 curve: [99.4, 95.6, 93.5, 91.42, 90.66]
2022-11-28 20:14:17,941 [trainer.py] => NME top1 curve: [88.5, 75.85, 72.47, 66.72, 64.22]
2022-11-28 20:14:17,941 [trainer.py] => NME top5 curve: [99.4, 95.95, 93.8, 91.2, 89.16]

2022-11-28 20:14:17,942 [trainer.py] => All params: 467414
2022-11-28 20:14:17,942 [trainer.py] => Trainable params: 467414
2022-11-28 20:14:17,943 [bic.py] => Learning on 50-60
2022-11-28 20:14:17,983 [bic.py] => Stage1 dset: 6760, Stage2 dset: 240
2022-11-28 20:14:17,983 [bic.py] => Lambda: 0.833
2022-11-28 20:14:17,995 [bic.py] => Parameters of bias layer:
2022-11-28 20:14:17,996 [bic.py] => 0 => 1.000, 0.000
2022-11-28 20:14:17,996 [bic.py] => 1 => 0.976, -1.640
2022-11-28 20:14:17,996 [bic.py] => 2 => 0.847, -1.789
2022-11-28 20:14:17,996 [bic.py] => 3 => 0.728, -1.453
2022-11-28 20:14:17,996 [bic.py] => 4 => 0.739, -1.271
2022-11-28 20:14:17,996 [bic.py] => 5 => 1.000, 0.000
2022-11-28 20:14:26,118 [bic.py] => training => Task 5, Epoch 1/170 => Loss 2.478, Train_accy 66.350, Test_accy 40.420
2022-11-28 20:14:34,455 [bic.py] => training => Task 5, Epoch 2/170 => Loss 2.353, Train_accy 70.000, Test_accy 44.320
2022-11-28 20:14:42,140 [bic.py] => training => Task 5, Epoch 3/170 => Loss 2.333, Train_accy 75.280, Test_accy 43.730
2022-11-28 20:14:50,026 [bic.py] => training => Task 5, Epoch 4/170 => Loss 2.310, Train_accy 76.730, Test_accy 43.620
2022-11-28 20:14:58,652 [bic.py] => training => Task 5, Epoch 5/170 => Loss 2.312, Train_accy 77.690, Test_accy 46.370
2022-11-28 20:15:06,486 [bic.py] => training => Task 5, Epoch 6/170 => Loss 2.304, Train_accy 75.310, Test_accy 42.650
2022-11-28 20:15:14,790 [bic.py] => training => Task 5, Epoch 7/170 => Loss 2.292, Train_accy 79.300, Test_accy 47.520
2022-11-28 20:15:23,217 [bic.py] => training => Task 5, Epoch 8/170 => Loss 2.293, Train_accy 79.630, Test_accy 45.700
2022-11-28 20:15:31,277 [bic.py] => training => Task 5, Epoch 9/170 => Loss 2.293, Train_accy 82.500, Test_accy 48.630
2022-11-28 20:15:39,330 [bic.py] => training => Task 5, Epoch 10/170 => Loss 2.286, Train_accy 83.060, Test_accy 47.200
2022-11-28 20:15:47,177 [bic.py] => training => Task 5, Epoch 11/170 => Loss 2.282, Train_accy 82.170, Test_accy 48.330
2022-11-28 20:15:55,034 [bic.py] => training => Task 5, Epoch 12/170 => Loss 2.276, Train_accy 84.700, Test_accy 46.130
2022-11-28 20:16:03,579 [bic.py] => training => Task 5, Epoch 13/170 => Loss 2.277, Train_accy 84.790, Test_accy 48.050
2022-11-28 20:16:11,535 [bic.py] => training => Task 5, Epoch 14/170 => Loss 2.282, Train_accy 81.850, Test_accy 44.620
2022-11-28 20:16:20,009 [bic.py] => training => Task 5, Epoch 15/170 => Loss 2.266, Train_accy 81.550, Test_accy 47.000
2022-11-28 20:16:28,688 [bic.py] => training => Task 5, Epoch 16/170 => Loss 2.269, Train_accy 84.530, Test_accy 46.950
2022-11-28 20:16:36,481 [bic.py] => training => Task 5, Epoch 17/170 => Loss 2.267, Train_accy 84.930, Test_accy 48.830
2022-11-28 20:16:44,610 [bic.py] => training => Task 5, Epoch 18/170 => Loss 2.266, Train_accy 86.920, Test_accy 45.780
2022-11-28 20:16:52,773 [bic.py] => training => Task 5, Epoch 19/170 => Loss 2.263, Train_accy 86.660, Test_accy 48.530
2022-11-28 20:17:01,138 [bic.py] => training => Task 5, Epoch 20/170 => Loss 2.260, Train_accy 81.240, Test_accy 44.470
2022-11-28 20:17:08,920 [bic.py] => training => Task 5, Epoch 21/170 => Loss 2.270, Train_accy 80.030, Test_accy 42.630
2022-11-28 20:17:17,299 [bic.py] => training => Task 5, Epoch 22/170 => Loss 2.257, Train_accy 86.780, Test_accy 48.200
2022-11-28 20:17:25,749 [bic.py] => training => Task 5, Epoch 23/170 => Loss 2.252, Train_accy 87.340, Test_accy 48.120
2022-11-28 20:17:33,984 [bic.py] => training => Task 5, Epoch 24/170 => Loss 2.250, Train_accy 88.820, Test_accy 48.070
2022-11-28 20:17:42,149 [bic.py] => training => Task 5, Epoch 25/170 => Loss 2.260, Train_accy 85.040, Test_accy 45.720
2022-11-28 20:17:50,267 [bic.py] => training => Task 5, Epoch 26/170 => Loss 2.261, Train_accy 90.720, Test_accy 49.350
2022-11-28 20:17:58,742 [bic.py] => training => Task 5, Epoch 27/170 => Loss 2.258, Train_accy 88.390, Test_accy 48.900
2022-11-28 20:18:07,088 [bic.py] => training => Task 5, Epoch 28/170 => Loss 2.250, Train_accy 87.970, Test_accy 47.950
2022-11-28 20:18:15,272 [bic.py] => training => Task 5, Epoch 29/170 => Loss 2.245, Train_accy 90.280, Test_accy 47.980
2022-11-28 20:18:23,684 [bic.py] => training => Task 5, Epoch 30/170 => Loss 2.255, Train_accy 88.110, Test_accy 47.680
2022-11-28 20:18:31,692 [bic.py] => training => Task 5, Epoch 31/170 => Loss 2.245, Train_accy 88.420, Test_accy 46.400
2022-11-28 20:18:39,844 [bic.py] => training => Task 5, Epoch 32/170 => Loss 2.244, Train_accy 87.000, Test_accy 45.680
2022-11-28 20:18:47,812 [bic.py] => training => Task 5, Epoch 33/170 => Loss 2.252, Train_accy 89.220, Test_accy 49.280
2022-11-28 20:18:56,475 [bic.py] => training => Task 5, Epoch 34/170 => Loss 2.253, Train_accy 86.880, Test_accy 46.470
2022-11-28 20:19:04,208 [bic.py] => training => Task 5, Epoch 35/170 => Loss 2.256, Train_accy 85.840, Test_accy 47.770
2022-11-28 20:19:12,659 [bic.py] => training => Task 5, Epoch 36/170 => Loss 2.248, Train_accy 89.590, Test_accy 46.680
2022-11-28 20:19:21,015 [bic.py] => training => Task 5, Epoch 37/170 => Loss 2.251, Train_accy 88.570, Test_accy 49.500
2022-11-28 20:19:29,310 [bic.py] => training => Task 5, Epoch 38/170 => Loss 2.241, Train_accy 90.720, Test_accy 49.820
2022-11-28 20:19:37,335 [bic.py] => training => Task 5, Epoch 39/170 => Loss 2.248, Train_accy 92.070, Test_accy 49.550
2022-11-28 20:19:45,760 [bic.py] => training => Task 5, Epoch 40/170 => Loss 2.242, Train_accy 91.540, Test_accy 50.700
2022-11-28 20:19:53,896 [bic.py] => training => Task 5, Epoch 41/170 => Loss 2.249, Train_accy 90.030, Test_accy 45.370
2022-11-28 20:20:02,245 [bic.py] => training => Task 5, Epoch 42/170 => Loss 2.236, Train_accy 90.550, Test_accy 49.350
2022-11-28 20:20:10,632 [bic.py] => training => Task 5, Epoch 43/170 => Loss 2.238, Train_accy 90.720, Test_accy 49.550
2022-11-28 20:20:18,845 [bic.py] => training => Task 5, Epoch 44/170 => Loss 2.243, Train_accy 92.650, Test_accy 48.670
2022-11-28 20:20:27,048 [bic.py] => training => Task 5, Epoch 45/170 => Loss 2.236, Train_accy 90.900, Test_accy 48.670
2022-11-28 20:20:34,641 [bic.py] => training => Task 5, Epoch 46/170 => Loss 2.239, Train_accy 89.940, Test_accy 50.000
2022-11-28 20:20:42,850 [bic.py] => training => Task 5, Epoch 47/170 => Loss 2.240, Train_accy 87.930, Test_accy 48.980
2022-11-28 20:20:50,684 [bic.py] => training => Task 5, Epoch 48/170 => Loss 2.243, Train_accy 89.320, Test_accy 46.980
2022-11-28 20:20:59,182 [bic.py] => training => Task 5, Epoch 49/170 => Loss 2.237, Train_accy 89.420, Test_accy 45.880
2022-11-28 20:21:07,474 [bic.py] => training => Task 5, Epoch 50/170 => Loss 2.242, Train_accy 89.560, Test_accy 45.200
2022-11-28 20:21:16,050 [bic.py] => training => Task 5, Epoch 51/170 => Loss 2.239, Train_accy 88.850, Test_accy 46.280
2022-11-28 20:21:24,278 [bic.py] => training => Task 5, Epoch 52/170 => Loss 2.245, Train_accy 87.380, Test_accy 45.520
2022-11-28 20:21:32,027 [bic.py] => training => Task 5, Epoch 53/170 => Loss 2.236, Train_accy 86.980, Test_accy 44.930
2022-11-28 20:21:40,635 [bic.py] => training => Task 5, Epoch 54/170 => Loss 2.240, Train_accy 84.720, Test_accy 44.270
2022-11-28 20:21:48,456 [bic.py] => training => Task 5, Epoch 55/170 => Loss 2.241, Train_accy 89.560, Test_accy 47.620
2022-11-28 20:21:56,704 [bic.py] => training => Task 5, Epoch 56/170 => Loss 2.238, Train_accy 90.040, Test_accy 48.480
2022-11-28 20:22:04,834 [bic.py] => training => Task 5, Epoch 57/170 => Loss 2.233, Train_accy 92.410, Test_accy 47.830
2022-11-28 20:22:13,374 [bic.py] => training => Task 5, Epoch 58/170 => Loss 2.234, Train_accy 87.970, Test_accy 45.150
2022-11-28 20:22:21,314 [bic.py] => training => Task 5, Epoch 59/170 => Loss 2.235, Train_accy 91.200, Test_accy 45.370
2022-11-28 20:22:29,977 [bic.py] => training => Task 5, Epoch 60/170 => Loss 2.236, Train_accy 91.300, Test_accy 50.350
2022-11-28 20:22:38,198 [bic.py] => training => Task 5, Epoch 61/170 => Loss 2.205, Train_accy 97.320, Test_accy 53.370
2022-11-28 20:22:46,255 [bic.py] => training => Task 5, Epoch 62/170 => Loss 2.190, Train_accy 98.120, Test_accy 53.980
2022-11-28 20:22:54,457 [bic.py] => training => Task 5, Epoch 63/170 => Loss 2.184, Train_accy 98.360, Test_accy 53.580
2022-11-28 20:23:02,605 [bic.py] => training => Task 5, Epoch 64/170 => Loss 2.184, Train_accy 98.460, Test_accy 53.670
2022-11-28 20:23:10,577 [bic.py] => training => Task 5, Epoch 65/170 => Loss 2.175, Train_accy 98.480, Test_accy 54.030
2022-11-28 20:23:18,788 [bic.py] => training => Task 5, Epoch 66/170 => Loss 2.175, Train_accy 98.730, Test_accy 53.300
2022-11-28 20:23:27,240 [bic.py] => training => Task 5, Epoch 67/170 => Loss 2.175, Train_accy 98.460, Test_accy 52.850
2022-11-28 20:23:35,460 [bic.py] => training => Task 5, Epoch 68/170 => Loss 2.171, Train_accy 98.910, Test_accy 53.820
2022-11-28 20:23:43,756 [bic.py] => training => Task 5, Epoch 69/170 => Loss 2.169, Train_accy 98.570, Test_accy 53.700
2022-11-28 20:23:51,937 [bic.py] => training => Task 5, Epoch 70/170 => Loss 2.176, Train_accy 98.790, Test_accy 54.400
2022-11-28 20:24:00,499 [bic.py] => training => Task 5, Epoch 71/170 => Loss 2.174, Train_accy 98.790, Test_accy 53.370
2022-11-28 20:24:08,781 [bic.py] => training => Task 5, Epoch 72/170 => Loss 2.173, Train_accy 99.050, Test_accy 54.420
2022-11-28 20:24:16,856 [bic.py] => training => Task 5, Epoch 73/170 => Loss 2.170, Train_accy 98.850, Test_accy 53.200
2022-11-28 20:24:25,471 [bic.py] => training => Task 5, Epoch 74/170 => Loss 2.170, Train_accy 98.820, Test_accy 53.830
2022-11-28 20:24:33,473 [bic.py] => training => Task 5, Epoch 75/170 => Loss 2.165, Train_accy 98.800, Test_accy 54.020
2022-11-28 20:24:41,457 [bic.py] => training => Task 5, Epoch 76/170 => Loss 2.170, Train_accy 98.800, Test_accy 53.450
2022-11-28 20:24:49,762 [bic.py] => training => Task 5, Epoch 77/170 => Loss 2.170, Train_accy 98.960, Test_accy 53.870
2022-11-28 20:24:57,906 [bic.py] => training => Task 5, Epoch 78/170 => Loss 2.173, Train_accy 99.110, Test_accy 53.980
2022-11-28 20:25:05,850 [bic.py] => training => Task 5, Epoch 79/170 => Loss 2.162, Train_accy 99.200, Test_accy 54.100
2022-11-28 20:25:14,003 [bic.py] => training => Task 5, Epoch 80/170 => Loss 2.170, Train_accy 99.170, Test_accy 54.030
2022-11-28 20:25:22,407 [bic.py] => training => Task 5, Epoch 81/170 => Loss 2.168, Train_accy 99.080, Test_accy 53.850
2022-11-28 20:25:30,363 [bic.py] => training => Task 5, Epoch 82/170 => Loss 2.163, Train_accy 99.020, Test_accy 54.220
2022-11-28 20:25:38,337 [bic.py] => training => Task 5, Epoch 83/170 => Loss 2.166, Train_accy 99.110, Test_accy 54.420
2022-11-28 20:25:46,275 [bic.py] => training => Task 5, Epoch 84/170 => Loss 2.168, Train_accy 99.300, Test_accy 53.830
2022-11-28 20:25:55,122 [bic.py] => training => Task 5, Epoch 85/170 => Loss 2.166, Train_accy 99.110, Test_accy 53.920
2022-11-28 20:26:03,300 [bic.py] => training => Task 5, Epoch 86/170 => Loss 2.168, Train_accy 99.040, Test_accy 53.230
2022-11-28 20:26:11,734 [bic.py] => training => Task 5, Epoch 87/170 => Loss 2.170, Train_accy 99.100, Test_accy 52.680
2022-11-28 20:26:19,843 [bic.py] => training => Task 5, Epoch 88/170 => Loss 2.169, Train_accy 99.020, Test_accy 54.430
2022-11-28 20:26:28,082 [bic.py] => training => Task 5, Epoch 89/170 => Loss 2.162, Train_accy 99.200, Test_accy 53.830
2022-11-28 20:26:36,235 [bic.py] => training => Task 5, Epoch 90/170 => Loss 2.165, Train_accy 98.950, Test_accy 53.200
2022-11-28 20:26:44,451 [bic.py] => training => Task 5, Epoch 91/170 => Loss 2.162, Train_accy 99.250, Test_accy 54.570
2022-11-28 20:26:52,873 [bic.py] => training => Task 5, Epoch 92/170 => Loss 2.162, Train_accy 99.230, Test_accy 54.130
2022-11-28 20:27:01,351 [bic.py] => training => Task 5, Epoch 93/170 => Loss 2.164, Train_accy 99.190, Test_accy 53.670
2022-11-28 20:27:10,012 [bic.py] => training => Task 5, Epoch 94/170 => Loss 2.162, Train_accy 99.200, Test_accy 54.650
2022-11-28 20:27:18,006 [bic.py] => training => Task 5, Epoch 95/170 => Loss 2.163, Train_accy 99.280, Test_accy 53.700
2022-11-28 20:27:25,797 [bic.py] => training => Task 5, Epoch 96/170 => Loss 2.163, Train_accy 99.050, Test_accy 53.680
2022-11-28 20:27:33,756 [bic.py] => training => Task 5, Epoch 97/170 => Loss 2.162, Train_accy 99.260, Test_accy 54.000
2022-11-28 20:27:41,945 [bic.py] => training => Task 5, Epoch 98/170 => Loss 2.165, Train_accy 99.050, Test_accy 54.400
2022-11-28 20:27:49,897 [bic.py] => training => Task 5, Epoch 99/170 => Loss 2.160, Train_accy 99.040, Test_accy 53.980
2022-11-28 20:27:58,302 [bic.py] => training => Task 5, Epoch 100/170 => Loss 2.162, Train_accy 98.990, Test_accy 53.350
2022-11-28 20:28:06,383 [bic.py] => training => Task 5, Epoch 101/170 => Loss 2.162, Train_accy 99.140, Test_accy 53.820
2022-11-28 20:28:14,879 [bic.py] => training => Task 5, Epoch 102/170 => Loss 2.161, Train_accy 99.170, Test_accy 53.880
2022-11-28 20:28:23,346 [bic.py] => training => Task 5, Epoch 103/170 => Loss 2.158, Train_accy 99.230, Test_accy 53.650
2022-11-28 20:28:31,609 [bic.py] => training => Task 5, Epoch 104/170 => Loss 2.160, Train_accy 99.300, Test_accy 53.700
2022-11-28 20:28:39,662 [bic.py] => training => Task 5, Epoch 105/170 => Loss 2.161, Train_accy 99.390, Test_accy 54.300
2022-11-28 20:28:47,965 [bic.py] => training => Task 5, Epoch 106/170 => Loss 2.154, Train_accy 99.280, Test_accy 54.220
2022-11-28 20:28:55,822 [bic.py] => training => Task 5, Epoch 107/170 => Loss 2.164, Train_accy 99.300, Test_accy 54.550
2022-11-28 20:29:03,986 [bic.py] => training => Task 5, Epoch 108/170 => Loss 2.162, Train_accy 99.300, Test_accy 54.530
2022-11-28 20:29:11,884 [bic.py] => training => Task 5, Epoch 109/170 => Loss 2.161, Train_accy 99.350, Test_accy 54.050
2022-11-28 20:29:20,227 [bic.py] => training => Task 5, Epoch 110/170 => Loss 2.160, Train_accy 99.130, Test_accy 53.670
2022-11-28 20:29:28,678 [bic.py] => training => Task 5, Epoch 111/170 => Loss 2.159, Train_accy 99.390, Test_accy 53.950
2022-11-28 20:29:36,711 [bic.py] => training => Task 5, Epoch 112/170 => Loss 2.156, Train_accy 99.320, Test_accy 54.300
2022-11-28 20:29:44,803 [bic.py] => training => Task 5, Epoch 113/170 => Loss 2.163, Train_accy 99.050, Test_accy 53.750
2022-11-28 20:29:53,195 [bic.py] => training => Task 5, Epoch 114/170 => Loss 2.160, Train_accy 99.230, Test_accy 53.970
2022-11-28 20:30:01,512 [bic.py] => training => Task 5, Epoch 115/170 => Loss 2.162, Train_accy 99.200, Test_accy 54.020
2022-11-28 20:30:09,846 [bic.py] => training => Task 5, Epoch 116/170 => Loss 2.157, Train_accy 99.350, Test_accy 54.280
2022-11-28 20:30:17,814 [bic.py] => training => Task 5, Epoch 117/170 => Loss 2.158, Train_accy 99.160, Test_accy 53.820
2022-11-28 20:30:26,055 [bic.py] => training => Task 5, Epoch 118/170 => Loss 2.156, Train_accy 99.420, Test_accy 53.770
2022-11-28 20:30:34,133 [bic.py] => training => Task 5, Epoch 119/170 => Loss 2.159, Train_accy 99.190, Test_accy 54.420
2022-11-28 20:30:42,114 [bic.py] => training => Task 5, Epoch 120/170 => Loss 2.157, Train_accy 99.320, Test_accy 54.030
2022-11-28 20:30:50,356 [bic.py] => training => Task 5, Epoch 121/170 => Loss 2.154, Train_accy 99.250, Test_accy 53.900
2022-11-28 20:30:58,773 [bic.py] => training => Task 5, Epoch 122/170 => Loss 2.163, Train_accy 99.190, Test_accy 53.720
2022-11-28 20:31:07,281 [bic.py] => training => Task 5, Epoch 123/170 => Loss 2.160, Train_accy 99.280, Test_accy 54.200
2022-11-28 20:31:15,296 [bic.py] => training => Task 5, Epoch 124/170 => Loss 2.156, Train_accy 99.260, Test_accy 54.320
2022-11-28 20:31:23,221 [bic.py] => training => Task 5, Epoch 125/170 => Loss 2.159, Train_accy 99.290, Test_accy 54.270
2022-11-28 20:31:31,484 [bic.py] => training => Task 5, Epoch 126/170 => Loss 2.161, Train_accy 99.200, Test_accy 53.900
2022-11-28 20:31:39,562 [bic.py] => training => Task 5, Epoch 127/170 => Loss 2.154, Train_accy 99.280, Test_accy 54.020
2022-11-28 20:31:47,857 [bic.py] => training => Task 5, Epoch 128/170 => Loss 2.158, Train_accy 99.230, Test_accy 53.520
2022-11-28 20:31:56,249 [bic.py] => training => Task 5, Epoch 129/170 => Loss 2.163, Train_accy 99.380, Test_accy 53.950
2022-11-28 20:32:04,370 [bic.py] => training => Task 5, Epoch 130/170 => Loss 2.157, Train_accy 99.420, Test_accy 53.770
2022-11-28 20:32:12,113 [bic.py] => training => Task 5, Epoch 131/170 => Loss 2.158, Train_accy 99.410, Test_accy 53.930
2022-11-28 20:32:20,049 [bic.py] => training => Task 5, Epoch 132/170 => Loss 2.158, Train_accy 99.320, Test_accy 53.880
2022-11-28 20:32:28,372 [bic.py] => training => Task 5, Epoch 133/170 => Loss 2.160, Train_accy 99.290, Test_accy 53.380
2022-11-28 20:32:36,564 [bic.py] => training => Task 5, Epoch 134/170 => Loss 2.154, Train_accy 99.350, Test_accy 54.030
2022-11-28 20:32:44,702 [bic.py] => training => Task 5, Epoch 135/170 => Loss 2.165, Train_accy 99.300, Test_accy 53.580
2022-11-28 20:32:52,836 [bic.py] => training => Task 5, Epoch 136/170 => Loss 2.160, Train_accy 99.420, Test_accy 54.000
2022-11-28 20:33:00,883 [bic.py] => training => Task 5, Epoch 137/170 => Loss 2.163, Train_accy 99.380, Test_accy 54.080
2022-11-28 20:33:08,968 [bic.py] => training => Task 5, Epoch 138/170 => Loss 2.156, Train_accy 99.350, Test_accy 54.150
2022-11-28 20:33:17,197 [bic.py] => training => Task 5, Epoch 139/170 => Loss 2.159, Train_accy 99.350, Test_accy 53.920
2022-11-28 20:33:25,266 [bic.py] => training => Task 5, Epoch 140/170 => Loss 2.155, Train_accy 99.220, Test_accy 53.720
2022-11-28 20:33:33,336 [bic.py] => training => Task 5, Epoch 141/170 => Loss 2.156, Train_accy 99.390, Test_accy 54.320
2022-11-28 20:33:41,445 [bic.py] => training => Task 5, Epoch 142/170 => Loss 2.161, Train_accy 99.190, Test_accy 53.620
2022-11-28 20:33:49,770 [bic.py] => training => Task 5, Epoch 143/170 => Loss 2.161, Train_accy 99.290, Test_accy 54.270
2022-11-28 20:33:58,503 [bic.py] => training => Task 5, Epoch 144/170 => Loss 2.163, Train_accy 99.320, Test_accy 53.750
2022-11-28 20:34:06,841 [bic.py] => training => Task 5, Epoch 145/170 => Loss 2.158, Train_accy 99.170, Test_accy 54.120
2022-11-28 20:34:15,212 [bic.py] => training => Task 5, Epoch 146/170 => Loss 2.160, Train_accy 99.500, Test_accy 53.670
2022-11-28 20:34:23,362 [bic.py] => training => Task 5, Epoch 147/170 => Loss 2.156, Train_accy 99.440, Test_accy 53.980
2022-11-28 20:34:31,250 [bic.py] => training => Task 5, Epoch 148/170 => Loss 2.158, Train_accy 99.320, Test_accy 54.150
2022-11-28 20:34:39,446 [bic.py] => training => Task 5, Epoch 149/170 => Loss 2.163, Train_accy 99.170, Test_accy 54.280
2022-11-28 20:34:47,125 [bic.py] => training => Task 5, Epoch 150/170 => Loss 2.158, Train_accy 99.450, Test_accy 53.820
2022-11-28 20:34:55,404 [bic.py] => training => Task 5, Epoch 151/170 => Loss 2.161, Train_accy 99.190, Test_accy 54.020
2022-11-28 20:35:03,723 [bic.py] => training => Task 5, Epoch 152/170 => Loss 2.159, Train_accy 99.390, Test_accy 54.030
2022-11-28 20:35:11,611 [bic.py] => training => Task 5, Epoch 153/170 => Loss 2.159, Train_accy 99.320, Test_accy 54.300
2022-11-28 20:35:19,561 [bic.py] => training => Task 5, Epoch 154/170 => Loss 2.156, Train_accy 99.320, Test_accy 54.230
2022-11-28 20:35:27,984 [bic.py] => training => Task 5, Epoch 155/170 => Loss 2.160, Train_accy 99.280, Test_accy 53.930
2022-11-28 20:35:36,584 [bic.py] => training => Task 5, Epoch 156/170 => Loss 2.158, Train_accy 99.330, Test_accy 53.730
2022-11-28 20:35:44,541 [bic.py] => training => Task 5, Epoch 157/170 => Loss 2.156, Train_accy 99.190, Test_accy 54.150
2022-11-28 20:35:52,565 [bic.py] => training => Task 5, Epoch 158/170 => Loss 2.157, Train_accy 99.280, Test_accy 54.150
2022-11-28 20:36:00,915 [bic.py] => training => Task 5, Epoch 159/170 => Loss 2.159, Train_accy 99.510, Test_accy 54.100
2022-11-28 20:36:08,940 [bic.py] => training => Task 5, Epoch 160/170 => Loss 2.157, Train_accy 99.290, Test_accy 53.720
2022-11-28 20:36:17,506 [bic.py] => training => Task 5, Epoch 161/170 => Loss 2.163, Train_accy 99.410, Test_accy 53.450
2022-11-28 20:36:25,749 [bic.py] => training => Task 5, Epoch 162/170 => Loss 2.161, Train_accy 99.290, Test_accy 53.800
2022-11-28 20:36:33,781 [bic.py] => training => Task 5, Epoch 163/170 => Loss 2.154, Train_accy 99.410, Test_accy 54.200
2022-11-28 20:36:41,912 [bic.py] => training => Task 5, Epoch 164/170 => Loss 2.162, Train_accy 99.360, Test_accy 53.970
2022-11-28 20:36:50,053 [bic.py] => training => Task 5, Epoch 165/170 => Loss 2.158, Train_accy 99.410, Test_accy 54.470
2022-11-28 20:36:58,464 [bic.py] => training => Task 5, Epoch 166/170 => Loss 2.161, Train_accy 99.330, Test_accy 54.380
2022-11-28 20:37:06,257 [bic.py] => training => Task 5, Epoch 167/170 => Loss 2.153, Train_accy 99.290, Test_accy 54.280
2022-11-28 20:37:14,385 [bic.py] => training => Task 5, Epoch 168/170 => Loss 2.154, Train_accy 99.470, Test_accy 53.680
2022-11-28 20:37:22,427 [bic.py] => training => Task 5, Epoch 169/170 => Loss 2.158, Train_accy 99.420, Test_accy 53.680
2022-11-28 20:37:30,630 [bic.py] => training => Task 5, Epoch 170/170 => Loss 2.162, Train_accy 99.410, Test_accy 54.050
2022-11-28 20:37:34,118 [bic.py] => bias_correction => Task 5, Epoch 1/170 => Loss 3.541, Train_accy 80.000, Test_accy 57.680
2022-11-28 20:37:37,714 [bic.py] => bias_correction => Task 5, Epoch 2/170 => Loss 3.487, Train_accy 85.000, Test_accy 61.530
2022-11-28 20:37:41,258 [bic.py] => bias_correction => Task 5, Epoch 3/170 => Loss 3.441, Train_accy 83.330, Test_accy 59.430
2022-11-28 20:37:44,772 [bic.py] => bias_correction => Task 5, Epoch 4/170 => Loss 3.481, Train_accy 80.000, Test_accy 57.330
2022-11-28 20:37:48,242 [bic.py] => bias_correction => Task 5, Epoch 5/170 => Loss 3.477, Train_accy 79.580, Test_accy 57.200
2022-11-28 20:37:51,959 [bic.py] => bias_correction => Task 5, Epoch 6/170 => Loss 3.478, Train_accy 82.080, Test_accy 58.680
2022-11-28 20:37:55,305 [bic.py] => bias_correction => Task 5, Epoch 7/170 => Loss 3.473, Train_accy 82.500, Test_accy 60.750
2022-11-28 20:37:58,942 [bic.py] => bias_correction => Task 5, Epoch 8/170 => Loss 3.437, Train_accy 82.920, Test_accy 60.400
2022-11-28 20:38:02,381 [bic.py] => bias_correction => Task 5, Epoch 9/170 => Loss 3.459, Train_accy 79.580, Test_accy 58.870
2022-11-28 20:38:05,849 [bic.py] => bias_correction => Task 5, Epoch 10/170 => Loss 3.458, Train_accy 80.420, Test_accy 59.370
2022-11-28 20:38:09,517 [bic.py] => bias_correction => Task 5, Epoch 11/170 => Loss 3.454, Train_accy 84.170, Test_accy 60.570
2022-11-28 20:38:13,067 [bic.py] => bias_correction => Task 5, Epoch 12/170 => Loss 3.456, Train_accy 87.080, Test_accy 60.700
2022-11-28 20:38:16,724 [bic.py] => bias_correction => Task 5, Epoch 13/170 => Loss 3.462, Train_accy 86.250, Test_accy 60.050
2022-11-28 20:38:20,399 [bic.py] => bias_correction => Task 5, Epoch 14/170 => Loss 3.456, Train_accy 85.000, Test_accy 60.000
2022-11-28 20:38:24,110 [bic.py] => bias_correction => Task 5, Epoch 15/170 => Loss 3.454, Train_accy 85.830, Test_accy 60.320
2022-11-28 20:38:27,719 [bic.py] => bias_correction => Task 5, Epoch 16/170 => Loss 3.449, Train_accy 85.000, Test_accy 60.650
2022-11-28 20:38:31,238 [bic.py] => bias_correction => Task 5, Epoch 17/170 => Loss 3.436, Train_accy 82.920, Test_accy 59.880
2022-11-28 20:38:34,748 [bic.py] => bias_correction => Task 5, Epoch 18/170 => Loss 3.451, Train_accy 82.500, Test_accy 59.580
2022-11-28 20:38:38,342 [bic.py] => bias_correction => Task 5, Epoch 19/170 => Loss 3.463, Train_accy 82.080, Test_accy 60.120
2022-11-28 20:38:41,845 [bic.py] => bias_correction => Task 5, Epoch 20/170 => Loss 3.445, Train_accy 83.330, Test_accy 60.850
2022-11-28 20:38:45,391 [bic.py] => bias_correction => Task 5, Epoch 21/170 => Loss 3.443, Train_accy 82.080, Test_accy 60.550
2022-11-28 20:38:48,805 [bic.py] => bias_correction => Task 5, Epoch 22/170 => Loss 3.436, Train_accy 82.920, Test_accy 60.680
2022-11-28 20:38:52,282 [bic.py] => bias_correction => Task 5, Epoch 23/170 => Loss 3.456, Train_accy 82.500, Test_accy 60.830
2022-11-28 20:38:56,103 [bic.py] => bias_correction => Task 5, Epoch 24/170 => Loss 3.449, Train_accy 82.500, Test_accy 60.630
2022-11-28 20:38:59,786 [bic.py] => bias_correction => Task 5, Epoch 25/170 => Loss 3.466, Train_accy 82.500, Test_accy 60.270
2022-11-28 20:39:03,399 [bic.py] => bias_correction => Task 5, Epoch 26/170 => Loss 3.439, Train_accy 84.580, Test_accy 60.430
2022-11-28 20:39:06,975 [bic.py] => bias_correction => Task 5, Epoch 27/170 => Loss 3.449, Train_accy 84.170, Test_accy 60.600
2022-11-28 20:39:10,619 [bic.py] => bias_correction => Task 5, Epoch 28/170 => Loss 3.454, Train_accy 84.580, Test_accy 60.650
2022-11-28 20:39:14,156 [bic.py] => bias_correction => Task 5, Epoch 29/170 => Loss 3.422, Train_accy 82.920, Test_accy 60.720
2022-11-28 20:39:17,601 [bic.py] => bias_correction => Task 5, Epoch 30/170 => Loss 3.446, Train_accy 83.330, Test_accy 60.630
2022-11-28 20:39:21,180 [bic.py] => bias_correction => Task 5, Epoch 31/170 => Loss 3.456, Train_accy 86.250, Test_accy 60.630
2022-11-28 20:39:24,732 [bic.py] => bias_correction => Task 5, Epoch 32/170 => Loss 3.436, Train_accy 83.750, Test_accy 60.650
2022-11-28 20:39:28,362 [bic.py] => bias_correction => Task 5, Epoch 33/170 => Loss 3.445, Train_accy 84.170, Test_accy 60.870
2022-11-28 20:39:31,883 [bic.py] => bias_correction => Task 5, Epoch 34/170 => Loss 3.435, Train_accy 85.000, Test_accy 60.770
2022-11-28 20:39:35,532 [bic.py] => bias_correction => Task 5, Epoch 35/170 => Loss 3.438, Train_accy 85.000, Test_accy 60.800
2022-11-28 20:39:39,136 [bic.py] => bias_correction => Task 5, Epoch 36/170 => Loss 3.433, Train_accy 84.580, Test_accy 60.670
2022-11-28 20:39:42,693 [bic.py] => bias_correction => Task 5, Epoch 37/170 => Loss 3.446, Train_accy 85.000, Test_accy 60.800
2022-11-28 20:39:46,447 [bic.py] => bias_correction => Task 5, Epoch 38/170 => Loss 3.443, Train_accy 83.330, Test_accy 60.970
2022-11-28 20:39:50,175 [bic.py] => bias_correction => Task 5, Epoch 39/170 => Loss 3.430, Train_accy 84.170, Test_accy 60.870
2022-11-28 20:39:53,897 [bic.py] => bias_correction => Task 5, Epoch 40/170 => Loss 3.436, Train_accy 83.330, Test_accy 60.970
2022-11-28 20:39:57,356 [bic.py] => bias_correction => Task 5, Epoch 41/170 => Loss 3.439, Train_accy 83.330, Test_accy 60.900
2022-11-28 20:40:00,859 [bic.py] => bias_correction => Task 5, Epoch 42/170 => Loss 3.453, Train_accy 85.000, Test_accy 60.920
2022-11-28 20:40:04,358 [bic.py] => bias_correction => Task 5, Epoch 43/170 => Loss 3.432, Train_accy 85.000, Test_accy 60.670
2022-11-28 20:40:07,902 [bic.py] => bias_correction => Task 5, Epoch 44/170 => Loss 3.445, Train_accy 84.580, Test_accy 60.870
2022-11-28 20:40:11,427 [bic.py] => bias_correction => Task 5, Epoch 45/170 => Loss 3.448, Train_accy 83.750, Test_accy 61.000
2022-11-28 20:40:15,130 [bic.py] => bias_correction => Task 5, Epoch 46/170 => Loss 3.425, Train_accy 83.750, Test_accy 60.850
2022-11-28 20:40:18,683 [bic.py] => bias_correction => Task 5, Epoch 47/170 => Loss 3.437, Train_accy 86.250, Test_accy 60.870
2022-11-28 20:40:22,518 [bic.py] => bias_correction => Task 5, Epoch 48/170 => Loss 3.442, Train_accy 85.000, Test_accy 60.720
2022-11-28 20:40:26,144 [bic.py] => bias_correction => Task 5, Epoch 49/170 => Loss 3.433, Train_accy 83.750, Test_accy 60.730
2022-11-28 20:40:29,570 [bic.py] => bias_correction => Task 5, Epoch 50/170 => Loss 3.426, Train_accy 82.500, Test_accy 60.820
2022-11-28 20:40:32,940 [bic.py] => bias_correction => Task 5, Epoch 51/170 => Loss 3.428, Train_accy 85.420, Test_accy 60.850
2022-11-28 20:40:36,388 [bic.py] => bias_correction => Task 5, Epoch 52/170 => Loss 3.429, Train_accy 81.670, Test_accy 61.070
2022-11-28 20:40:39,831 [bic.py] => bias_correction => Task 5, Epoch 53/170 => Loss 3.434, Train_accy 82.500, Test_accy 61.130
2022-11-28 20:40:43,302 [bic.py] => bias_correction => Task 5, Epoch 54/170 => Loss 3.420, Train_accy 82.920, Test_accy 60.820
2022-11-28 20:40:47,123 [bic.py] => bias_correction => Task 5, Epoch 55/170 => Loss 3.444, Train_accy 84.580, Test_accy 60.830
2022-11-28 20:40:50,887 [bic.py] => bias_correction => Task 5, Epoch 56/170 => Loss 3.435, Train_accy 85.830, Test_accy 61.230
2022-11-28 20:40:54,540 [bic.py] => bias_correction => Task 5, Epoch 57/170 => Loss 3.434, Train_accy 83.750, Test_accy 61.020
2022-11-28 20:40:58,312 [bic.py] => bias_correction => Task 5, Epoch 58/170 => Loss 3.417, Train_accy 83.750, Test_accy 61.050
2022-11-28 20:41:02,120 [bic.py] => bias_correction => Task 5, Epoch 59/170 => Loss 3.434, Train_accy 84.580, Test_accy 60.870
2022-11-28 20:41:05,760 [bic.py] => bias_correction => Task 5, Epoch 60/170 => Loss 3.433, Train_accy 83.330, Test_accy 60.930
2022-11-28 20:41:09,109 [bic.py] => bias_correction => Task 5, Epoch 61/170 => Loss 3.437, Train_accy 83.330, Test_accy 60.950
2022-11-28 20:41:12,703 [bic.py] => bias_correction => Task 5, Epoch 62/170 => Loss 3.449, Train_accy 81.670, Test_accy 60.780
2022-11-28 20:41:16,210 [bic.py] => bias_correction => Task 5, Epoch 63/170 => Loss 3.450, Train_accy 87.500, Test_accy 60.880
2022-11-28 20:41:19,765 [bic.py] => bias_correction => Task 5, Epoch 64/170 => Loss 3.439, Train_accy 85.420, Test_accy 60.900
2022-11-28 20:41:23,746 [bic.py] => bias_correction => Task 5, Epoch 65/170 => Loss 3.430, Train_accy 84.580, Test_accy 60.970
2022-11-28 20:41:27,407 [bic.py] => bias_correction => Task 5, Epoch 66/170 => Loss 3.451, Train_accy 85.420, Test_accy 60.870
2022-11-28 20:41:30,987 [bic.py] => bias_correction => Task 5, Epoch 67/170 => Loss 3.420, Train_accy 87.080, Test_accy 60.950
2022-11-28 20:41:34,759 [bic.py] => bias_correction => Task 5, Epoch 68/170 => Loss 3.446, Train_accy 83.330, Test_accy 60.920
2022-11-28 20:41:38,505 [bic.py] => bias_correction => Task 5, Epoch 69/170 => Loss 3.453, Train_accy 83.330, Test_accy 61.000
2022-11-28 20:41:42,189 [bic.py] => bias_correction => Task 5, Epoch 70/170 => Loss 3.440, Train_accy 86.670, Test_accy 61.050
2022-11-28 20:41:45,827 [bic.py] => bias_correction => Task 5, Epoch 71/170 => Loss 3.419, Train_accy 86.250, Test_accy 61.000
2022-11-28 20:41:49,449 [bic.py] => bias_correction => Task 5, Epoch 72/170 => Loss 3.431, Train_accy 80.420, Test_accy 61.200
2022-11-28 20:41:53,077 [bic.py] => bias_correction => Task 5, Epoch 73/170 => Loss 3.444, Train_accy 85.420, Test_accy 61.050
2022-11-28 20:41:56,750 [bic.py] => bias_correction => Task 5, Epoch 74/170 => Loss 3.436, Train_accy 87.080, Test_accy 61.180
2022-11-28 20:42:00,351 [bic.py] => bias_correction => Task 5, Epoch 75/170 => Loss 3.417, Train_accy 86.250, Test_accy 61.180
2022-11-28 20:42:03,914 [bic.py] => bias_correction => Task 5, Epoch 76/170 => Loss 3.421, Train_accy 85.420, Test_accy 61.220
2022-11-28 20:42:07,414 [bic.py] => bias_correction => Task 5, Epoch 77/170 => Loss 3.432, Train_accy 84.580, Test_accy 60.980
2022-11-28 20:42:11,131 [bic.py] => bias_correction => Task 5, Epoch 78/170 => Loss 3.417, Train_accy 83.330, Test_accy 61.020
2022-11-28 20:42:14,828 [bic.py] => bias_correction => Task 5, Epoch 79/170 => Loss 3.432, Train_accy 85.420, Test_accy 60.920
2022-11-28 20:42:18,353 [bic.py] => bias_correction => Task 5, Epoch 80/170 => Loss 3.437, Train_accy 85.830, Test_accy 61.070
2022-11-28 20:42:21,748 [bic.py] => bias_correction => Task 5, Epoch 81/170 => Loss 3.430, Train_accy 84.580, Test_accy 60.700
2022-11-28 20:42:25,329 [bic.py] => bias_correction => Task 5, Epoch 82/170 => Loss 3.449, Train_accy 85.420, Test_accy 60.650
2022-11-28 20:42:28,899 [bic.py] => bias_correction => Task 5, Epoch 83/170 => Loss 3.422, Train_accy 83.330, Test_accy 60.730
2022-11-28 20:42:32,663 [bic.py] => bias_correction => Task 5, Epoch 84/170 => Loss 3.443, Train_accy 85.830, Test_accy 60.600
2022-11-28 20:42:36,148 [bic.py] => bias_correction => Task 5, Epoch 85/170 => Loss 3.413, Train_accy 84.170, Test_accy 60.880
2022-11-28 20:42:39,486 [bic.py] => bias_correction => Task 5, Epoch 86/170 => Loss 3.421, Train_accy 84.170, Test_accy 60.670
2022-11-28 20:42:43,175 [bic.py] => bias_correction => Task 5, Epoch 87/170 => Loss 3.428, Train_accy 85.000, Test_accy 60.780
2022-11-28 20:42:46,763 [bic.py] => bias_correction => Task 5, Epoch 88/170 => Loss 3.442, Train_accy 82.080, Test_accy 60.750
2022-11-28 20:42:50,398 [bic.py] => bias_correction => Task 5, Epoch 89/170 => Loss 3.432, Train_accy 84.170, Test_accy 60.530
2022-11-28 20:42:54,096 [bic.py] => bias_correction => Task 5, Epoch 90/170 => Loss 3.432, Train_accy 83.750, Test_accy 60.700
2022-11-28 20:42:57,672 [bic.py] => bias_correction => Task 5, Epoch 91/170 => Loss 3.438, Train_accy 83.750, Test_accy 60.650
2022-11-28 20:43:01,171 [bic.py] => bias_correction => Task 5, Epoch 92/170 => Loss 3.432, Train_accy 83.750, Test_accy 60.570
2022-11-28 20:43:04,554 [bic.py] => bias_correction => Task 5, Epoch 93/170 => Loss 3.436, Train_accy 83.330, Test_accy 60.720
2022-11-28 20:43:08,239 [bic.py] => bias_correction => Task 5, Epoch 94/170 => Loss 3.430, Train_accy 84.170, Test_accy 60.570
2022-11-28 20:43:11,902 [bic.py] => bias_correction => Task 5, Epoch 95/170 => Loss 3.426, Train_accy 83.750, Test_accy 60.680
2022-11-28 20:43:15,485 [bic.py] => bias_correction => Task 5, Epoch 96/170 => Loss 3.448, Train_accy 83.330, Test_accy 60.600
2022-11-28 20:43:19,047 [bic.py] => bias_correction => Task 5, Epoch 97/170 => Loss 3.427, Train_accy 84.170, Test_accy 60.730
2022-11-28 20:43:22,676 [bic.py] => bias_correction => Task 5, Epoch 98/170 => Loss 3.429, Train_accy 84.170, Test_accy 60.930
2022-11-28 20:43:26,096 [bic.py] => bias_correction => Task 5, Epoch 99/170 => Loss 3.422, Train_accy 82.080, Test_accy 61.170
2022-11-28 20:43:29,670 [bic.py] => bias_correction => Task 5, Epoch 100/170 => Loss 3.442, Train_accy 86.250, Test_accy 61.150
2022-11-28 20:43:33,166 [bic.py] => bias_correction => Task 5, Epoch 101/170 => Loss 3.438, Train_accy 85.000, Test_accy 60.880
2022-11-28 20:43:36,699 [bic.py] => bias_correction => Task 5, Epoch 102/170 => Loss 3.444, Train_accy 83.330, Test_accy 61.080
2022-11-28 20:43:40,201 [bic.py] => bias_correction => Task 5, Epoch 103/170 => Loss 3.424, Train_accy 81.670, Test_accy 61.130
2022-11-28 20:43:43,736 [bic.py] => bias_correction => Task 5, Epoch 104/170 => Loss 3.427, Train_accy 87.500, Test_accy 60.930
2022-11-28 20:43:47,353 [bic.py] => bias_correction => Task 5, Epoch 105/170 => Loss 3.432, Train_accy 85.420, Test_accy 61.200
2022-11-28 20:43:50,905 [bic.py] => bias_correction => Task 5, Epoch 106/170 => Loss 3.434, Train_accy 81.250, Test_accy 60.920
2022-11-28 20:43:54,489 [bic.py] => bias_correction => Task 5, Epoch 107/170 => Loss 3.443, Train_accy 83.750, Test_accy 60.780
2022-11-28 20:43:58,200 [bic.py] => bias_correction => Task 5, Epoch 108/170 => Loss 3.408, Train_accy 81.670, Test_accy 60.820
2022-11-28 20:44:01,769 [bic.py] => bias_correction => Task 5, Epoch 109/170 => Loss 3.437, Train_accy 84.580, Test_accy 60.880
2022-11-28 20:44:05,364 [bic.py] => bias_correction => Task 5, Epoch 110/170 => Loss 3.434, Train_accy 85.420, Test_accy 60.870
2022-11-28 20:44:08,933 [bic.py] => bias_correction => Task 5, Epoch 111/170 => Loss 3.420, Train_accy 85.000, Test_accy 60.880
2022-11-28 20:44:12,431 [bic.py] => bias_correction => Task 5, Epoch 112/170 => Loss 3.431, Train_accy 84.170, Test_accy 60.930
2022-11-28 20:44:16,221 [bic.py] => bias_correction => Task 5, Epoch 113/170 => Loss 3.433, Train_accy 85.830, Test_accy 60.970
2022-11-28 20:44:19,951 [bic.py] => bias_correction => Task 5, Epoch 114/170 => Loss 3.435, Train_accy 84.580, Test_accy 60.920
2022-11-28 20:44:23,703 [bic.py] => bias_correction => Task 5, Epoch 115/170 => Loss 3.413, Train_accy 82.920, Test_accy 61.000
2022-11-28 20:44:27,189 [bic.py] => bias_correction => Task 5, Epoch 116/170 => Loss 3.426, Train_accy 84.580, Test_accy 61.030
2022-11-28 20:44:30,610 [bic.py] => bias_correction => Task 5, Epoch 117/170 => Loss 3.448, Train_accy 85.000, Test_accy 61.270
2022-11-28 20:44:34,169 [bic.py] => bias_correction => Task 5, Epoch 118/170 => Loss 3.438, Train_accy 83.330, Test_accy 61.130
2022-11-28 20:44:37,874 [bic.py] => bias_correction => Task 5, Epoch 119/170 => Loss 3.423, Train_accy 85.830, Test_accy 60.720
2022-11-28 20:44:41,368 [bic.py] => bias_correction => Task 5, Epoch 120/170 => Loss 3.433, Train_accy 83.750, Test_accy 61.170
2022-11-28 20:44:44,850 [bic.py] => bias_correction => Task 5, Epoch 121/170 => Loss 3.444, Train_accy 84.170, Test_accy 61.030
2022-11-28 20:44:48,431 [bic.py] => bias_correction => Task 5, Epoch 122/170 => Loss 3.414, Train_accy 80.000, Test_accy 60.880
2022-11-28 20:44:51,903 [bic.py] => bias_correction => Task 5, Epoch 123/170 => Loss 3.436, Train_accy 85.000, Test_accy 60.900
2022-11-28 20:44:55,369 [bic.py] => bias_correction => Task 5, Epoch 124/170 => Loss 3.426, Train_accy 84.580, Test_accy 60.750
2022-11-28 20:44:59,143 [bic.py] => bias_correction => Task 5, Epoch 125/170 => Loss 3.427, Train_accy 83.330, Test_accy 60.870
2022-11-28 20:45:02,670 [bic.py] => bias_correction => Task 5, Epoch 126/170 => Loss 3.424, Train_accy 83.330, Test_accy 60.880
2022-11-28 20:45:06,115 [bic.py] => bias_correction => Task 5, Epoch 127/170 => Loss 3.429, Train_accy 83.330, Test_accy 60.980
2022-11-28 20:45:09,676 [bic.py] => bias_correction => Task 5, Epoch 128/170 => Loss 3.443, Train_accy 83.750, Test_accy 61.020
2022-11-28 20:45:13,309 [bic.py] => bias_correction => Task 5, Epoch 129/170 => Loss 3.425, Train_accy 83.330, Test_accy 60.780
2022-11-28 20:45:16,821 [bic.py] => bias_correction => Task 5, Epoch 130/170 => Loss 3.421, Train_accy 86.250, Test_accy 60.750
2022-11-28 20:45:20,421 [bic.py] => bias_correction => Task 5, Epoch 131/170 => Loss 3.420, Train_accy 86.250, Test_accy 60.880
2022-11-28 20:45:23,953 [bic.py] => bias_correction => Task 5, Epoch 132/170 => Loss 3.443, Train_accy 84.580, Test_accy 61.030
2022-11-28 20:45:27,565 [bic.py] => bias_correction => Task 5, Epoch 133/170 => Loss 3.425, Train_accy 82.920, Test_accy 61.070
2022-11-28 20:45:31,093 [bic.py] => bias_correction => Task 5, Epoch 134/170 => Loss 3.421, Train_accy 82.920, Test_accy 60.970
2022-11-28 20:45:34,569 [bic.py] => bias_correction => Task 5, Epoch 135/170 => Loss 3.433, Train_accy 84.580, Test_accy 61.020
2022-11-28 20:45:38,429 [bic.py] => bias_correction => Task 5, Epoch 136/170 => Loss 3.437, Train_accy 83.330, Test_accy 60.980
2022-11-28 20:45:42,024 [bic.py] => bias_correction => Task 5, Epoch 137/170 => Loss 3.429, Train_accy 85.420, Test_accy 60.620
2022-11-28 20:45:45,621 [bic.py] => bias_correction => Task 5, Epoch 138/170 => Loss 3.447, Train_accy 83.750, Test_accy 60.750
2022-11-28 20:45:49,164 [bic.py] => bias_correction => Task 5, Epoch 139/170 => Loss 3.439, Train_accy 82.080, Test_accy 60.900
2022-11-28 20:45:52,846 [bic.py] => bias_correction => Task 5, Epoch 140/170 => Loss 3.438, Train_accy 84.580, Test_accy 60.920
2022-11-28 20:45:56,534 [bic.py] => bias_correction => Task 5, Epoch 141/170 => Loss 3.439, Train_accy 82.500, Test_accy 60.900
2022-11-28 20:46:00,024 [bic.py] => bias_correction => Task 5, Epoch 142/170 => Loss 3.437, Train_accy 83.330, Test_accy 60.880
2022-11-28 20:46:03,581 [bic.py] => bias_correction => Task 5, Epoch 143/170 => Loss 3.438, Train_accy 83.330, Test_accy 60.980
2022-11-28 20:46:07,373 [bic.py] => bias_correction => Task 5, Epoch 144/170 => Loss 3.437, Train_accy 82.080, Test_accy 60.730
2022-11-28 20:46:10,942 [bic.py] => bias_correction => Task 5, Epoch 145/170 => Loss 3.427, Train_accy 85.420, Test_accy 60.750
2022-11-28 20:46:14,532 [bic.py] => bias_correction => Task 5, Epoch 146/170 => Loss 3.426, Train_accy 84.580, Test_accy 60.770
2022-11-28 20:46:18,101 [bic.py] => bias_correction => Task 5, Epoch 147/170 => Loss 3.434, Train_accy 86.250, Test_accy 60.850
2022-11-28 20:46:21,822 [bic.py] => bias_correction => Task 5, Epoch 148/170 => Loss 3.437, Train_accy 84.170, Test_accy 60.800
2022-11-28 20:46:25,486 [bic.py] => bias_correction => Task 5, Epoch 149/170 => Loss 3.423, Train_accy 84.170, Test_accy 60.870
2022-11-28 20:46:29,044 [bic.py] => bias_correction => Task 5, Epoch 150/170 => Loss 3.450, Train_accy 82.500, Test_accy 60.780
2022-11-28 20:46:32,647 [bic.py] => bias_correction => Task 5, Epoch 151/170 => Loss 3.420, Train_accy 85.420, Test_accy 60.880
2022-11-28 20:46:36,148 [bic.py] => bias_correction => Task 5, Epoch 152/170 => Loss 3.437, Train_accy 82.920, Test_accy 60.980
2022-11-28 20:46:39,648 [bic.py] => bias_correction => Task 5, Epoch 153/170 => Loss 3.465, Train_accy 84.580, Test_accy 61.100
2022-11-28 20:46:43,237 [bic.py] => bias_correction => Task 5, Epoch 154/170 => Loss 3.444, Train_accy 85.000, Test_accy 60.970
2022-11-28 20:46:46,909 [bic.py] => bias_correction => Task 5, Epoch 155/170 => Loss 3.423, Train_accy 81.670, Test_accy 61.030
2022-11-28 20:46:50,548 [bic.py] => bias_correction => Task 5, Epoch 156/170 => Loss 3.433, Train_accy 82.920, Test_accy 60.800
2022-11-28 20:46:54,230 [bic.py] => bias_correction => Task 5, Epoch 157/170 => Loss 3.425, Train_accy 85.830, Test_accy 61.000
2022-11-28 20:46:57,725 [bic.py] => bias_correction => Task 5, Epoch 158/170 => Loss 3.437, Train_accy 85.000, Test_accy 61.100
2022-11-28 20:47:01,388 [bic.py] => bias_correction => Task 5, Epoch 159/170 => Loss 3.430, Train_accy 82.920, Test_accy 60.920
2022-11-28 20:47:05,039 [bic.py] => bias_correction => Task 5, Epoch 160/170 => Loss 3.430, Train_accy 81.670, Test_accy 60.870
2022-11-28 20:47:08,666 [bic.py] => bias_correction => Task 5, Epoch 161/170 => Loss 3.438, Train_accy 84.580, Test_accy 60.750
2022-11-28 20:47:12,288 [bic.py] => bias_correction => Task 5, Epoch 162/170 => Loss 3.421, Train_accy 86.250, Test_accy 60.820
2022-11-28 20:47:16,110 [bic.py] => bias_correction => Task 5, Epoch 163/170 => Loss 3.430, Train_accy 85.000, Test_accy 60.800
2022-11-28 20:47:19,929 [bic.py] => bias_correction => Task 5, Epoch 164/170 => Loss 3.438, Train_accy 86.670, Test_accy 60.870
2022-11-28 20:47:23,886 [bic.py] => bias_correction => Task 5, Epoch 165/170 => Loss 3.431, Train_accy 85.000, Test_accy 60.770
2022-11-28 20:47:27,494 [bic.py] => bias_correction => Task 5, Epoch 166/170 => Loss 3.425, Train_accy 86.250, Test_accy 60.800
2022-11-28 20:47:31,140 [bic.py] => bias_correction => Task 5, Epoch 167/170 => Loss 3.418, Train_accy 86.250, Test_accy 60.920
2022-11-28 20:47:34,731 [bic.py] => bias_correction => Task 5, Epoch 168/170 => Loss 3.433, Train_accy 85.000, Test_accy 60.930
2022-11-28 20:47:38,533 [bic.py] => bias_correction => Task 5, Epoch 169/170 => Loss 3.427, Train_accy 84.170, Test_accy 60.950
2022-11-28 20:47:42,307 [bic.py] => bias_correction => Task 5, Epoch 170/170 => Loss 3.451, Train_accy 82.920, Test_accy 60.900
2022-11-28 20:47:42,308 [base.py] => Reducing exemplars...(33 per classes)
2022-11-28 20:48:03,169 [base.py] => Constructing exemplars...(33 per classes)
2022-11-28 20:48:12,472 [bic.py] => Parameters of bias layer:
2022-11-28 20:48:12,473 [bic.py] => 0 => 1.000, 0.000
2022-11-28 20:48:12,473 [bic.py] => 1 => 0.976, -1.640
2022-11-28 20:48:12,473 [bic.py] => 2 => 0.847, -1.789
2022-11-28 20:48:12,473 [bic.py] => 3 => 0.728, -1.453
2022-11-28 20:48:12,473 [bic.py] => 4 => 0.739, -1.271
2022-11-28 20:48:12,473 [bic.py] => 5 => 0.788, -1.449
2022-11-28 20:48:14,623 [bic.py] => Exemplar size: 1980
2022-11-28 20:48:14,624 [trainer.py] => CNN: {'total': 60.9, '00-09': 67.0, '10-19': 51.9, '20-29': 64.0, '30-39': 54.7, '40-49': 62.0, '50-59': 65.8, 'old': 59.92, 'new': 65.8}
2022-11-28 20:48:14,624 [trainer.py] => NME: {'total': 60.88, '00-09': 62.8, '10-19': 47.1, '20-29': 60.4, '30-39': 56.6, '40-49': 69.5, '50-59': 68.9, 'old': 59.28, 'new': 68.9}
2022-11-28 20:48:14,624 [trainer.py] => CNN top1 curve: [88.7, 75.6, 72.3, 66.6, 64.42, 60.9]
2022-11-28 20:48:14,624 [trainer.py] => CNN top5 curve: [99.4, 95.6, 93.5, 91.42, 90.66, 87.9]
2022-11-28 20:48:14,624 [trainer.py] => NME top1 curve: [88.5, 75.85, 72.47, 66.72, 64.22, 60.88]
2022-11-28 20:48:14,624 [trainer.py] => NME top5 curve: [99.4, 95.95, 93.8, 91.2, 89.16, 86.13]

2022-11-28 20:48:14,624 [trainer.py] => All params: 468066
2022-11-28 20:48:14,625 [trainer.py] => Trainable params: 468066
2022-11-28 20:48:14,625 [bic.py] => Learning on 60-70
2022-11-28 20:48:14,672 [bic.py] => Stage1 dset: 6770, Stage2 dset: 210
2022-11-28 20:48:14,672 [bic.py] => Lambda: 0.857
2022-11-28 20:48:14,687 [bic.py] => Parameters of bias layer:
2022-11-28 20:48:14,687 [bic.py] => 0 => 1.000, 0.000
2022-11-28 20:48:14,687 [bic.py] => 1 => 0.976, -1.640
2022-11-28 20:48:14,687 [bic.py] => 2 => 0.847, -1.789
2022-11-28 20:48:14,687 [bic.py] => 3 => 0.728, -1.453
2022-11-28 20:48:14,687 [bic.py] => 4 => 0.739, -1.271
2022-11-28 20:48:14,687 [bic.py] => 5 => 0.788, -1.449
2022-11-28 20:48:14,687 [bic.py] => 6 => 1.000, 0.000
2022-11-28 20:48:23,190 [bic.py] => training => Task 6, Epoch 1/170 => Loss 2.676, Train_accy 70.210, Test_accy 40.560
2022-11-28 20:48:31,724 [bic.py] => training => Task 6, Epoch 2/170 => Loss 2.571, Train_accy 75.130, Test_accy 42.610
2022-11-28 20:48:39,996 [bic.py] => training => Task 6, Epoch 3/170 => Loss 2.554, Train_accy 77.210, Test_accy 43.160
2022-11-28 20:48:48,270 [bic.py] => training => Task 6, Epoch 4/170 => Loss 2.538, Train_accy 78.830, Test_accy 44.160
2022-11-28 20:48:56,681 [bic.py] => training => Task 6, Epoch 5/170 => Loss 2.530, Train_accy 80.060, Test_accy 44.530
2022-11-28 20:49:04,896 [bic.py] => training => Task 6, Epoch 6/170 => Loss 2.522, Train_accy 76.130, Test_accy 40.310
2022-11-28 20:49:13,103 [bic.py] => training => Task 6, Epoch 7/170 => Loss 2.520, Train_accy 79.540, Test_accy 41.460
2022-11-28 20:49:21,383 [bic.py] => training => Task 6, Epoch 8/170 => Loss 2.518, Train_accy 82.420, Test_accy 44.370
2022-11-28 20:49:30,335 [bic.py] => training => Task 6, Epoch 9/170 => Loss 2.510, Train_accy 83.090, Test_accy 43.260
2022-11-28 20:49:38,803 [bic.py] => training => Task 6, Epoch 10/170 => Loss 2.505, Train_accy 78.080, Test_accy 42.900
2022-11-28 20:49:47,348 [bic.py] => training => Task 6, Epoch 11/170 => Loss 2.508, Train_accy 84.510, Test_accy 46.360
2022-11-28 20:49:55,982 [bic.py] => training => Task 6, Epoch 12/170 => Loss 2.495, Train_accy 86.970, Test_accy 45.270
2022-11-28 20:50:04,187 [bic.py] => training => Task 6, Epoch 13/170 => Loss 2.491, Train_accy 87.250, Test_accy 45.530
2022-11-28 20:50:12,445 [bic.py] => training => Task 6, Epoch 14/170 => Loss 2.498, Train_accy 87.220, Test_accy 44.900
2022-11-28 20:50:20,623 [bic.py] => training => Task 6, Epoch 15/170 => Loss 2.492, Train_accy 87.300, Test_accy 43.600
2022-11-28 20:50:29,299 [bic.py] => training => Task 6, Epoch 16/170 => Loss 2.493, Train_accy 86.030, Test_accy 44.970
2022-11-28 20:50:37,814 [bic.py] => training => Task 6, Epoch 17/170 => Loss 2.489, Train_accy 88.420, Test_accy 44.860
2022-11-28 20:50:46,333 [bic.py] => training => Task 6, Epoch 18/170 => Loss 2.487, Train_accy 87.210, Test_accy 44.700
2022-11-28 20:50:55,179 [bic.py] => training => Task 6, Epoch 19/170 => Loss 2.488, Train_accy 86.930, Test_accy 43.240
2022-11-28 20:51:03,587 [bic.py] => training => Task 6, Epoch 20/170 => Loss 2.485, Train_accy 86.930, Test_accy 45.510
2022-11-28 20:51:12,293 [bic.py] => training => Task 6, Epoch 21/170 => Loss 2.485, Train_accy 88.420, Test_accy 44.440
2022-11-28 20:51:21,090 [bic.py] => training => Task 6, Epoch 22/170 => Loss 2.482, Train_accy 89.510, Test_accy 46.400
2022-11-28 20:51:29,753 [bic.py] => training => Task 6, Epoch 23/170 => Loss 2.484, Train_accy 86.620, Test_accy 46.100
2022-11-28 20:51:37,964 [bic.py] => training => Task 6, Epoch 24/170 => Loss 2.484, Train_accy 92.040, Test_accy 47.800
2022-11-28 20:51:46,205 [bic.py] => training => Task 6, Epoch 25/170 => Loss 2.487, Train_accy 87.190, Test_accy 44.640
2022-11-28 20:51:54,559 [bic.py] => training => Task 6, Epoch 26/170 => Loss 2.486, Train_accy 89.190, Test_accy 44.510
2022-11-28 20:52:02,866 [bic.py] => training => Task 6, Epoch 27/170 => Loss 2.484, Train_accy 90.500, Test_accy 47.790
2022-11-28 20:52:11,390 [bic.py] => training => Task 6, Epoch 28/170 => Loss 2.481, Train_accy 83.590, Test_accy 42.010
2022-11-28 20:52:20,238 [bic.py] => training => Task 6, Epoch 29/170 => Loss 2.480, Train_accy 89.420, Test_accy 44.830
2022-11-28 20:52:28,699 [bic.py] => training => Task 6, Epoch 30/170 => Loss 2.482, Train_accy 88.710, Test_accy 45.140
2022-11-28 20:52:37,048 [bic.py] => training => Task 6, Epoch 31/170 => Loss 2.476, Train_accy 91.370, Test_accy 47.230
2022-11-28 20:52:45,526 [bic.py] => training => Task 6, Epoch 32/170 => Loss 2.472, Train_accy 90.900, Test_accy 45.640
2022-11-28 20:52:54,199 [bic.py] => training => Task 6, Epoch 33/170 => Loss 2.472, Train_accy 88.480, Test_accy 45.770
2022-11-28 20:53:02,694 [bic.py] => training => Task 6, Epoch 34/170 => Loss 2.480, Train_accy 88.970, Test_accy 41.200
2022-11-28 20:53:10,626 [bic.py] => training => Task 6, Epoch 35/170 => Loss 2.480, Train_accy 91.230, Test_accy 46.270
2022-11-28 20:53:19,332 [bic.py] => training => Task 6, Epoch 36/170 => Loss 2.476, Train_accy 92.230, Test_accy 46.110
2022-11-28 20:53:28,047 [bic.py] => training => Task 6, Epoch 37/170 => Loss 2.476, Train_accy 91.210, Test_accy 45.890
2022-11-28 20:53:36,424 [bic.py] => training => Task 6, Epoch 38/170 => Loss 2.471, Train_accy 90.720, Test_accy 47.510
2022-11-28 20:53:44,610 [bic.py] => training => Task 6, Epoch 39/170 => Loss 2.472, Train_accy 92.640, Test_accy 46.260
2022-11-28 20:53:52,582 [bic.py] => training => Task 6, Epoch 40/170 => Loss 2.475, Train_accy 89.970, Test_accy 44.030
2022-11-28 20:54:00,995 [bic.py] => training => Task 6, Epoch 41/170 => Loss 2.473, Train_accy 89.910, Test_accy 43.290
2022-11-28 20:54:09,112 [bic.py] => training => Task 6, Epoch 42/170 => Loss 2.476, Train_accy 91.990, Test_accy 45.070
2022-11-28 20:54:17,239 [bic.py] => training => Task 6, Epoch 43/170 => Loss 2.468, Train_accy 91.330, Test_accy 47.160
2022-11-28 20:54:25,952 [bic.py] => training => Task 6, Epoch 44/170 => Loss 2.468, Train_accy 93.250, Test_accy 47.430
2022-11-28 20:54:34,152 [bic.py] => training => Task 6, Epoch 45/170 => Loss 2.473, Train_accy 91.980, Test_accy 45.890
2022-11-28 20:54:42,939 [bic.py] => training => Task 6, Epoch 46/170 => Loss 2.465, Train_accy 91.030, Test_accy 45.730
2022-11-28 20:54:51,465 [bic.py] => training => Task 6, Epoch 47/170 => Loss 2.465, Train_accy 92.900, Test_accy 44.570
2022-11-28 20:55:00,286 [bic.py] => training => Task 6, Epoch 48/170 => Loss 2.474, Train_accy 88.170, Test_accy 43.740
2022-11-28 20:55:08,539 [bic.py] => training => Task 6, Epoch 49/170 => Loss 2.474, Train_accy 90.610, Test_accy 44.500
2022-11-28 20:55:16,719 [bic.py] => training => Task 6, Epoch 50/170 => Loss 2.467, Train_accy 92.920, Test_accy 47.760
2022-11-28 20:55:25,580 [bic.py] => training => Task 6, Epoch 51/170 => Loss 2.466, Train_accy 90.550, Test_accy 45.370
2022-11-28 20:55:33,631 [bic.py] => training => Task 6, Epoch 52/170 => Loss 2.471, Train_accy 92.880, Test_accy 45.840
2022-11-28 20:55:41,984 [bic.py] => training => Task 6, Epoch 53/170 => Loss 2.469, Train_accy 92.900, Test_accy 48.630
2022-11-28 20:55:50,459 [bic.py] => training => Task 6, Epoch 54/170 => Loss 2.472, Train_accy 91.820, Test_accy 45.260
2022-11-28 20:55:59,177 [bic.py] => training => Task 6, Epoch 55/170 => Loss 2.469, Train_accy 90.500, Test_accy 44.770
2022-11-28 20:56:07,221 [bic.py] => training => Task 6, Epoch 56/170 => Loss 2.469, Train_accy 90.710, Test_accy 44.940
2022-11-28 20:56:16,091 [bic.py] => training => Task 6, Epoch 57/170 => Loss 2.478, Train_accy 91.370, Test_accy 45.940
2022-11-28 20:56:25,285 [bic.py] => training => Task 6, Epoch 58/170 => Loss 2.474, Train_accy 92.780, Test_accy 45.570
2022-11-28 20:56:33,669 [bic.py] => training => Task 6, Epoch 59/170 => Loss 2.467, Train_accy 87.980, Test_accy 43.790
2022-11-28 20:56:41,488 [bic.py] => training => Task 6, Epoch 60/170 => Loss 2.465, Train_accy 90.320, Test_accy 48.330
2022-11-28 20:56:50,295 [bic.py] => training => Task 6, Epoch 61/170 => Loss 2.440, Train_accy 97.960, Test_accy 51.100
2022-11-28 20:56:58,712 [bic.py] => training => Task 6, Epoch 62/170 => Loss 2.428, Train_accy 98.090, Test_accy 51.670
2022-11-28 20:57:06,705 [bic.py] => training => Task 6, Epoch 63/170 => Loss 2.425, Train_accy 98.540, Test_accy 51.260
2022-11-28 20:57:14,875 [bic.py] => training => Task 6, Epoch 64/170 => Loss 2.420, Train_accy 98.490, Test_accy 51.740
2022-11-28 20:57:23,499 [bic.py] => training => Task 6, Epoch 65/170 => Loss 2.416, Train_accy 98.320, Test_accy 51.270
2022-11-28 20:57:31,910 [bic.py] => training => Task 6, Epoch 66/170 => Loss 2.417, Train_accy 98.540, Test_accy 52.640
2022-11-28 20:57:40,272 [bic.py] => training => Task 6, Epoch 67/170 => Loss 2.419, Train_accy 98.830, Test_accy 51.800
2022-11-28 20:57:48,621 [bic.py] => training => Task 6, Epoch 68/170 => Loss 2.412, Train_accy 98.700, Test_accy 52.400
2022-11-28 20:57:57,176 [bic.py] => training => Task 6, Epoch 69/170 => Loss 2.412, Train_accy 98.770, Test_accy 52.260
2022-11-28 20:58:05,776 [bic.py] => training => Task 6, Epoch 70/170 => Loss 2.417, Train_accy 99.010, Test_accy 52.330
2022-11-28 20:58:13,983 [bic.py] => training => Task 6, Epoch 71/170 => Loss 2.412, Train_accy 98.970, Test_accy 52.290
2022-11-28 20:58:22,211 [bic.py] => training => Task 6, Epoch 72/170 => Loss 2.420, Train_accy 98.830, Test_accy 51.390
2022-11-28 20:58:30,899 [bic.py] => training => Task 6, Epoch 73/170 => Loss 2.411, Train_accy 98.980, Test_accy 52.070
2022-11-28 20:58:39,473 [bic.py] => training => Task 6, Epoch 74/170 => Loss 2.404, Train_accy 99.050, Test_accy 52.730
2022-11-28 20:58:47,550 [bic.py] => training => Task 6, Epoch 75/170 => Loss 2.409, Train_accy 98.890, Test_accy 52.630
2022-11-28 20:58:56,037 [bic.py] => training => Task 6, Epoch 76/170 => Loss 2.413, Train_accy 98.920, Test_accy 51.430
2022-11-28 20:59:04,708 [bic.py] => training => Task 6, Epoch 77/170 => Loss 2.410, Train_accy 98.970, Test_accy 51.940
2022-11-28 20:59:13,261 [bic.py] => training => Task 6, Epoch 78/170 => Loss 2.406, Train_accy 99.200, Test_accy 52.340
2022-11-28 20:59:21,777 [bic.py] => training => Task 6, Epoch 79/170 => Loss 2.410, Train_accy 99.010, Test_accy 52.330
2022-11-28 20:59:30,135 [bic.py] => training => Task 6, Epoch 80/170 => Loss 2.410, Train_accy 99.000, Test_accy 52.130
2022-11-28 20:59:38,405 [bic.py] => training => Task 6, Epoch 81/170 => Loss 2.403, Train_accy 99.260, Test_accy 52.770
2022-11-28 20:59:46,770 [bic.py] => training => Task 6, Epoch 82/170 => Loss 2.408, Train_accy 99.080, Test_accy 52.460
2022-11-28 20:59:55,295 [bic.py] => training => Task 6, Epoch 83/170 => Loss 2.406, Train_accy 99.200, Test_accy 52.670
2022-11-28 21:00:03,680 [bic.py] => training => Task 6, Epoch 84/170 => Loss 2.405, Train_accy 99.130, Test_accy 52.300
2022-11-28 21:00:12,166 [bic.py] => training => Task 6, Epoch 85/170 => Loss 2.407, Train_accy 99.250, Test_accy 51.400
2022-11-28 21:00:20,643 [bic.py] => training => Task 6, Epoch 86/170 => Loss 2.403, Train_accy 99.130, Test_accy 52.030
2022-11-28 21:00:29,131 [bic.py] => training => Task 6, Epoch 87/170 => Loss 2.408, Train_accy 99.250, Test_accy 51.830
2022-11-28 21:00:37,485 [bic.py] => training => Task 6, Epoch 88/170 => Loss 2.405, Train_accy 99.350, Test_accy 52.310
2022-11-28 21:00:45,895 [bic.py] => training => Task 6, Epoch 89/170 => Loss 2.408, Train_accy 99.100, Test_accy 52.010
2022-11-28 21:00:54,432 [bic.py] => training => Task 6, Epoch 90/170 => Loss 2.406, Train_accy 99.130, Test_accy 52.490
2022-11-28 21:01:03,108 [bic.py] => training => Task 6, Epoch 91/170 => Loss 2.408, Train_accy 99.230, Test_accy 52.490
2022-11-28 21:01:11,482 [bic.py] => training => Task 6, Epoch 92/170 => Loss 2.405, Train_accy 99.230, Test_accy 52.910
2022-11-28 21:01:19,779 [bic.py] => training => Task 6, Epoch 93/170 => Loss 2.406, Train_accy 99.360, Test_accy 52.230
2022-11-28 21:01:28,833 [bic.py] => training => Task 6, Epoch 94/170 => Loss 2.414, Train_accy 99.340, Test_accy 52.890
2022-11-28 21:01:37,111 [bic.py] => training => Task 6, Epoch 95/170 => Loss 2.405, Train_accy 99.110, Test_accy 52.210
2022-11-28 21:01:45,674 [bic.py] => training => Task 6, Epoch 96/170 => Loss 2.402, Train_accy 99.170, Test_accy 51.630
2022-11-28 21:01:54,257 [bic.py] => training => Task 6, Epoch 97/170 => Loss 2.403, Train_accy 99.170, Test_accy 52.700
2022-11-28 21:02:03,311 [bic.py] => training => Task 6, Epoch 98/170 => Loss 2.400, Train_accy 99.290, Test_accy 52.790
2022-11-28 21:02:12,158 [bic.py] => training => Task 6, Epoch 99/170 => Loss 2.405, Train_accy 99.320, Test_accy 52.690
2022-11-28 21:02:21,258 [bic.py] => training => Task 6, Epoch 100/170 => Loss 2.400, Train_accy 99.290, Test_accy 51.570
2022-11-28 21:02:29,909 [bic.py] => training => Task 6, Epoch 101/170 => Loss 2.402, Train_accy 99.280, Test_accy 52.560
2022-11-28 21:02:37,980 [bic.py] => training => Task 6, Epoch 102/170 => Loss 2.405, Train_accy 99.290, Test_accy 52.030
2022-11-28 21:02:46,544 [bic.py] => training => Task 6, Epoch 103/170 => Loss 2.399, Train_accy 99.320, Test_accy 52.910
2022-11-28 21:02:55,249 [bic.py] => training => Task 6, Epoch 104/170 => Loss 2.403, Train_accy 99.420, Test_accy 52.290
2022-11-28 21:03:03,675 [bic.py] => training => Task 6, Epoch 105/170 => Loss 2.404, Train_accy 99.110, Test_accy 52.410
2022-11-28 21:03:11,825 [bic.py] => training => Task 6, Epoch 106/170 => Loss 2.401, Train_accy 99.360, Test_accy 52.760
2022-11-28 21:03:19,967 [bic.py] => training => Task 6, Epoch 107/170 => Loss 2.405, Train_accy 99.230, Test_accy 52.830
2022-11-28 21:03:28,690 [bic.py] => training => Task 6, Epoch 108/170 => Loss 2.403, Train_accy 99.250, Test_accy 52.760
2022-11-28 21:03:37,051 [bic.py] => training => Task 6, Epoch 109/170 => Loss 2.398, Train_accy 99.170, Test_accy 52.030
2022-11-28 21:03:45,539 [bic.py] => training => Task 6, Epoch 110/170 => Loss 2.402, Train_accy 99.410, Test_accy 52.740
2022-11-28 21:03:54,321 [bic.py] => training => Task 6, Epoch 111/170 => Loss 2.395, Train_accy 99.340, Test_accy 52.800
2022-11-28 21:04:02,849 [bic.py] => training => Task 6, Epoch 112/170 => Loss 2.400, Train_accy 99.160, Test_accy 52.210
2022-11-28 21:04:11,493 [bic.py] => training => Task 6, Epoch 113/170 => Loss 2.404, Train_accy 99.290, Test_accy 52.300
2022-11-28 21:04:19,907 [bic.py] => training => Task 6, Epoch 114/170 => Loss 2.398, Train_accy 99.260, Test_accy 52.460
2022-11-28 21:04:28,610 [bic.py] => training => Task 6, Epoch 115/170 => Loss 2.400, Train_accy 99.340, Test_accy 52.260
2022-11-28 21:04:36,855 [bic.py] => training => Task 6, Epoch 116/170 => Loss 2.400, Train_accy 99.310, Test_accy 52.090
2022-11-28 21:04:45,208 [bic.py] => training => Task 6, Epoch 117/170 => Loss 2.405, Train_accy 99.480, Test_accy 52.530
2022-11-28 21:04:53,871 [bic.py] => training => Task 6, Epoch 118/170 => Loss 2.401, Train_accy 99.500, Test_accy 52.660
2022-11-28 21:05:02,231 [bic.py] => training => Task 6, Epoch 119/170 => Loss 2.396, Train_accy 99.380, Test_accy 52.200
2022-11-28 21:05:10,720 [bic.py] => training => Task 6, Epoch 120/170 => Loss 2.407, Train_accy 99.320, Test_accy 52.570
2022-11-28 21:05:19,142 [bic.py] => training => Task 6, Epoch 121/170 => Loss 2.399, Train_accy 99.350, Test_accy 52.310
2022-11-28 21:05:27,710 [bic.py] => training => Task 6, Epoch 122/170 => Loss 2.398, Train_accy 99.340, Test_accy 52.660
2022-11-28 21:05:36,239 [bic.py] => training => Task 6, Epoch 123/170 => Loss 2.399, Train_accy 99.390, Test_accy 52.310
2022-11-28 21:05:44,867 [bic.py] => training => Task 6, Epoch 124/170 => Loss 2.406, Train_accy 99.280, Test_accy 51.870
2022-11-28 21:05:53,471 [bic.py] => training => Task 6, Epoch 125/170 => Loss 2.402, Train_accy 99.420, Test_accy 52.560
2022-11-28 21:06:02,423 [bic.py] => training => Task 6, Epoch 126/170 => Loss 2.400, Train_accy 99.500, Test_accy 52.190
2022-11-28 21:06:10,696 [bic.py] => training => Task 6, Epoch 127/170 => Loss 2.403, Train_accy 99.360, Test_accy 52.570
2022-11-28 21:06:18,691 [bic.py] => training => Task 6, Epoch 128/170 => Loss 2.403, Train_accy 99.440, Test_accy 52.810
2022-11-28 21:06:26,816 [bic.py] => training => Task 6, Epoch 129/170 => Loss 2.401, Train_accy 99.420, Test_accy 51.990
2022-11-28 21:06:34,973 [bic.py] => training => Task 6, Epoch 130/170 => Loss 2.399, Train_accy 99.310, Test_accy 52.840
2022-11-28 21:06:43,391 [bic.py] => training => Task 6, Epoch 131/170 => Loss 2.396, Train_accy 99.360, Test_accy 52.260
2022-11-28 21:06:51,649 [bic.py] => training => Task 6, Epoch 132/170 => Loss 2.405, Train_accy 99.410, Test_accy 52.210
2022-11-28 21:07:00,111 [bic.py] => training => Task 6, Epoch 133/170 => Loss 2.397, Train_accy 99.390, Test_accy 52.740
2022-11-28 21:07:08,780 [bic.py] => training => Task 6, Epoch 134/170 => Loss 2.401, Train_accy 99.250, Test_accy 52.340
2022-11-28 21:07:17,088 [bic.py] => training => Task 6, Epoch 135/170 => Loss 2.402, Train_accy 99.570, Test_accy 52.170
2022-11-28 21:07:25,536 [bic.py] => training => Task 6, Epoch 136/170 => Loss 2.397, Train_accy 99.250, Test_accy 52.490
2022-11-28 21:07:34,202 [bic.py] => training => Task 6, Epoch 137/170 => Loss 2.403, Train_accy 99.450, Test_accy 52.460
2022-11-28 21:07:42,640 [bic.py] => training => Task 6, Epoch 138/170 => Loss 2.396, Train_accy 99.320, Test_accy 52.160
2022-11-28 21:07:51,010 [bic.py] => training => Task 6, Epoch 139/170 => Loss 2.400, Train_accy 99.360, Test_accy 52.740
2022-11-28 21:07:59,586 [bic.py] => training => Task 6, Epoch 140/170 => Loss 2.398, Train_accy 99.380, Test_accy 52.270
2022-11-28 21:08:08,359 [bic.py] => training => Task 6, Epoch 141/170 => Loss 2.402, Train_accy 99.290, Test_accy 52.590
2022-11-28 21:08:16,949 [bic.py] => training => Task 6, Epoch 142/170 => Loss 2.398, Train_accy 99.390, Test_accy 52.490
2022-11-28 21:08:25,704 [bic.py] => training => Task 6, Epoch 143/170 => Loss 2.406, Train_accy 99.350, Test_accy 52.640
2022-11-28 21:08:34,113 [bic.py] => training => Task 6, Epoch 144/170 => Loss 2.401, Train_accy 99.250, Test_accy 52.490
2022-11-28 21:08:42,407 [bic.py] => training => Task 6, Epoch 145/170 => Loss 2.403, Train_accy 99.450, Test_accy 52.730
2022-11-28 21:08:50,626 [bic.py] => training => Task 6, Epoch 146/170 => Loss 2.402, Train_accy 99.290, Test_accy 52.710
2022-11-28 21:08:59,505 [bic.py] => training => Task 6, Epoch 147/170 => Loss 2.397, Train_accy 99.310, Test_accy 52.790
2022-11-28 21:09:07,739 [bic.py] => training => Task 6, Epoch 148/170 => Loss 2.401, Train_accy 99.340, Test_accy 52.570
2022-11-28 21:09:16,179 [bic.py] => training => Task 6, Epoch 149/170 => Loss 2.402, Train_accy 99.450, Test_accy 52.260
2022-11-28 21:09:25,087 [bic.py] => training => Task 6, Epoch 150/170 => Loss 2.399, Train_accy 99.450, Test_accy 52.740
2022-11-28 21:09:33,355 [bic.py] => training => Task 6, Epoch 151/170 => Loss 2.399, Train_accy 99.390, Test_accy 52.590
2022-11-28 21:09:41,828 [bic.py] => training => Task 6, Epoch 152/170 => Loss 2.406, Train_accy 99.450, Test_accy 52.410
2022-11-28 21:09:50,178 [bic.py] => training => Task 6, Epoch 153/170 => Loss 2.400, Train_accy 99.320, Test_accy 52.790
2022-11-28 21:09:58,877 [bic.py] => training => Task 6, Epoch 154/170 => Loss 2.399, Train_accy 99.280, Test_accy 52.700
2022-11-28 21:10:07,618 [bic.py] => training => Task 6, Epoch 155/170 => Loss 2.401, Train_accy 99.110, Test_accy 52.610
2022-11-28 21:10:15,837 [bic.py] => training => Task 6, Epoch 156/170 => Loss 2.398, Train_accy 99.380, Test_accy 52.660
2022-11-28 21:10:24,403 [bic.py] => training => Task 6, Epoch 157/170 => Loss 2.397, Train_accy 99.250, Test_accy 52.740
2022-11-28 21:10:33,085 [bic.py] => training => Task 6, Epoch 158/170 => Loss 2.399, Train_accy 99.410, Test_accy 52.900
2022-11-28 21:10:41,705 [bic.py] => training => Task 6, Epoch 159/170 => Loss 2.399, Train_accy 99.530, Test_accy 53.510
2022-11-28 21:10:50,141 [bic.py] => training => Task 6, Epoch 160/170 => Loss 2.405, Train_accy 99.250, Test_accy 52.710
2022-11-28 21:10:58,603 [bic.py] => training => Task 6, Epoch 161/170 => Loss 2.403, Train_accy 99.500, Test_accy 52.770
2022-11-28 21:11:06,702 [bic.py] => training => Task 6, Epoch 162/170 => Loss 2.403, Train_accy 99.450, Test_accy 53.000
2022-11-28 21:11:15,053 [bic.py] => training => Task 6, Epoch 163/170 => Loss 2.404, Train_accy 99.310, Test_accy 52.890
2022-11-28 21:11:23,845 [bic.py] => training => Task 6, Epoch 164/170 => Loss 2.403, Train_accy 99.250, Test_accy 52.400
2022-11-28 21:11:32,221 [bic.py] => training => Task 6, Epoch 165/170 => Loss 2.402, Train_accy 99.360, Test_accy 52.600
2022-11-28 21:11:40,624 [bic.py] => training => Task 6, Epoch 166/170 => Loss 2.401, Train_accy 99.510, Test_accy 52.400
2022-11-28 21:11:48,890 [bic.py] => training => Task 6, Epoch 167/170 => Loss 2.395, Train_accy 99.320, Test_accy 52.400
2022-11-28 21:11:57,514 [bic.py] => training => Task 6, Epoch 168/170 => Loss 2.400, Train_accy 99.360, Test_accy 52.160
2022-11-28 21:12:06,021 [bic.py] => training => Task 6, Epoch 169/170 => Loss 2.400, Train_accy 99.320, Test_accy 52.510
2022-11-28 21:12:14,436 [bic.py] => training => Task 6, Epoch 170/170 => Loss 2.401, Train_accy 99.250, Test_accy 52.810
2022-11-28 21:12:18,265 [bic.py] => bias_correction => Task 6, Epoch 1/170 => Loss 3.718, Train_accy 74.290, Test_accy 55.310
2022-11-28 21:12:22,007 [bic.py] => bias_correction => Task 6, Epoch 2/170 => Loss 3.703, Train_accy 82.860, Test_accy 59.310
2022-11-28 21:12:25,813 [bic.py] => bias_correction => Task 6, Epoch 3/170 => Loss 3.637, Train_accy 82.860, Test_accy 58.010
2022-11-28 21:12:29,341 [bic.py] => bias_correction => Task 6, Epoch 4/170 => Loss 3.650, Train_accy 79.050, Test_accy 54.730
2022-11-28 21:12:33,108 [bic.py] => bias_correction => Task 6, Epoch 5/170 => Loss 3.667, Train_accy 76.190, Test_accy 53.070
2022-11-28 21:12:36,929 [bic.py] => bias_correction => Task 6, Epoch 6/170 => Loss 3.677, Train_accy 75.710, Test_accy 52.670
2022-11-28 21:12:40,838 [bic.py] => bias_correction => Task 6, Epoch 7/170 => Loss 3.674, Train_accy 77.140, Test_accy 52.170
2022-11-28 21:12:44,593 [bic.py] => bias_correction => Task 6, Epoch 8/170 => Loss 3.675, Train_accy 74.760, Test_accy 52.230
2022-11-28 21:12:48,258 [bic.py] => bias_correction => Task 6, Epoch 9/170 => Loss 3.654, Train_accy 77.140, Test_accy 52.090
2022-11-28 21:12:52,060 [bic.py] => bias_correction => Task 6, Epoch 10/170 => Loss 3.662, Train_accy 74.290, Test_accy 52.700
2022-11-28 21:12:55,903 [bic.py] => bias_correction => Task 6, Epoch 11/170 => Loss 3.676, Train_accy 77.140, Test_accy 53.590
2022-11-28 21:12:59,855 [bic.py] => bias_correction => Task 6, Epoch 12/170 => Loss 3.673, Train_accy 79.050, Test_accy 55.270
2022-11-28 21:13:03,557 [bic.py] => bias_correction => Task 6, Epoch 13/170 => Loss 3.656, Train_accy 85.710, Test_accy 57.590
2022-11-28 21:13:07,298 [bic.py] => bias_correction => Task 6, Epoch 14/170 => Loss 3.641, Train_accy 81.900, Test_accy 58.670
2022-11-28 21:13:10,930 [bic.py] => bias_correction => Task 6, Epoch 15/170 => Loss 3.639, Train_accy 80.000, Test_accy 57.940
2022-11-28 21:13:14,678 [bic.py] => bias_correction => Task 6, Epoch 16/170 => Loss 3.672, Train_accy 83.330, Test_accy 57.630
2022-11-28 21:13:18,346 [bic.py] => bias_correction => Task 6, Epoch 17/170 => Loss 3.642, Train_accy 81.430, Test_accy 58.230
2022-11-28 21:13:22,197 [bic.py] => bias_correction => Task 6, Epoch 18/170 => Loss 3.640, Train_accy 83.810, Test_accy 58.610
2022-11-28 21:13:26,023 [bic.py] => bias_correction => Task 6, Epoch 19/170 => Loss 3.651, Train_accy 82.380, Test_accy 58.170
2022-11-28 21:13:29,631 [bic.py] => bias_correction => Task 6, Epoch 20/170 => Loss 3.651, Train_accy 80.480, Test_accy 58.090
2022-11-28 21:13:33,378 [bic.py] => bias_correction => Task 6, Epoch 21/170 => Loss 3.631, Train_accy 84.760, Test_accy 58.060
2022-11-28 21:13:37,075 [bic.py] => bias_correction => Task 6, Epoch 22/170 => Loss 3.644, Train_accy 83.330, Test_accy 58.200
2022-11-28 21:13:40,633 [bic.py] => bias_correction => Task 6, Epoch 23/170 => Loss 3.638, Train_accy 83.810, Test_accy 58.500
2022-11-28 21:13:44,238 [bic.py] => bias_correction => Task 6, Epoch 24/170 => Loss 3.639, Train_accy 80.950, Test_accy 58.130
2022-11-28 21:13:48,028 [bic.py] => bias_correction => Task 6, Epoch 25/170 => Loss 3.655, Train_accy 81.900, Test_accy 58.130
2022-11-28 21:13:51,920 [bic.py] => bias_correction => Task 6, Epoch 26/170 => Loss 3.651, Train_accy 80.000, Test_accy 58.360
2022-11-28 21:13:55,713 [bic.py] => bias_correction => Task 6, Epoch 27/170 => Loss 3.647, Train_accy 80.950, Test_accy 58.260
2022-11-28 21:13:59,707 [bic.py] => bias_correction => Task 6, Epoch 28/170 => Loss 3.658, Train_accy 80.000, Test_accy 58.200
2022-11-28 21:14:03,382 [bic.py] => bias_correction => Task 6, Epoch 29/170 => Loss 3.636, Train_accy 82.380, Test_accy 58.440
2022-11-28 21:14:07,136 [bic.py] => bias_correction => Task 6, Epoch 30/170 => Loss 3.643, Train_accy 83.810, Test_accy 58.860
2022-11-28 21:14:10,817 [bic.py] => bias_correction => Task 6, Epoch 31/170 => Loss 3.656, Train_accy 80.480, Test_accy 58.710
2022-11-28 21:14:14,617 [bic.py] => bias_correction => Task 6, Epoch 32/170 => Loss 3.647, Train_accy 82.380, Test_accy 58.740
2022-11-28 21:14:18,406 [bic.py] => bias_correction => Task 6, Epoch 33/170 => Loss 3.623, Train_accy 82.860, Test_accy 58.610
2022-11-28 21:14:22,081 [bic.py] => bias_correction => Task 6, Epoch 34/170 => Loss 3.634, Train_accy 85.240, Test_accy 58.670
2022-11-28 21:14:25,788 [bic.py] => bias_correction => Task 6, Epoch 35/170 => Loss 3.637, Train_accy 82.860, Test_accy 58.430
2022-11-28 21:14:29,661 [bic.py] => bias_correction => Task 6, Epoch 36/170 => Loss 3.628, Train_accy 85.710, Test_accy 58.530
2022-11-28 21:14:33,354 [bic.py] => bias_correction => Task 6, Epoch 37/170 => Loss 3.623, Train_accy 84.760, Test_accy 58.660
2022-11-28 21:14:37,171 [bic.py] => bias_correction => Task 6, Epoch 38/170 => Loss 3.635, Train_accy 83.810, Test_accy 58.390
2022-11-28 21:14:40,791 [bic.py] => bias_correction => Task 6, Epoch 39/170 => Loss 3.630, Train_accy 84.290, Test_accy 58.230
2022-11-28 21:14:44,624 [bic.py] => bias_correction => Task 6, Epoch 40/170 => Loss 3.625, Train_accy 83.810, Test_accy 58.400
2022-11-28 21:14:48,489 [bic.py] => bias_correction => Task 6, Epoch 41/170 => Loss 3.628, Train_accy 81.430, Test_accy 58.340
2022-11-28 21:14:52,230 [bic.py] => bias_correction => Task 6, Epoch 42/170 => Loss 3.635, Train_accy 81.900, Test_accy 58.570
2022-11-28 21:14:56,313 [bic.py] => bias_correction => Task 6, Epoch 43/170 => Loss 3.627, Train_accy 81.900, Test_accy 58.600
2022-11-28 21:15:00,055 [bic.py] => bias_correction => Task 6, Epoch 44/170 => Loss 3.606, Train_accy 83.810, Test_accy 58.660
2022-11-28 21:15:03,800 [bic.py] => bias_correction => Task 6, Epoch 45/170 => Loss 3.636, Train_accy 82.860, Test_accy 58.600
2022-11-28 21:15:07,440 [bic.py] => bias_correction => Task 6, Epoch 46/170 => Loss 3.615, Train_accy 82.380, Test_accy 58.660
2022-11-28 21:15:11,142 [bic.py] => bias_correction => Task 6, Epoch 47/170 => Loss 3.640, Train_accy 83.330, Test_accy 58.570
2022-11-28 21:15:14,942 [bic.py] => bias_correction => Task 6, Epoch 48/170 => Loss 3.649, Train_accy 85.710, Test_accy 58.610
2022-11-28 21:15:18,654 [bic.py] => bias_correction => Task 6, Epoch 49/170 => Loss 3.647, Train_accy 83.810, Test_accy 58.490
2022-11-28 21:15:22,318 [bic.py] => bias_correction => Task 6, Epoch 50/170 => Loss 3.655, Train_accy 82.380, Test_accy 58.440
2022-11-28 21:15:25,875 [bic.py] => bias_correction => Task 6, Epoch 51/170 => Loss 3.631, Train_accy 81.900, Test_accy 58.430
2022-11-28 21:15:29,611 [bic.py] => bias_correction => Task 6, Epoch 52/170 => Loss 3.637, Train_accy 84.290, Test_accy 58.390
2022-11-28 21:15:33,308 [bic.py] => bias_correction => Task 6, Epoch 53/170 => Loss 3.630, Train_accy 81.900, Test_accy 58.400
2022-11-28 21:15:36,946 [bic.py] => bias_correction => Task 6, Epoch 54/170 => Loss 3.634, Train_accy 82.380, Test_accy 58.230
2022-11-28 21:15:40,753 [bic.py] => bias_correction => Task 6, Epoch 55/170 => Loss 3.629, Train_accy 84.760, Test_accy 58.440
2022-11-28 21:15:44,631 [bic.py] => bias_correction => Task 6, Epoch 56/170 => Loss 3.634, Train_accy 85.240, Test_accy 58.330
2022-11-28 21:15:48,313 [bic.py] => bias_correction => Task 6, Epoch 57/170 => Loss 3.645, Train_accy 80.480, Test_accy 58.630
2022-11-28 21:15:52,020 [bic.py] => bias_correction => Task 6, Epoch 58/170 => Loss 3.605, Train_accy 83.810, Test_accy 58.500
2022-11-28 21:15:55,840 [bic.py] => bias_correction => Task 6, Epoch 59/170 => Loss 3.617, Train_accy 82.380, Test_accy 58.630
2022-11-28 21:15:59,691 [bic.py] => bias_correction => Task 6, Epoch 60/170 => Loss 3.634, Train_accy 81.900, Test_accy 58.830
2022-11-28 21:16:03,348 [bic.py] => bias_correction => Task 6, Epoch 61/170 => Loss 3.624, Train_accy 82.380, Test_accy 59.110
2022-11-28 21:16:06,882 [bic.py] => bias_correction => Task 6, Epoch 62/170 => Loss 3.645, Train_accy 81.900, Test_accy 58.990
2022-11-28 21:16:10,550 [bic.py] => bias_correction => Task 6, Epoch 63/170 => Loss 3.634, Train_accy 84.290, Test_accy 59.000
2022-11-28 21:16:14,433 [bic.py] => bias_correction => Task 6, Epoch 64/170 => Loss 3.634, Train_accy 82.860, Test_accy 58.900
2022-11-28 21:16:18,212 [bic.py] => bias_correction => Task 6, Epoch 65/170 => Loss 3.625, Train_accy 82.860, Test_accy 59.130
2022-11-28 21:16:22,253 [bic.py] => bias_correction => Task 6, Epoch 66/170 => Loss 3.629, Train_accy 86.190, Test_accy 59.000
2022-11-28 21:16:26,127 [bic.py] => bias_correction => Task 6, Epoch 67/170 => Loss 3.620, Train_accy 86.190, Test_accy 59.230
2022-11-28 21:16:29,977 [bic.py] => bias_correction => Task 6, Epoch 68/170 => Loss 3.652, Train_accy 82.380, Test_accy 59.230
2022-11-28 21:16:33,885 [bic.py] => bias_correction => Task 6, Epoch 69/170 => Loss 3.623, Train_accy 85.710, Test_accy 59.270
2022-11-28 21:16:37,563 [bic.py] => bias_correction => Task 6, Epoch 70/170 => Loss 3.610, Train_accy 86.670, Test_accy 58.970
2022-11-28 21:16:41,489 [bic.py] => bias_correction => Task 6, Epoch 71/170 => Loss 3.634, Train_accy 82.860, Test_accy 58.710
2022-11-28 21:16:45,112 [bic.py] => bias_correction => Task 6, Epoch 72/170 => Loss 3.629, Train_accy 84.290, Test_accy 58.600
2022-11-28 21:16:48,922 [bic.py] => bias_correction => Task 6, Epoch 73/170 => Loss 3.624, Train_accy 80.950, Test_accy 58.860
2022-11-28 21:16:52,851 [bic.py] => bias_correction => Task 6, Epoch 74/170 => Loss 3.619, Train_accy 81.430, Test_accy 58.500
2022-11-28 21:16:56,747 [bic.py] => bias_correction => Task 6, Epoch 75/170 => Loss 3.629, Train_accy 83.330, Test_accy 58.760
2022-11-28 21:17:00,375 [bic.py] => bias_correction => Task 6, Epoch 76/170 => Loss 3.634, Train_accy 81.430, Test_accy 58.530
2022-11-28 21:17:04,158 [bic.py] => bias_correction => Task 6, Epoch 77/170 => Loss 3.638, Train_accy 82.380, Test_accy 58.910
2022-11-28 21:17:07,885 [bic.py] => bias_correction => Task 6, Epoch 78/170 => Loss 3.630, Train_accy 81.900, Test_accy 58.810
2022-11-28 21:17:11,580 [bic.py] => bias_correction => Task 6, Epoch 79/170 => Loss 3.635, Train_accy 81.430, Test_accy 58.870
2022-11-28 21:17:15,311 [bic.py] => bias_correction => Task 6, Epoch 80/170 => Loss 3.621, Train_accy 80.950, Test_accy 59.070
2022-11-28 21:17:19,314 [bic.py] => bias_correction => Task 6, Epoch 81/170 => Loss 3.641, Train_accy 83.330, Test_accy 59.090
2022-11-28 21:17:23,409 [bic.py] => bias_correction => Task 6, Epoch 82/170 => Loss 3.631, Train_accy 81.900, Test_accy 59.130
2022-11-28 21:17:27,076 [bic.py] => bias_correction => Task 6, Epoch 83/170 => Loss 3.615, Train_accy 80.480, Test_accy 58.870
2022-11-28 21:17:30,663 [bic.py] => bias_correction => Task 6, Epoch 84/170 => Loss 3.616, Train_accy 85.710, Test_accy 58.830
2022-11-28 21:17:34,630 [bic.py] => bias_correction => Task 6, Epoch 85/170 => Loss 3.649, Train_accy 81.900, Test_accy 58.910
2022-11-28 21:17:38,591 [bic.py] => bias_correction => Task 6, Epoch 86/170 => Loss 3.644, Train_accy 84.760, Test_accy 59.170
2022-11-28 21:17:42,355 [bic.py] => bias_correction => Task 6, Epoch 87/170 => Loss 3.620, Train_accy 80.950, Test_accy 58.940
2022-11-28 21:17:46,117 [bic.py] => bias_correction => Task 6, Epoch 88/170 => Loss 3.640, Train_accy 83.810, Test_accy 58.960
2022-11-28 21:17:49,779 [bic.py] => bias_correction => Task 6, Epoch 89/170 => Loss 3.624, Train_accy 82.380, Test_accy 58.870
2022-11-28 21:17:54,033 [bic.py] => bias_correction => Task 6, Epoch 90/170 => Loss 3.611, Train_accy 83.810, Test_accy 58.630
2022-11-28 21:17:57,780 [bic.py] => bias_correction => Task 6, Epoch 91/170 => Loss 3.649, Train_accy 84.290, Test_accy 58.610
2022-11-28 21:18:01,475 [bic.py] => bias_correction => Task 6, Epoch 92/170 => Loss 3.644, Train_accy 83.810, Test_accy 58.930
2022-11-28 21:18:05,338 [bic.py] => bias_correction => Task 6, Epoch 93/170 => Loss 3.630, Train_accy 84.760, Test_accy 59.140
2022-11-28 21:18:08,964 [bic.py] => bias_correction => Task 6, Epoch 94/170 => Loss 3.622, Train_accy 87.620, Test_accy 58.900
2022-11-28 21:18:12,752 [bic.py] => bias_correction => Task 6, Epoch 95/170 => Loss 3.626, Train_accy 82.380, Test_accy 58.890
2022-11-28 21:18:16,486 [bic.py] => bias_correction => Task 6, Epoch 96/170 => Loss 3.622, Train_accy 82.380, Test_accy 58.830
2022-11-28 21:18:20,228 [bic.py] => bias_correction => Task 6, Epoch 97/170 => Loss 3.635, Train_accy 81.430, Test_accy 58.640
2022-11-28 21:18:24,136 [bic.py] => bias_correction => Task 6, Epoch 98/170 => Loss 3.624, Train_accy 84.760, Test_accy 58.700
2022-11-28 21:18:28,011 [bic.py] => bias_correction => Task 6, Epoch 99/170 => Loss 3.640, Train_accy 80.950, Test_accy 58.740
2022-11-28 21:18:31,716 [bic.py] => bias_correction => Task 6, Epoch 100/170 => Loss 3.626, Train_accy 81.900, Test_accy 58.860
2022-11-28 21:18:35,643 [bic.py] => bias_correction => Task 6, Epoch 101/170 => Loss 3.636, Train_accy 82.380, Test_accy 59.090
2022-11-28 21:18:39,487 [bic.py] => bias_correction => Task 6, Epoch 102/170 => Loss 3.631, Train_accy 81.430, Test_accy 58.940
2022-11-28 21:18:43,239 [bic.py] => bias_correction => Task 6, Epoch 103/170 => Loss 3.630, Train_accy 84.290, Test_accy 58.900
2022-11-28 21:18:47,009 [bic.py] => bias_correction => Task 6, Epoch 104/170 => Loss 3.630, Train_accy 80.950, Test_accy 59.000
2022-11-28 21:18:50,661 [bic.py] => bias_correction => Task 6, Epoch 105/170 => Loss 3.624, Train_accy 80.950, Test_accy 59.060
2022-11-28 21:18:54,466 [bic.py] => bias_correction => Task 6, Epoch 106/170 => Loss 3.616, Train_accy 82.380, Test_accy 58.800
2022-11-28 21:18:58,300 [bic.py] => bias_correction => Task 6, Epoch 107/170 => Loss 3.653, Train_accy 84.290, Test_accy 59.030
2022-11-28 21:19:02,416 [bic.py] => bias_correction => Task 6, Epoch 108/170 => Loss 3.614, Train_accy 81.900, Test_accy 59.170
2022-11-28 21:19:06,223 [bic.py] => bias_correction => Task 6, Epoch 109/170 => Loss 3.629, Train_accy 84.760, Test_accy 59.160
2022-11-28 21:19:10,131 [bic.py] => bias_correction => Task 6, Epoch 110/170 => Loss 3.623, Train_accy 81.900, Test_accy 59.140
2022-11-28 21:19:13,820 [bic.py] => bias_correction => Task 6, Epoch 111/170 => Loss 3.624, Train_accy 82.380, Test_accy 59.190
2022-11-28 21:19:17,557 [bic.py] => bias_correction => Task 6, Epoch 112/170 => Loss 3.623, Train_accy 85.240, Test_accy 59.160
2022-11-28 21:19:21,235 [bic.py] => bias_correction => Task 6, Epoch 113/170 => Loss 3.635, Train_accy 81.900, Test_accy 59.140
2022-11-28 21:19:25,031 [bic.py] => bias_correction => Task 6, Epoch 114/170 => Loss 3.622, Train_accy 83.330, Test_accy 58.970
2022-11-28 21:19:28,851 [bic.py] => bias_correction => Task 6, Epoch 115/170 => Loss 3.648, Train_accy 82.380, Test_accy 58.690
2022-11-28 21:19:32,557 [bic.py] => bias_correction => Task 6, Epoch 116/170 => Loss 3.650, Train_accy 81.430, Test_accy 59.070
2022-11-28 21:19:36,234 [bic.py] => bias_correction => Task 6, Epoch 117/170 => Loss 3.634, Train_accy 81.900, Test_accy 58.970
2022-11-28 21:19:40,039 [bic.py] => bias_correction => Task 6, Epoch 118/170 => Loss 3.630, Train_accy 80.950, Test_accy 58.740
2022-11-28 21:19:43,897 [bic.py] => bias_correction => Task 6, Epoch 119/170 => Loss 3.605, Train_accy 84.760, Test_accy 58.630
2022-11-28 21:19:47,964 [bic.py] => bias_correction => Task 6, Epoch 120/170 => Loss 3.610, Train_accy 82.380, Test_accy 58.800
2022-11-28 21:19:51,699 [bic.py] => bias_correction => Task 6, Epoch 121/170 => Loss 3.641, Train_accy 82.860, Test_accy 58.870
2022-11-28 21:19:55,388 [bic.py] => bias_correction => Task 6, Epoch 122/170 => Loss 3.622, Train_accy 85.240, Test_accy 58.790
2022-11-28 21:19:59,200 [bic.py] => bias_correction => Task 6, Epoch 123/170 => Loss 3.640, Train_accy 81.900, Test_accy 58.870
2022-11-28 21:20:03,031 [bic.py] => bias_correction => Task 6, Epoch 124/170 => Loss 3.636, Train_accy 82.380, Test_accy 59.010
2022-11-28 21:20:06,828 [bic.py] => bias_correction => Task 6, Epoch 125/170 => Loss 3.625, Train_accy 84.290, Test_accy 58.990
2022-11-28 21:20:10,468 [bic.py] => bias_correction => Task 6, Epoch 126/170 => Loss 3.625, Train_accy 84.760, Test_accy 58.810
2022-11-28 21:20:14,187 [bic.py] => bias_correction => Task 6, Epoch 127/170 => Loss 3.625, Train_accy 83.810, Test_accy 58.900
2022-11-28 21:20:18,060 [bic.py] => bias_correction => Task 6, Epoch 128/170 => Loss 3.622, Train_accy 81.900, Test_accy 58.600
2022-11-28 21:20:21,825 [bic.py] => bias_correction => Task 6, Epoch 129/170 => Loss 3.621, Train_accy 80.480, Test_accy 58.640
2022-11-28 21:20:25,538 [bic.py] => bias_correction => Task 6, Epoch 130/170 => Loss 3.618, Train_accy 81.900, Test_accy 58.730
2022-11-28 21:20:29,246 [bic.py] => bias_correction => Task 6, Epoch 131/170 => Loss 3.619, Train_accy 84.290, Test_accy 58.900
2022-11-28 21:20:32,997 [bic.py] => bias_correction => Task 6, Epoch 132/170 => Loss 3.631, Train_accy 83.330, Test_accy 58.660
2022-11-28 21:20:36,795 [bic.py] => bias_correction => Task 6, Epoch 133/170 => Loss 3.622, Train_accy 83.810, Test_accy 58.670
2022-11-28 21:20:40,572 [bic.py] => bias_correction => Task 6, Epoch 134/170 => Loss 3.619, Train_accy 86.190, Test_accy 58.740
2022-11-28 21:20:44,457 [bic.py] => bias_correction => Task 6, Epoch 135/170 => Loss 3.641, Train_accy 83.330, Test_accy 58.690
2022-11-28 21:20:48,383 [bic.py] => bias_correction => Task 6, Epoch 136/170 => Loss 3.632, Train_accy 85.240, Test_accy 58.890
2022-11-28 21:20:52,204 [bic.py] => bias_correction => Task 6, Epoch 137/170 => Loss 3.636, Train_accy 83.810, Test_accy 58.640
2022-11-28 21:20:55,899 [bic.py] => bias_correction => Task 6, Epoch 138/170 => Loss 3.641, Train_accy 82.860, Test_accy 58.810
2022-11-28 21:20:59,843 [bic.py] => bias_correction => Task 6, Epoch 139/170 => Loss 3.620, Train_accy 80.480, Test_accy 58.740
2022-11-28 21:21:03,542 [bic.py] => bias_correction => Task 6, Epoch 140/170 => Loss 3.606, Train_accy 84.290, Test_accy 58.740
2022-11-28 21:21:07,395 [bic.py] => bias_correction => Task 6, Epoch 141/170 => Loss 3.649, Train_accy 85.240, Test_accy 58.960
2022-11-28 21:21:11,165 [bic.py] => bias_correction => Task 6, Epoch 142/170 => Loss 3.634, Train_accy 83.810, Test_accy 58.890
2022-11-28 21:21:14,948 [bic.py] => bias_correction => Task 6, Epoch 143/170 => Loss 3.624, Train_accy 84.760, Test_accy 58.770
2022-11-28 21:21:19,023 [bic.py] => bias_correction => Task 6, Epoch 144/170 => Loss 3.629, Train_accy 81.900, Test_accy 58.670
2022-11-28 21:21:23,081 [bic.py] => bias_correction => Task 6, Epoch 145/170 => Loss 3.616, Train_accy 83.810, Test_accy 58.640
2022-11-28 21:21:26,911 [bic.py] => bias_correction => Task 6, Epoch 146/170 => Loss 3.630, Train_accy 81.430, Test_accy 58.670
2022-11-28 21:21:30,796 [bic.py] => bias_correction => Task 6, Epoch 147/170 => Loss 3.631, Train_accy 81.430, Test_accy 59.000
2022-11-28 21:21:34,357 [bic.py] => bias_correction => Task 6, Epoch 148/170 => Loss 3.636, Train_accy 83.330, Test_accy 58.810
2022-11-28 21:21:38,072 [bic.py] => bias_correction => Task 6, Epoch 149/170 => Loss 3.630, Train_accy 81.900, Test_accy 58.770
2022-11-28 21:21:41,831 [bic.py] => bias_correction => Task 6, Epoch 150/170 => Loss 3.634, Train_accy 81.430, Test_accy 58.600
2022-11-28 21:21:45,603 [bic.py] => bias_correction => Task 6, Epoch 151/170 => Loss 3.635, Train_accy 82.860, Test_accy 58.740
2022-11-28 21:21:49,261 [bic.py] => bias_correction => Task 6, Epoch 152/170 => Loss 3.625, Train_accy 84.760, Test_accy 58.770
2022-11-28 21:21:53,278 [bic.py] => bias_correction => Task 6, Epoch 153/170 => Loss 3.628, Train_accy 81.430, Test_accy 59.110
2022-11-28 21:21:57,141 [bic.py] => bias_correction => Task 6, Epoch 154/170 => Loss 3.634, Train_accy 82.860, Test_accy 59.040
2022-11-28 21:22:01,097 [bic.py] => bias_correction => Task 6, Epoch 155/170 => Loss 3.616, Train_accy 82.860, Test_accy 58.840
2022-11-28 21:22:04,835 [bic.py] => bias_correction => Task 6, Epoch 156/170 => Loss 3.619, Train_accy 82.860, Test_accy 58.590
2022-11-28 21:22:08,820 [bic.py] => bias_correction => Task 6, Epoch 157/170 => Loss 3.633, Train_accy 81.900, Test_accy 58.540
2022-11-28 21:22:12,576 [bic.py] => bias_correction => Task 6, Epoch 158/170 => Loss 3.621, Train_accy 81.900, Test_accy 58.670
2022-11-28 21:22:16,231 [bic.py] => bias_correction => Task 6, Epoch 159/170 => Loss 3.629, Train_accy 82.380, Test_accy 58.600
2022-11-28 21:22:19,999 [bic.py] => bias_correction => Task 6, Epoch 160/170 => Loss 3.633, Train_accy 81.900, Test_accy 58.540
2022-11-28 21:22:24,187 [bic.py] => bias_correction => Task 6, Epoch 161/170 => Loss 3.619, Train_accy 82.380, Test_accy 58.510
2022-11-28 21:22:27,917 [bic.py] => bias_correction => Task 6, Epoch 162/170 => Loss 3.633, Train_accy 83.330, Test_accy 58.760
2022-11-28 21:22:31,706 [bic.py] => bias_correction => Task 6, Epoch 163/170 => Loss 3.618, Train_accy 83.330, Test_accy 58.830
2022-11-28 21:22:35,742 [bic.py] => bias_correction => Task 6, Epoch 164/170 => Loss 3.628, Train_accy 81.900, Test_accy 58.810
2022-11-28 21:22:39,542 [bic.py] => bias_correction => Task 6, Epoch 165/170 => Loss 3.622, Train_accy 82.380, Test_accy 58.860
2022-11-28 21:22:43,268 [bic.py] => bias_correction => Task 6, Epoch 166/170 => Loss 3.638, Train_accy 82.860, Test_accy 59.030
2022-11-28 21:22:47,098 [bic.py] => bias_correction => Task 6, Epoch 167/170 => Loss 3.635, Train_accy 82.860, Test_accy 59.190
2022-11-28 21:22:50,893 [bic.py] => bias_correction => Task 6, Epoch 168/170 => Loss 3.641, Train_accy 83.810, Test_accy 59.010
2022-11-28 21:22:54,782 [bic.py] => bias_correction => Task 6, Epoch 169/170 => Loss 3.620, Train_accy 81.900, Test_accy 58.900
2022-11-28 21:22:58,704 [bic.py] => bias_correction => Task 6, Epoch 170/170 => Loss 3.607, Train_accy 85.240, Test_accy 58.660
2022-11-28 21:22:58,705 [base.py] => Reducing exemplars...(28 per classes)
2022-11-28 21:23:23,199 [base.py] => Constructing exemplars...(28 per classes)
2022-11-28 21:23:31,883 [bic.py] => Parameters of bias layer:
2022-11-28 21:23:31,884 [bic.py] => 0 => 1.000, 0.000
2022-11-28 21:23:31,884 [bic.py] => 1 => 0.976, -1.640
2022-11-28 21:23:31,884 [bic.py] => 2 => 0.847, -1.789
2022-11-28 21:23:31,884 [bic.py] => 3 => 0.728, -1.453
2022-11-28 21:23:31,884 [bic.py] => 4 => 0.739, -1.271
2022-11-28 21:23:31,884 [bic.py] => 5 => 0.788, -1.449
2022-11-28 21:23:31,884 [bic.py] => 6 => 0.727, -1.396
2022-11-28 21:23:34,224 [bic.py] => Exemplar size: 1960
2022-11-28 21:23:34,224 [trainer.py] => CNN: {'total': 58.66, '00-09': 64.2, '10-19': 50.7, '20-29': 61.1, '30-39': 50.9, '40-49': 61.0, '50-59': 58.6, '60-69': 64.1, 'old': 57.75, 'new': 64.1}
2022-11-28 21:23:34,224 [trainer.py] => NME: {'total': 58.87, '00-09': 60.3, '10-19': 43.5, '20-29': 58.9, '30-39': 50.8, '40-49': 66.4, '50-59': 58.3, '60-69': 73.9, 'old': 56.37, 'new': 73.9}
2022-11-28 21:23:34,225 [trainer.py] => CNN top1 curve: [88.7, 75.6, 72.3, 66.6, 64.42, 60.9, 58.66]
2022-11-28 21:23:34,225 [trainer.py] => CNN top5 curve: [99.4, 95.6, 93.5, 91.42, 90.66, 87.9, 85.69]
2022-11-28 21:23:34,225 [trainer.py] => NME top1 curve: [88.5, 75.85, 72.47, 66.72, 64.22, 60.88, 58.87]
2022-11-28 21:23:34,225 [trainer.py] => NME top5 curve: [99.4, 95.95, 93.8, 91.2, 89.16, 86.13, 84.11]

2022-11-28 21:23:34,225 [trainer.py] => All params: 468718
2022-11-28 21:23:34,225 [trainer.py] => Trainable params: 468718
2022-11-28 21:23:34,226 [bic.py] => Learning on 70-80
2022-11-28 21:23:34,277 [bic.py] => Stage1 dset: 6800, Stage2 dset: 160
2022-11-28 21:23:34,277 [bic.py] => Lambda: 0.875
2022-11-28 21:23:34,294 [bic.py] => Parameters of bias layer:
2022-11-28 21:23:34,295 [bic.py] => 0 => 1.000, 0.000
2022-11-28 21:23:34,295 [bic.py] => 1 => 0.976, -1.640
2022-11-28 21:23:34,295 [bic.py] => 2 => 0.847, -1.789
2022-11-28 21:23:34,295 [bic.py] => 3 => 0.728, -1.453
2022-11-28 21:23:34,295 [bic.py] => 4 => 0.739, -1.271
2022-11-28 21:23:34,295 [bic.py] => 5 => 0.788, -1.449
2022-11-28 21:23:34,295 [bic.py] => 6 => 0.727, -1.396
2022-11-28 21:23:34,295 [bic.py] => 7 => 1.000, 0.000
2022-11-28 21:23:43,784 [bic.py] => training => Task 7, Epoch 1/170 => Loss 2.833, Train_accy 66.600, Test_accy 37.440
2022-11-28 21:23:53,030 [bic.py] => training => Task 7, Epoch 2/170 => Loss 2.789, Train_accy 67.970, Test_accy 37.790
2022-11-28 21:24:01,952 [bic.py] => training => Task 7, Epoch 3/170 => Loss 2.795, Train_accy 68.850, Test_accy 36.590
2022-11-28 21:24:10,549 [bic.py] => training => Task 7, Epoch 4/170 => Loss 2.765, Train_accy 70.260, Test_accy 32.650
2022-11-28 21:24:19,046 [bic.py] => training => Task 7, Epoch 5/170 => Loss 2.775, Train_accy 73.470, Test_accy 38.260
2022-11-28 21:24:27,805 [bic.py] => training => Task 7, Epoch 6/170 => Loss 2.738, Train_accy 78.490, Test_accy 39.900
2022-11-28 21:24:36,255 [bic.py] => training => Task 7, Epoch 7/170 => Loss 2.731, Train_accy 76.340, Test_accy 40.540
2022-11-28 21:24:45,095 [bic.py] => training => Task 7, Epoch 8/170 => Loss 2.734, Train_accy 78.530, Test_accy 40.640
2022-11-28 21:24:54,301 [bic.py] => training => Task 7, Epoch 9/170 => Loss 2.716, Train_accy 78.190, Test_accy 40.060
2022-11-28 21:25:03,310 [bic.py] => training => Task 7, Epoch 10/170 => Loss 2.719, Train_accy 81.060, Test_accy 41.320
2022-11-28 21:25:12,399 [bic.py] => training => Task 7, Epoch 11/170 => Loss 2.720, Train_accy 81.210, Test_accy 41.310
2022-11-28 21:25:21,545 [bic.py] => training => Task 7, Epoch 12/170 => Loss 2.721, Train_accy 80.960, Test_accy 42.640
2022-11-28 21:25:30,467 [bic.py] => training => Task 7, Epoch 13/170 => Loss 2.728, Train_accy 77.900, Test_accy 40.610
2022-11-28 21:25:39,248 [bic.py] => training => Task 7, Epoch 14/170 => Loss 2.706, Train_accy 82.210, Test_accy 38.140
2022-11-28 21:25:48,083 [bic.py] => training => Task 7, Epoch 15/170 => Loss 2.718, Train_accy 81.870, Test_accy 43.720
2022-11-28 21:25:56,965 [bic.py] => training => Task 7, Epoch 16/170 => Loss 2.743, Train_accy 81.220, Test_accy 39.510
2022-11-28 21:26:05,654 [bic.py] => training => Task 7, Epoch 17/170 => Loss 2.718, Train_accy 79.910, Test_accy 40.170
2022-11-28 21:26:14,474 [bic.py] => training => Task 7, Epoch 18/170 => Loss 2.704, Train_accy 81.540, Test_accy 40.110
2022-11-28 21:26:23,626 [bic.py] => training => Task 7, Epoch 19/170 => Loss 2.727, Train_accy 82.530, Test_accy 40.410
2022-11-28 21:26:32,610 [bic.py] => training => Task 7, Epoch 20/170 => Loss 2.716, Train_accy 82.590, Test_accy 42.840
2022-11-28 21:26:41,270 [bic.py] => training => Task 7, Epoch 21/170 => Loss 2.703, Train_accy 83.620, Test_accy 43.740
2022-11-28 21:26:50,195 [bic.py] => training => Task 7, Epoch 22/170 => Loss 2.693, Train_accy 85.290, Test_accy 42.800
2022-11-28 21:26:59,310 [bic.py] => training => Task 7, Epoch 23/170 => Loss 2.710, Train_accy 79.820, Test_accy 39.660
2022-11-28 21:27:07,957 [bic.py] => training => Task 7, Epoch 24/170 => Loss 2.725, Train_accy 84.280, Test_accy 42.040
2022-11-28 21:27:16,446 [bic.py] => training => Task 7, Epoch 25/170 => Loss 2.704, Train_accy 86.410, Test_accy 43.450
2022-11-28 21:27:25,401 [bic.py] => training => Task 7, Epoch 26/170 => Loss 2.706, Train_accy 85.930, Test_accy 41.800
2022-11-28 21:27:34,534 [bic.py] => training => Task 7, Epoch 27/170 => Loss 2.703, Train_accy 81.130, Test_accy 39.020
2022-11-28 21:27:43,265 [bic.py] => training => Task 7, Epoch 28/170 => Loss 2.700, Train_accy 85.030, Test_accy 44.710
2022-11-28 21:27:52,082 [bic.py] => training => Task 7, Epoch 29/170 => Loss 2.697, Train_accy 86.150, Test_accy 44.460
2022-11-28 21:28:00,691 [bic.py] => training => Task 7, Epoch 30/170 => Loss 2.687, Train_accy 81.400, Test_accy 39.250
2022-11-28 21:28:09,637 [bic.py] => training => Task 7, Epoch 31/170 => Loss 2.723, Train_accy 84.810, Test_accy 43.060
2022-11-28 21:28:19,065 [bic.py] => training => Task 7, Epoch 32/170 => Loss 2.714, Train_accy 84.910, Test_accy 40.140
2022-11-28 21:28:28,200 [bic.py] => training => Task 7, Epoch 33/170 => Loss 2.690, Train_accy 80.940, Test_accy 37.760
2022-11-28 21:28:36,958 [bic.py] => training => Task 7, Epoch 34/170 => Loss 2.690, Train_accy 86.430, Test_accy 42.540
2022-11-28 21:28:45,852 [bic.py] => training => Task 7, Epoch 35/170 => Loss 2.696, Train_accy 84.130, Test_accy 40.800
2022-11-28 21:28:54,975 [bic.py] => training => Task 7, Epoch 36/170 => Loss 2.689, Train_accy 85.780, Test_accy 40.510
2022-11-28 21:29:03,357 [bic.py] => training => Task 7, Epoch 37/170 => Loss 2.701, Train_accy 83.650, Test_accy 36.780
2022-11-28 21:29:11,908 [bic.py] => training => Task 7, Epoch 38/170 => Loss 2.687, Train_accy 87.820, Test_accy 42.080
2022-11-28 21:29:20,557 [bic.py] => training => Task 7, Epoch 39/170 => Loss 2.678, Train_accy 88.620, Test_accy 42.040
2022-11-28 21:29:29,921 [bic.py] => training => Task 7, Epoch 40/170 => Loss 2.690, Train_accy 87.760, Test_accy 44.850
2022-11-28 21:29:38,524 [bic.py] => training => Task 7, Epoch 41/170 => Loss 2.682, Train_accy 86.250, Test_accy 44.000
2022-11-28 21:29:47,590 [bic.py] => training => Task 7, Epoch 42/170 => Loss 2.685, Train_accy 89.210, Test_accy 43.360
2022-11-28 21:29:56,544 [bic.py] => training => Task 7, Epoch 43/170 => Loss 2.688, Train_accy 82.810, Test_accy 38.170
2022-11-28 21:30:05,617 [bic.py] => training => Task 7, Epoch 44/170 => Loss 2.691, Train_accy 87.440, Test_accy 39.940
2022-11-28 21:30:14,546 [bic.py] => training => Task 7, Epoch 45/170 => Loss 2.683, Train_accy 85.510, Test_accy 39.450
2022-11-28 21:30:23,647 [bic.py] => training => Task 7, Epoch 46/170 => Loss 2.698, Train_accy 86.750, Test_accy 42.020
2022-11-28 21:30:32,857 [bic.py] => training => Task 7, Epoch 47/170 => Loss 2.692, Train_accy 88.320, Test_accy 41.560
2022-11-28 21:30:42,084 [bic.py] => training => Task 7, Epoch 48/170 => Loss 2.698, Train_accy 85.530, Test_accy 39.240
2022-11-28 21:30:50,921 [bic.py] => training => Task 7, Epoch 49/170 => Loss 2.703, Train_accy 86.930, Test_accy 41.390
2022-11-28 21:31:00,044 [bic.py] => training => Task 7, Epoch 50/170 => Loss 2.697, Train_accy 89.000, Test_accy 41.490
2022-11-28 21:31:08,870 [bic.py] => training => Task 7, Epoch 51/170 => Loss 2.696, Train_accy 86.320, Test_accy 43.180
2022-11-28 21:31:17,429 [bic.py] => training => Task 7, Epoch 52/170 => Loss 2.700, Train_accy 83.190, Test_accy 38.950
2022-11-28 21:31:26,086 [bic.py] => training => Task 7, Epoch 53/170 => Loss 2.699, Train_accy 88.680, Test_accy 42.100
2022-11-28 21:31:34,839 [bic.py] => training => Task 7, Epoch 54/170 => Loss 2.690, Train_accy 88.160, Test_accy 42.620
2022-11-28 21:31:43,979 [bic.py] => training => Task 7, Epoch 55/170 => Loss 2.698, Train_accy 87.510, Test_accy 42.650
2022-11-28 21:31:52,997 [bic.py] => training => Task 7, Epoch 56/170 => Loss 2.699, Train_accy 83.150, Test_accy 37.910
2022-11-28 21:32:02,140 [bic.py] => training => Task 7, Epoch 57/170 => Loss 2.681, Train_accy 90.260, Test_accy 41.420
2022-11-28 21:32:11,073 [bic.py] => training => Task 7, Epoch 58/170 => Loss 2.685, Train_accy 89.060, Test_accy 43.310
2022-11-28 21:32:19,596 [bic.py] => training => Task 7, Epoch 59/170 => Loss 2.680, Train_accy 91.160, Test_accy 43.810
2022-11-28 21:32:28,932 [bic.py] => training => Task 7, Epoch 60/170 => Loss 2.674, Train_accy 87.060, Test_accy 41.520
2022-11-28 21:32:37,694 [bic.py] => training => Task 7, Epoch 61/170 => Loss 2.649, Train_accy 96.070, Test_accy 46.780
2022-11-28 21:32:46,610 [bic.py] => training => Task 7, Epoch 62/170 => Loss 2.637, Train_accy 96.160, Test_accy 47.340
2022-11-28 21:32:55,989 [bic.py] => training => Task 7, Epoch 63/170 => Loss 2.633, Train_accy 96.530, Test_accy 46.820
2022-11-28 21:33:05,089 [bic.py] => training => Task 7, Epoch 64/170 => Loss 2.641, Train_accy 96.740, Test_accy 47.120
2022-11-28 21:33:13,912 [bic.py] => training => Task 7, Epoch 65/170 => Loss 2.626, Train_accy 96.310, Test_accy 46.310
2022-11-28 21:33:22,815 [bic.py] => training => Task 7, Epoch 66/170 => Loss 2.624, Train_accy 96.720, Test_accy 47.410
2022-11-28 21:33:31,587 [bic.py] => training => Task 7, Epoch 67/170 => Loss 2.626, Train_accy 96.780, Test_accy 47.310
2022-11-28 21:33:40,611 [bic.py] => training => Task 7, Epoch 68/170 => Loss 2.625, Train_accy 96.790, Test_accy 47.540
2022-11-28 21:33:49,140 [bic.py] => training => Task 7, Epoch 69/170 => Loss 2.618, Train_accy 96.870, Test_accy 47.210
2022-11-28 21:33:58,433 [bic.py] => training => Task 7, Epoch 70/170 => Loss 2.624, Train_accy 96.540, Test_accy 46.140
2022-11-28 21:34:07,165 [bic.py] => training => Task 7, Epoch 71/170 => Loss 2.622, Train_accy 96.970, Test_accy 47.510
2022-11-28 21:34:16,044 [bic.py] => training => Task 7, Epoch 72/170 => Loss 2.617, Train_accy 97.060, Test_accy 47.190
2022-11-28 21:34:24,745 [bic.py] => training => Task 7, Epoch 73/170 => Loss 2.619, Train_accy 97.150, Test_accy 47.290
2022-11-28 21:34:33,885 [bic.py] => training => Task 7, Epoch 74/170 => Loss 2.616, Train_accy 97.100, Test_accy 46.900
2022-11-28 21:34:43,035 [bic.py] => training => Task 7, Epoch 75/170 => Loss 2.615, Train_accy 97.130, Test_accy 47.140
2022-11-28 21:34:51,792 [bic.py] => training => Task 7, Epoch 76/170 => Loss 2.619, Train_accy 97.260, Test_accy 47.320
2022-11-28 21:35:00,606 [bic.py] => training => Task 7, Epoch 77/170 => Loss 2.615, Train_accy 97.460, Test_accy 47.420
2022-11-28 21:35:09,343 [bic.py] => training => Task 7, Epoch 78/170 => Loss 2.615, Train_accy 97.290, Test_accy 47.690
2022-11-28 21:35:18,042 [bic.py] => training => Task 7, Epoch 79/170 => Loss 2.626, Train_accy 97.780, Test_accy 47.950
2022-11-28 21:35:26,870 [bic.py] => training => Task 7, Epoch 80/170 => Loss 2.620, Train_accy 97.320, Test_accy 47.140
2022-11-28 21:35:35,897 [bic.py] => training => Task 7, Epoch 81/170 => Loss 2.618, Train_accy 97.120, Test_accy 46.850
2022-11-28 21:35:44,994 [bic.py] => training => Task 7, Epoch 82/170 => Loss 2.619, Train_accy 97.430, Test_accy 47.990
2022-11-28 21:35:54,482 [bic.py] => training => Task 7, Epoch 83/170 => Loss 2.615, Train_accy 97.440, Test_accy 47.690
2022-11-28 21:36:03,565 [bic.py] => training => Task 7, Epoch 84/170 => Loss 2.612, Train_accy 97.690, Test_accy 46.820
2022-11-28 21:36:12,277 [bic.py] => training => Task 7, Epoch 85/170 => Loss 2.614, Train_accy 97.460, Test_accy 47.840
2022-11-28 21:36:20,925 [bic.py] => training => Task 7, Epoch 86/170 => Loss 2.611, Train_accy 97.590, Test_accy 47.740
2022-11-28 21:36:30,153 [bic.py] => training => Task 7, Epoch 87/170 => Loss 2.618, Train_accy 97.530, Test_accy 48.120
2022-11-28 21:36:39,251 [bic.py] => training => Task 7, Epoch 88/170 => Loss 2.604, Train_accy 97.650, Test_accy 47.390
2022-11-28 21:36:48,097 [bic.py] => training => Task 7, Epoch 89/170 => Loss 2.617, Train_accy 97.540, Test_accy 48.120
2022-11-28 21:36:57,230 [bic.py] => training => Task 7, Epoch 90/170 => Loss 2.618, Train_accy 97.690, Test_accy 46.920
2022-11-28 21:37:06,033 [bic.py] => training => Task 7, Epoch 91/170 => Loss 2.621, Train_accy 97.630, Test_accy 47.150
2022-11-28 21:37:14,859 [bic.py] => training => Task 7, Epoch 92/170 => Loss 2.617, Train_accy 97.720, Test_accy 48.290
2022-11-28 21:37:24,295 [bic.py] => training => Task 7, Epoch 93/170 => Loss 2.619, Train_accy 97.720, Test_accy 47.690
2022-11-28 21:37:33,146 [bic.py] => training => Task 7, Epoch 94/170 => Loss 2.615, Train_accy 97.630, Test_accy 48.120
2022-11-28 21:37:41,689 [bic.py] => training => Task 7, Epoch 95/170 => Loss 2.611, Train_accy 97.650, Test_accy 47.760
2022-11-28 21:37:50,669 [bic.py] => training => Task 7, Epoch 96/170 => Loss 2.608, Train_accy 97.430, Test_accy 46.600
2022-11-28 21:38:00,142 [bic.py] => training => Task 7, Epoch 97/170 => Loss 2.611, Train_accy 97.690, Test_accy 47.480
2022-11-28 21:38:09,080 [bic.py] => training => Task 7, Epoch 98/170 => Loss 2.619, Train_accy 97.690, Test_accy 47.920
2022-11-28 21:38:17,717 [bic.py] => training => Task 7, Epoch 99/170 => Loss 2.608, Train_accy 97.380, Test_accy 46.780
2022-11-28 21:38:26,700 [bic.py] => training => Task 7, Epoch 100/170 => Loss 2.614, Train_accy 97.590, Test_accy 46.990
2022-11-28 21:38:35,449 [bic.py] => training => Task 7, Epoch 101/170 => Loss 2.606, Train_accy 98.090, Test_accy 47.080
2022-11-28 21:38:44,252 [bic.py] => training => Task 7, Epoch 102/170 => Loss 2.616, Train_accy 97.910, Test_accy 47.560
2022-11-28 21:38:53,139 [bic.py] => training => Task 7, Epoch 103/170 => Loss 2.610, Train_accy 98.240, Test_accy 47.510
2022-11-28 21:39:01,841 [bic.py] => training => Task 7, Epoch 104/170 => Loss 2.615, Train_accy 98.150, Test_accy 47.390
2022-11-28 21:39:10,580 [bic.py] => training => Task 7, Epoch 105/170 => Loss 2.611, Train_accy 98.240, Test_accy 47.990
2022-11-28 21:39:19,659 [bic.py] => training => Task 7, Epoch 106/170 => Loss 2.607, Train_accy 98.190, Test_accy 47.290
2022-11-28 21:39:28,449 [bic.py] => training => Task 7, Epoch 107/170 => Loss 2.603, Train_accy 97.790, Test_accy 46.880
2022-11-28 21:39:37,403 [bic.py] => training => Task 7, Epoch 108/170 => Loss 2.610, Train_accy 97.970, Test_accy 47.820
2022-11-28 21:39:46,672 [bic.py] => training => Task 7, Epoch 109/170 => Loss 2.611, Train_accy 97.960, Test_accy 47.510
2022-11-28 21:39:55,654 [bic.py] => training => Task 7, Epoch 110/170 => Loss 2.612, Train_accy 97.910, Test_accy 47.690
2022-11-28 21:40:04,658 [bic.py] => training => Task 7, Epoch 111/170 => Loss 2.606, Train_accy 98.070, Test_accy 46.950
2022-11-28 21:40:13,930 [bic.py] => training => Task 7, Epoch 112/170 => Loss 2.610, Train_accy 98.180, Test_accy 47.340
2022-11-28 21:40:22,626 [bic.py] => training => Task 7, Epoch 113/170 => Loss 2.611, Train_accy 98.010, Test_accy 47.380
2022-11-28 21:40:31,476 [bic.py] => training => Task 7, Epoch 114/170 => Loss 2.606, Train_accy 97.960, Test_accy 47.860
2022-11-28 21:40:40,440 [bic.py] => training => Task 7, Epoch 115/170 => Loss 2.609, Train_accy 98.040, Test_accy 47.710
2022-11-28 21:40:49,228 [bic.py] => training => Task 7, Epoch 116/170 => Loss 2.606, Train_accy 97.850, Test_accy 47.760
2022-11-28 21:40:58,080 [bic.py] => training => Task 7, Epoch 117/170 => Loss 2.610, Train_accy 98.030, Test_accy 47.800
2022-11-28 21:41:06,500 [bic.py] => training => Task 7, Epoch 118/170 => Loss 2.611, Train_accy 98.030, Test_accy 47.340
2022-11-28 21:41:15,312 [bic.py] => training => Task 7, Epoch 119/170 => Loss 2.613, Train_accy 98.150, Test_accy 47.710
2022-11-28 21:41:24,670 [bic.py] => training => Task 7, Epoch 120/170 => Loss 2.602, Train_accy 97.710, Test_accy 47.580
2022-11-28 21:41:33,501 [bic.py] => training => Task 7, Epoch 121/170 => Loss 2.607, Train_accy 97.790, Test_accy 47.780
2022-11-28 21:41:42,447 [bic.py] => training => Task 7, Epoch 122/170 => Loss 2.609, Train_accy 98.120, Test_accy 48.160
2022-11-28 21:41:51,455 [bic.py] => training => Task 7, Epoch 123/170 => Loss 2.611, Train_accy 98.130, Test_accy 47.850
2022-11-28 21:42:00,557 [bic.py] => training => Task 7, Epoch 124/170 => Loss 2.608, Train_accy 98.280, Test_accy 47.990
2022-11-28 21:42:09,474 [bic.py] => training => Task 7, Epoch 125/170 => Loss 2.616, Train_accy 98.180, Test_accy 48.120
2022-11-28 21:42:18,317 [bic.py] => training => Task 7, Epoch 126/170 => Loss 2.613, Train_accy 98.040, Test_accy 48.200
2022-11-28 21:42:27,153 [bic.py] => training => Task 7, Epoch 127/170 => Loss 2.613, Train_accy 98.370, Test_accy 47.940
2022-11-28 21:42:35,972 [bic.py] => training => Task 7, Epoch 128/170 => Loss 2.609, Train_accy 98.240, Test_accy 47.780
2022-11-28 21:42:44,710 [bic.py] => training => Task 7, Epoch 129/170 => Loss 2.606, Train_accy 98.160, Test_accy 48.000
2022-11-28 21:42:53,941 [bic.py] => training => Task 7, Epoch 130/170 => Loss 2.605, Train_accy 98.090, Test_accy 47.680
2022-11-28 21:43:02,788 [bic.py] => training => Task 7, Epoch 131/170 => Loss 2.606, Train_accy 98.070, Test_accy 47.610
2022-11-28 21:43:11,480 [bic.py] => training => Task 7, Epoch 132/170 => Loss 2.607, Train_accy 98.190, Test_accy 47.280
2022-11-28 21:43:20,188 [bic.py] => training => Task 7, Epoch 133/170 => Loss 2.615, Train_accy 98.440, Test_accy 48.740
2022-11-28 21:43:29,194 [bic.py] => training => Task 7, Epoch 134/170 => Loss 2.604, Train_accy 98.060, Test_accy 47.680
2022-11-28 21:43:37,952 [bic.py] => training => Task 7, Epoch 135/170 => Loss 2.611, Train_accy 97.970, Test_accy 47.410
2022-11-28 21:43:46,633 [bic.py] => training => Task 7, Epoch 136/170 => Loss 2.616, Train_accy 98.010, Test_accy 47.020
2022-11-28 21:43:55,866 [bic.py] => training => Task 7, Epoch 137/170 => Loss 2.606, Train_accy 98.260, Test_accy 47.760
2022-11-28 21:44:04,925 [bic.py] => training => Task 7, Epoch 138/170 => Loss 2.615, Train_accy 98.280, Test_accy 47.340
2022-11-28 21:44:13,512 [bic.py] => training => Task 7, Epoch 139/170 => Loss 2.609, Train_accy 98.120, Test_accy 48.090
2022-11-28 21:44:22,489 [bic.py] => training => Task 7, Epoch 140/170 => Loss 2.608, Train_accy 98.000, Test_accy 48.150
2022-11-28 21:44:31,349 [bic.py] => training => Task 7, Epoch 141/170 => Loss 2.606, Train_accy 98.120, Test_accy 47.850
2022-11-28 21:44:40,410 [bic.py] => training => Task 7, Epoch 142/170 => Loss 2.604, Train_accy 98.130, Test_accy 47.020
2022-11-28 21:44:49,380 [bic.py] => training => Task 7, Epoch 143/170 => Loss 2.609, Train_accy 97.940, Test_accy 47.220
2022-11-28 21:44:58,445 [bic.py] => training => Task 7, Epoch 144/170 => Loss 2.605, Train_accy 98.030, Test_accy 47.940
2022-11-28 21:45:07,096 [bic.py] => training => Task 7, Epoch 145/170 => Loss 2.602, Train_accy 98.090, Test_accy 48.040
2022-11-28 21:45:16,112 [bic.py] => training => Task 7, Epoch 146/170 => Loss 2.607, Train_accy 98.090, Test_accy 48.110
2022-11-28 21:45:25,242 [bic.py] => training => Task 7, Epoch 147/170 => Loss 2.603, Train_accy 97.790, Test_accy 46.580
2022-11-28 21:45:34,120 [bic.py] => training => Task 7, Epoch 148/170 => Loss 2.610, Train_accy 97.910, Test_accy 47.880
2022-11-28 21:45:43,176 [bic.py] => training => Task 7, Epoch 149/170 => Loss 2.603, Train_accy 98.060, Test_accy 47.290
2022-11-28 21:45:52,439 [bic.py] => training => Task 7, Epoch 150/170 => Loss 2.609, Train_accy 98.030, Test_accy 46.920
2022-11-28 21:46:01,756 [bic.py] => training => Task 7, Epoch 151/170 => Loss 2.605, Train_accy 98.150, Test_accy 46.980
2022-11-28 21:46:10,547 [bic.py] => training => Task 7, Epoch 152/170 => Loss 2.598, Train_accy 97.970, Test_accy 47.700
2022-11-28 21:46:19,317 [bic.py] => training => Task 7, Epoch 153/170 => Loss 2.609, Train_accy 98.240, Test_accy 47.420
2022-11-28 21:46:28,462 [bic.py] => training => Task 7, Epoch 154/170 => Loss 2.609, Train_accy 98.190, Test_accy 47.790
2022-11-28 21:46:36,734 [bic.py] => training => Task 7, Epoch 155/170 => Loss 2.605, Train_accy 98.150, Test_accy 47.800
2022-11-28 21:46:45,470 [bic.py] => training => Task 7, Epoch 156/170 => Loss 2.603, Train_accy 98.090, Test_accy 47.690
2022-11-28 21:46:54,505 [bic.py] => training => Task 7, Epoch 157/170 => Loss 2.610, Train_accy 98.070, Test_accy 47.410
2022-11-28 21:47:03,508 [bic.py] => training => Task 7, Epoch 158/170 => Loss 2.610, Train_accy 97.960, Test_accy 47.280
2022-11-28 21:47:12,122 [bic.py] => training => Task 7, Epoch 159/170 => Loss 2.607, Train_accy 98.350, Test_accy 47.390
2022-11-28 21:47:20,604 [bic.py] => training => Task 7, Epoch 160/170 => Loss 2.605, Train_accy 98.160, Test_accy 48.080
2022-11-28 21:47:29,533 [bic.py] => training => Task 7, Epoch 161/170 => Loss 2.610, Train_accy 98.130, Test_accy 47.980
2022-11-28 21:47:38,732 [bic.py] => training => Task 7, Epoch 162/170 => Loss 2.610, Train_accy 98.190, Test_accy 46.940
2022-11-28 21:47:47,480 [bic.py] => training => Task 7, Epoch 163/170 => Loss 2.605, Train_accy 98.060, Test_accy 47.340
2022-11-28 21:47:56,356 [bic.py] => training => Task 7, Epoch 164/170 => Loss 2.605, Train_accy 97.820, Test_accy 47.460
2022-11-28 21:48:04,779 [bic.py] => training => Task 7, Epoch 165/170 => Loss 2.614, Train_accy 98.040, Test_accy 47.780
2022-11-28 21:48:13,672 [bic.py] => training => Task 7, Epoch 166/170 => Loss 2.606, Train_accy 98.100, Test_accy 47.740
2022-11-28 21:48:22,702 [bic.py] => training => Task 7, Epoch 167/170 => Loss 2.608, Train_accy 98.220, Test_accy 47.680
2022-11-28 21:48:31,482 [bic.py] => training => Task 7, Epoch 168/170 => Loss 2.605, Train_accy 97.930, Test_accy 48.300
2022-11-28 21:48:40,595 [bic.py] => training => Task 7, Epoch 169/170 => Loss 2.613, Train_accy 98.340, Test_accy 47.320
2022-11-28 21:48:49,443 [bic.py] => training => Task 7, Epoch 170/170 => Loss 2.608, Train_accy 98.190, Test_accy 47.880
2022-11-28 21:48:53,732 [bic.py] => bias_correction => Task 7, Epoch 1/170 => Loss 4.004, Train_accy 66.250, Test_accy 50.800
2022-11-28 21:48:57,810 [bic.py] => bias_correction => Task 7, Epoch 2/170 => Loss 3.935, Train_accy 76.250, Test_accy 55.320
2022-11-28 21:49:01,826 [bic.py] => bias_correction => Task 7, Epoch 3/170 => Loss 3.845, Train_accy 81.250, Test_accy 54.460
2022-11-28 21:49:05,889 [bic.py] => bias_correction => Task 7, Epoch 4/170 => Loss 3.880, Train_accy 74.380, Test_accy 51.600
2022-11-28 21:49:10,344 [bic.py] => bias_correction => Task 7, Epoch 5/170 => Loss 3.875, Train_accy 75.000, Test_accy 51.100
2022-11-28 21:49:14,719 [bic.py] => bias_correction => Task 7, Epoch 6/170 => Loss 3.894, Train_accy 73.750, Test_accy 51.050
2022-11-28 21:49:18,693 [bic.py] => bias_correction => Task 7, Epoch 7/170 => Loss 3.870, Train_accy 76.250, Test_accy 50.610
2022-11-28 21:49:22,728 [bic.py] => bias_correction => Task 7, Epoch 8/170 => Loss 3.856, Train_accy 75.000, Test_accy 50.500
2022-11-28 21:49:26,743 [bic.py] => bias_correction => Task 7, Epoch 9/170 => Loss 3.870, Train_accy 73.750, Test_accy 50.740
2022-11-28 21:49:30,664 [bic.py] => bias_correction => Task 7, Epoch 10/170 => Loss 3.878, Train_accy 72.500, Test_accy 50.650
2022-11-28 21:49:34,592 [bic.py] => bias_correction => Task 7, Epoch 11/170 => Loss 3.853, Train_accy 76.250, Test_accy 50.690
2022-11-28 21:49:38,404 [bic.py] => bias_correction => Task 7, Epoch 12/170 => Loss 3.884, Train_accy 76.250, Test_accy 50.720
2022-11-28 21:49:42,181 [bic.py] => bias_correction => Task 7, Epoch 13/170 => Loss 3.858, Train_accy 72.500, Test_accy 50.750
2022-11-28 21:49:46,092 [bic.py] => bias_correction => Task 7, Epoch 14/170 => Loss 3.855, Train_accy 73.120, Test_accy 50.840
2022-11-28 21:49:50,269 [bic.py] => bias_correction => Task 7, Epoch 15/170 => Loss 3.855, Train_accy 75.620, Test_accy 50.950
2022-11-28 21:49:54,434 [bic.py] => bias_correction => Task 7, Epoch 16/170 => Loss 3.839, Train_accy 75.620, Test_accy 51.020
2022-11-28 21:49:58,571 [bic.py] => bias_correction => Task 7, Epoch 17/170 => Loss 3.894, Train_accy 76.250, Test_accy 50.850
2022-11-28 21:50:02,755 [bic.py] => bias_correction => Task 7, Epoch 18/170 => Loss 3.874, Train_accy 75.620, Test_accy 50.740
2022-11-28 21:50:06,734 [bic.py] => bias_correction => Task 7, Epoch 19/170 => Loss 3.871, Train_accy 74.380, Test_accy 50.660
2022-11-28 21:50:10,693 [bic.py] => bias_correction => Task 7, Epoch 20/170 => Loss 3.908, Train_accy 70.000, Test_accy 50.600
2022-11-28 21:50:14,706 [bic.py] => bias_correction => Task 7, Epoch 21/170 => Loss 3.828, Train_accy 72.500, Test_accy 50.650
2022-11-28 21:50:18,627 [bic.py] => bias_correction => Task 7, Epoch 22/170 => Loss 3.902, Train_accy 74.380, Test_accy 50.640
2022-11-28 21:50:22,838 [bic.py] => bias_correction => Task 7, Epoch 23/170 => Loss 3.876, Train_accy 76.250, Test_accy 50.420
2022-11-28 21:50:26,880 [bic.py] => bias_correction => Task 7, Epoch 24/170 => Loss 3.875, Train_accy 75.000, Test_accy 50.410
2022-11-28 21:50:30,900 [bic.py] => bias_correction => Task 7, Epoch 25/170 => Loss 3.864, Train_accy 73.750, Test_accy 50.500
2022-11-28 21:50:35,003 [bic.py] => bias_correction => Task 7, Epoch 26/170 => Loss 3.884, Train_accy 70.620, Test_accy 50.260
2022-11-28 21:50:38,964 [bic.py] => bias_correction => Task 7, Epoch 27/170 => Loss 3.866, Train_accy 71.880, Test_accy 50.040
2022-11-28 21:50:43,191 [bic.py] => bias_correction => Task 7, Epoch 28/170 => Loss 3.832, Train_accy 73.120, Test_accy 50.310
2022-11-28 21:50:47,187 [bic.py] => bias_correction => Task 7, Epoch 29/170 => Loss 3.835, Train_accy 75.000, Test_accy 50.550
2022-11-28 21:50:51,375 [bic.py] => bias_correction => Task 7, Epoch 30/170 => Loss 3.863, Train_accy 73.750, Test_accy 50.740
2022-11-28 21:50:55,540 [bic.py] => bias_correction => Task 7, Epoch 31/170 => Loss 3.880, Train_accy 73.750, Test_accy 50.520
2022-11-28 21:50:59,980 [bic.py] => bias_correction => Task 7, Epoch 32/170 => Loss 3.889, Train_accy 74.380, Test_accy 50.610
2022-11-28 21:51:04,069 [bic.py] => bias_correction => Task 7, Epoch 33/170 => Loss 3.856, Train_accy 75.000, Test_accy 50.640
2022-11-28 21:51:08,128 [bic.py] => bias_correction => Task 7, Epoch 34/170 => Loss 3.846, Train_accy 73.120, Test_accy 50.390
2022-11-28 21:51:12,226 [bic.py] => bias_correction => Task 7, Epoch 35/170 => Loss 3.835, Train_accy 73.120, Test_accy 50.390
2022-11-28 21:51:16,339 [bic.py] => bias_correction => Task 7, Epoch 36/170 => Loss 3.891, Train_accy 73.750, Test_accy 50.440
2022-11-28 21:51:20,264 [bic.py] => bias_correction => Task 7, Epoch 37/170 => Loss 3.833, Train_accy 74.380, Test_accy 50.490
2022-11-28 21:51:24,617 [bic.py] => bias_correction => Task 7, Epoch 38/170 => Loss 3.833, Train_accy 71.880, Test_accy 50.450
2022-11-28 21:51:28,756 [bic.py] => bias_correction => Task 7, Epoch 39/170 => Loss 3.851, Train_accy 75.620, Test_accy 50.380
2022-11-28 21:51:32,819 [bic.py] => bias_correction => Task 7, Epoch 40/170 => Loss 3.874, Train_accy 71.250, Test_accy 50.440
2022-11-28 21:51:36,673 [bic.py] => bias_correction => Task 7, Epoch 41/170 => Loss 3.855, Train_accy 73.750, Test_accy 50.260
2022-11-28 21:51:40,744 [bic.py] => bias_correction => Task 7, Epoch 42/170 => Loss 3.912, Train_accy 73.120, Test_accy 50.500
2022-11-28 21:51:44,820 [bic.py] => bias_correction => Task 7, Epoch 43/170 => Loss 3.858, Train_accy 71.880, Test_accy 50.210
2022-11-28 21:51:48,773 [bic.py] => bias_correction => Task 7, Epoch 44/170 => Loss 3.843, Train_accy 75.620, Test_accy 50.150
2022-11-28 21:51:52,649 [bic.py] => bias_correction => Task 7, Epoch 45/170 => Loss 3.887, Train_accy 71.250, Test_accy 50.420
2022-11-28 21:51:56,756 [bic.py] => bias_correction => Task 7, Epoch 46/170 => Loss 3.855, Train_accy 76.250, Test_accy 50.340
2022-11-28 21:52:00,898 [bic.py] => bias_correction => Task 7, Epoch 47/170 => Loss 3.866, Train_accy 70.000, Test_accy 50.180
2022-11-28 21:52:05,281 [bic.py] => bias_correction => Task 7, Epoch 48/170 => Loss 3.900, Train_accy 71.250, Test_accy 50.020
2022-11-28 21:52:09,258 [bic.py] => bias_correction => Task 7, Epoch 49/170 => Loss 3.847, Train_accy 72.500, Test_accy 49.980
2022-11-28 21:52:13,108 [bic.py] => bias_correction => Task 7, Epoch 50/170 => Loss 3.861, Train_accy 72.500, Test_accy 49.980
2022-11-28 21:52:17,133 [bic.py] => bias_correction => Task 7, Epoch 51/170 => Loss 3.813, Train_accy 71.880, Test_accy 50.050
2022-11-28 21:52:21,044 [bic.py] => bias_correction => Task 7, Epoch 52/170 => Loss 3.896, Train_accy 74.380, Test_accy 50.100
2022-11-28 21:52:25,151 [bic.py] => bias_correction => Task 7, Epoch 53/170 => Loss 3.918, Train_accy 72.500, Test_accy 50.100
2022-11-28 21:52:29,244 [bic.py] => bias_correction => Task 7, Epoch 54/170 => Loss 3.893, Train_accy 73.750, Test_accy 50.200
2022-11-28 21:52:33,267 [bic.py] => bias_correction => Task 7, Epoch 55/170 => Loss 3.858, Train_accy 73.120, Test_accy 50.490
2022-11-28 21:52:37,744 [bic.py] => bias_correction => Task 7, Epoch 56/170 => Loss 3.880, Train_accy 73.120, Test_accy 50.400
2022-11-28 21:52:41,729 [bic.py] => bias_correction => Task 7, Epoch 57/170 => Loss 3.896, Train_accy 74.380, Test_accy 50.310
2022-11-28 21:52:45,759 [bic.py] => bias_correction => Task 7, Epoch 58/170 => Loss 3.869, Train_accy 75.000, Test_accy 50.220
2022-11-28 21:52:49,687 [bic.py] => bias_correction => Task 7, Epoch 59/170 => Loss 3.847, Train_accy 75.000, Test_accy 50.000
2022-11-28 21:52:54,098 [bic.py] => bias_correction => Task 7, Epoch 60/170 => Loss 3.892, Train_accy 75.000, Test_accy 50.180
2022-11-28 21:52:58,214 [bic.py] => bias_correction => Task 7, Epoch 61/170 => Loss 3.895, Train_accy 74.380, Test_accy 50.400
2022-11-28 21:53:02,393 [bic.py] => bias_correction => Task 7, Epoch 62/170 => Loss 3.884, Train_accy 72.500, Test_accy 50.520
2022-11-28 21:53:06,368 [bic.py] => bias_correction => Task 7, Epoch 63/170 => Loss 3.865, Train_accy 75.000, Test_accy 50.860
2022-11-28 21:53:10,308 [bic.py] => bias_correction => Task 7, Epoch 64/170 => Loss 3.865, Train_accy 73.750, Test_accy 50.840
2022-11-28 21:53:14,524 [bic.py] => bias_correction => Task 7, Epoch 65/170 => Loss 3.876, Train_accy 74.380, Test_accy 50.650
2022-11-28 21:53:18,451 [bic.py] => bias_correction => Task 7, Epoch 66/170 => Loss 3.888, Train_accy 74.380, Test_accy 50.780
2022-11-28 21:53:22,410 [bic.py] => bias_correction => Task 7, Epoch 67/170 => Loss 3.877, Train_accy 76.250, Test_accy 51.050
2022-11-28 21:53:26,380 [bic.py] => bias_correction => Task 7, Epoch 68/170 => Loss 3.818, Train_accy 75.000, Test_accy 50.700
2022-11-28 21:53:30,229 [bic.py] => bias_correction => Task 7, Epoch 69/170 => Loss 3.869, Train_accy 75.000, Test_accy 50.600
2022-11-28 21:53:34,191 [bic.py] => bias_correction => Task 7, Epoch 70/170 => Loss 3.858, Train_accy 74.380, Test_accy 50.540
2022-11-28 21:53:38,134 [bic.py] => bias_correction => Task 7, Epoch 71/170 => Loss 3.909, Train_accy 71.880, Test_accy 50.290
2022-11-28 21:53:42,284 [bic.py] => bias_correction => Task 7, Epoch 72/170 => Loss 3.885, Train_accy 75.000, Test_accy 50.690
2022-11-28 21:53:46,225 [bic.py] => bias_correction => Task 7, Epoch 73/170 => Loss 3.859, Train_accy 75.620, Test_accy 50.510
2022-11-28 21:53:50,194 [bic.py] => bias_correction => Task 7, Epoch 74/170 => Loss 3.841, Train_accy 75.620, Test_accy 50.360
2022-11-28 21:53:54,538 [bic.py] => bias_correction => Task 7, Epoch 75/170 => Loss 3.884, Train_accy 73.120, Test_accy 50.580
2022-11-28 21:53:58,434 [bic.py] => bias_correction => Task 7, Epoch 76/170 => Loss 3.863, Train_accy 73.750, Test_accy 50.650
2022-11-28 21:54:02,510 [bic.py] => bias_correction => Task 7, Epoch 77/170 => Loss 3.886, Train_accy 73.750, Test_accy 50.400
2022-11-28 21:54:06,444 [bic.py] => bias_correction => Task 7, Epoch 78/170 => Loss 3.874, Train_accy 76.880, Test_accy 50.260
2022-11-28 21:54:10,705 [bic.py] => bias_correction => Task 7, Epoch 79/170 => Loss 3.867, Train_accy 73.750, Test_accy 50.300
2022-11-28 21:54:14,732 [bic.py] => bias_correction => Task 7, Epoch 80/170 => Loss 3.855, Train_accy 75.000, Test_accy 50.220
2022-11-28 21:54:18,984 [bic.py] => bias_correction => Task 7, Epoch 81/170 => Loss 3.832, Train_accy 74.380, Test_accy 50.210
2022-11-28 21:54:23,509 [bic.py] => bias_correction => Task 7, Epoch 82/170 => Loss 3.830, Train_accy 74.380, Test_accy 50.350
2022-11-28 21:54:27,465 [bic.py] => bias_correction => Task 7, Epoch 83/170 => Loss 3.878, Train_accy 72.500, Test_accy 50.390
2022-11-28 21:54:31,377 [bic.py] => bias_correction => Task 7, Epoch 84/170 => Loss 3.898, Train_accy 73.120, Test_accy 50.260
2022-11-28 21:54:35,250 [bic.py] => bias_correction => Task 7, Epoch 85/170 => Loss 3.878, Train_accy 73.750, Test_accy 50.340
2022-11-28 21:54:39,136 [bic.py] => bias_correction => Task 7, Epoch 86/170 => Loss 3.889, Train_accy 77.500, Test_accy 50.110
2022-11-28 21:54:43,229 [bic.py] => bias_correction => Task 7, Epoch 87/170 => Loss 3.904, Train_accy 71.880, Test_accy 50.190
2022-11-28 21:54:47,314 [bic.py] => bias_correction => Task 7, Epoch 88/170 => Loss 3.856, Train_accy 73.750, Test_accy 50.260
2022-11-28 21:54:51,283 [bic.py] => bias_correction => Task 7, Epoch 89/170 => Loss 3.879, Train_accy 71.880, Test_accy 50.280
2022-11-28 21:54:55,421 [bic.py] => bias_correction => Task 7, Epoch 90/170 => Loss 3.875, Train_accy 73.120, Test_accy 50.240
2022-11-28 21:54:59,854 [bic.py] => bias_correction => Task 7, Epoch 91/170 => Loss 3.862, Train_accy 73.750, Test_accy 50.480
2022-11-28 21:55:03,934 [bic.py] => bias_correction => Task 7, Epoch 92/170 => Loss 3.906, Train_accy 73.750, Test_accy 50.180
2022-11-28 21:55:07,916 [bic.py] => bias_correction => Task 7, Epoch 93/170 => Loss 3.856, Train_accy 73.750, Test_accy 50.150
2022-11-28 21:55:11,828 [bic.py] => bias_correction => Task 7, Epoch 94/170 => Loss 3.864, Train_accy 73.750, Test_accy 50.210
2022-11-28 21:55:15,671 [bic.py] => bias_correction => Task 7, Epoch 95/170 => Loss 3.867, Train_accy 72.500, Test_accy 50.240
2022-11-28 21:55:19,777 [bic.py] => bias_correction => Task 7, Epoch 96/170 => Loss 3.857, Train_accy 71.250, Test_accy 50.180
2022-11-28 21:55:24,424 [bic.py] => bias_correction => Task 7, Epoch 97/170 => Loss 3.886, Train_accy 71.250, Test_accy 49.940
2022-11-28 21:55:28,576 [bic.py] => bias_correction => Task 7, Epoch 98/170 => Loss 3.878, Train_accy 75.620, Test_accy 49.660
2022-11-28 21:55:32,557 [bic.py] => bias_correction => Task 7, Epoch 99/170 => Loss 3.885, Train_accy 73.750, Test_accy 49.850
2022-11-28 21:55:36,595 [bic.py] => bias_correction => Task 7, Epoch 100/170 => Loss 3.917, Train_accy 73.750, Test_accy 50.080
2022-11-28 21:55:40,610 [bic.py] => bias_correction => Task 7, Epoch 101/170 => Loss 3.874, Train_accy 73.750, Test_accy 50.310
2022-11-28 21:55:44,656 [bic.py] => bias_correction => Task 7, Epoch 102/170 => Loss 3.881, Train_accy 73.750, Test_accy 50.260
2022-11-28 21:55:48,840 [bic.py] => bias_correction => Task 7, Epoch 103/170 => Loss 3.888, Train_accy 73.750, Test_accy 50.110
2022-11-28 21:55:53,056 [bic.py] => bias_correction => Task 7, Epoch 104/170 => Loss 3.864, Train_accy 71.880, Test_accy 49.950
2022-11-28 21:55:57,065 [bic.py] => bias_correction => Task 7, Epoch 105/170 => Loss 3.804, Train_accy 71.880, Test_accy 50.200
2022-11-28 21:56:00,982 [bic.py] => bias_correction => Task 7, Epoch 106/170 => Loss 3.896, Train_accy 75.000, Test_accy 50.580
2022-11-28 21:56:05,011 [bic.py] => bias_correction => Task 7, Epoch 107/170 => Loss 3.851, Train_accy 73.120, Test_accy 50.410
2022-11-28 21:56:08,965 [bic.py] => bias_correction => Task 7, Epoch 108/170 => Loss 3.840, Train_accy 73.120, Test_accy 50.790
2022-11-28 21:56:12,924 [bic.py] => bias_correction => Task 7, Epoch 109/170 => Loss 3.893, Train_accy 72.500, Test_accy 50.660
2022-11-28 21:56:17,033 [bic.py] => bias_correction => Task 7, Epoch 110/170 => Loss 3.809, Train_accy 73.750, Test_accy 50.540
2022-11-28 21:56:21,348 [bic.py] => bias_correction => Task 7, Epoch 111/170 => Loss 3.871, Train_accy 72.500, Test_accy 50.580
2022-11-28 21:56:25,622 [bic.py] => bias_correction => Task 7, Epoch 112/170 => Loss 3.886, Train_accy 73.750, Test_accy 50.240
2022-11-28 21:56:29,743 [bic.py] => bias_correction => Task 7, Epoch 113/170 => Loss 3.858, Train_accy 76.250, Test_accy 50.240
2022-11-28 21:56:33,607 [bic.py] => bias_correction => Task 7, Epoch 114/170 => Loss 3.878, Train_accy 74.380, Test_accy 50.290
2022-11-28 21:56:37,828 [bic.py] => bias_correction => Task 7, Epoch 115/170 => Loss 3.886, Train_accy 76.880, Test_accy 50.250
2022-11-28 21:56:41,760 [bic.py] => bias_correction => Task 7, Epoch 116/170 => Loss 3.872, Train_accy 70.620, Test_accy 50.320
2022-11-28 21:56:45,912 [bic.py] => bias_correction => Task 7, Epoch 117/170 => Loss 3.860, Train_accy 71.250, Test_accy 50.490
2022-11-28 21:56:49,978 [bic.py] => bias_correction => Task 7, Epoch 118/170 => Loss 3.849, Train_accy 71.250, Test_accy 50.280
2022-11-28 21:56:54,391 [bic.py] => bias_correction => Task 7, Epoch 119/170 => Loss 3.877, Train_accy 75.000, Test_accy 49.900
2022-11-28 21:56:58,607 [bic.py] => bias_correction => Task 7, Epoch 120/170 => Loss 3.859, Train_accy 75.000, Test_accy 50.120
2022-11-28 21:57:02,493 [bic.py] => bias_correction => Task 7, Epoch 121/170 => Loss 3.886, Train_accy 74.380, Test_accy 50.440
2022-11-28 21:57:06,711 [bic.py] => bias_correction => Task 7, Epoch 122/170 => Loss 3.891, Train_accy 72.500, Test_accy 50.450
2022-11-28 21:57:10,900 [bic.py] => bias_correction => Task 7, Epoch 123/170 => Loss 3.863, Train_accy 75.000, Test_accy 50.690
2022-11-28 21:57:14,789 [bic.py] => bias_correction => Task 7, Epoch 124/170 => Loss 3.880, Train_accy 77.500, Test_accy 50.780
2022-11-28 21:57:18,937 [bic.py] => bias_correction => Task 7, Epoch 125/170 => Loss 3.845, Train_accy 74.380, Test_accy 50.740
2022-11-28 21:57:23,118 [bic.py] => bias_correction => Task 7, Epoch 126/170 => Loss 3.853, Train_accy 75.620, Test_accy 50.690
2022-11-28 21:57:27,236 [bic.py] => bias_correction => Task 7, Epoch 127/170 => Loss 3.845, Train_accy 75.620, Test_accy 50.780
2022-11-28 21:57:31,196 [bic.py] => bias_correction => Task 7, Epoch 128/170 => Loss 3.843, Train_accy 75.620, Test_accy 50.680
2022-11-28 21:57:35,330 [bic.py] => bias_correction => Task 7, Epoch 129/170 => Loss 3.922, Train_accy 73.750, Test_accy 50.500
2022-11-28 21:57:39,377 [bic.py] => bias_correction => Task 7, Epoch 130/170 => Loss 3.872, Train_accy 75.620, Test_accy 50.200
2022-11-28 21:57:43,343 [bic.py] => bias_correction => Task 7, Epoch 131/170 => Loss 3.919, Train_accy 71.880, Test_accy 50.090
2022-11-28 21:57:47,468 [bic.py] => bias_correction => Task 7, Epoch 132/170 => Loss 3.886, Train_accy 74.380, Test_accy 50.520
2022-11-28 21:57:51,664 [bic.py] => bias_correction => Task 7, Epoch 133/170 => Loss 3.902, Train_accy 76.250, Test_accy 50.680
2022-11-28 21:57:55,922 [bic.py] => bias_correction => Task 7, Epoch 134/170 => Loss 3.829, Train_accy 73.120, Test_accy 50.410
2022-11-28 21:58:00,149 [bic.py] => bias_correction => Task 7, Epoch 135/170 => Loss 3.848, Train_accy 71.250, Test_accy 50.690
2022-11-28 21:58:04,233 [bic.py] => bias_correction => Task 7, Epoch 136/170 => Loss 3.876, Train_accy 73.750, Test_accy 50.240
2022-11-28 21:58:08,541 [bic.py] => bias_correction => Task 7, Epoch 137/170 => Loss 3.896, Train_accy 71.880, Test_accy 50.460
2022-11-28 21:58:12,769 [bic.py] => bias_correction => Task 7, Epoch 138/170 => Loss 3.845, Train_accy 73.120, Test_accy 50.520
2022-11-28 21:58:16,717 [bic.py] => bias_correction => Task 7, Epoch 139/170 => Loss 3.875, Train_accy 71.880, Test_accy 50.500
2022-11-28 21:58:20,801 [bic.py] => bias_correction => Task 7, Epoch 140/170 => Loss 3.871, Train_accy 71.250, Test_accy 50.450
2022-11-28 21:58:25,160 [bic.py] => bias_correction => Task 7, Epoch 141/170 => Loss 3.860, Train_accy 73.750, Test_accy 50.500
2022-11-28 21:58:29,274 [bic.py] => bias_correction => Task 7, Epoch 142/170 => Loss 3.924, Train_accy 69.380, Test_accy 50.460
2022-11-28 21:58:33,500 [bic.py] => bias_correction => Task 7, Epoch 143/170 => Loss 3.880, Train_accy 71.880, Test_accy 50.650
2022-11-28 21:58:37,579 [bic.py] => bias_correction => Task 7, Epoch 144/170 => Loss 3.895, Train_accy 76.250, Test_accy 50.820
2022-11-28 21:58:41,415 [bic.py] => bias_correction => Task 7, Epoch 145/170 => Loss 3.885, Train_accy 75.620, Test_accy 50.840
2022-11-28 21:58:45,349 [bic.py] => bias_correction => Task 7, Epoch 146/170 => Loss 3.867, Train_accy 73.750, Test_accy 50.990
2022-11-28 21:58:49,338 [bic.py] => bias_correction => Task 7, Epoch 147/170 => Loss 3.853, Train_accy 76.880, Test_accy 50.740
2022-11-28 21:58:53,955 [bic.py] => bias_correction => Task 7, Epoch 148/170 => Loss 3.879, Train_accy 73.750, Test_accy 50.600
2022-11-28 21:58:58,232 [bic.py] => bias_correction => Task 7, Epoch 149/170 => Loss 3.874, Train_accy 71.880, Test_accy 50.680
2022-11-28 21:59:02,181 [bic.py] => bias_correction => Task 7, Epoch 150/170 => Loss 3.909, Train_accy 75.620, Test_accy 50.760
2022-11-28 21:59:06,251 [bic.py] => bias_correction => Task 7, Epoch 151/170 => Loss 3.854, Train_accy 73.750, Test_accy 50.560
2022-11-28 21:59:10,215 [bic.py] => bias_correction => Task 7, Epoch 152/170 => Loss 3.877, Train_accy 75.620, Test_accy 50.540
2022-11-28 21:59:14,540 [bic.py] => bias_correction => Task 7, Epoch 153/170 => Loss 3.875, Train_accy 73.750, Test_accy 50.280
2022-11-28 21:59:18,798 [bic.py] => bias_correction => Task 7, Epoch 154/170 => Loss 3.854, Train_accy 72.500, Test_accy 50.460
2022-11-28 21:59:23,075 [bic.py] => bias_correction => Task 7, Epoch 155/170 => Loss 3.903, Train_accy 77.500, Test_accy 50.400
2022-11-28 21:59:27,264 [bic.py] => bias_correction => Task 7, Epoch 156/170 => Loss 3.892, Train_accy 73.750, Test_accy 50.590
2022-11-28 21:59:31,616 [bic.py] => bias_correction => Task 7, Epoch 157/170 => Loss 3.891, Train_accy 75.620, Test_accy 50.350
2022-11-28 21:59:35,491 [bic.py] => bias_correction => Task 7, Epoch 158/170 => Loss 3.818, Train_accy 76.250, Test_accy 50.400
2022-11-28 21:59:39,630 [bic.py] => bias_correction => Task 7, Epoch 159/170 => Loss 3.887, Train_accy 75.620, Test_accy 50.510
2022-11-28 21:59:43,562 [bic.py] => bias_correction => Task 7, Epoch 160/170 => Loss 3.878, Train_accy 73.750, Test_accy 50.660
2022-11-28 21:59:47,679 [bic.py] => bias_correction => Task 7, Epoch 161/170 => Loss 3.908, Train_accy 76.880, Test_accy 50.740
2022-11-28 21:59:51,691 [bic.py] => bias_correction => Task 7, Epoch 162/170 => Loss 3.898, Train_accy 73.750, Test_accy 50.790
2022-11-28 21:59:55,980 [bic.py] => bias_correction => Task 7, Epoch 163/170 => Loss 3.877, Train_accy 73.750, Test_accy 50.680
2022-11-28 21:59:59,870 [bic.py] => bias_correction => Task 7, Epoch 164/170 => Loss 3.867, Train_accy 73.750, Test_accy 50.780
2022-11-28 22:00:03,833 [bic.py] => bias_correction => Task 7, Epoch 165/170 => Loss 3.867, Train_accy 75.620, Test_accy 50.720
2022-11-28 22:00:07,921 [bic.py] => bias_correction => Task 7, Epoch 166/170 => Loss 3.846, Train_accy 74.380, Test_accy 50.640
2022-11-28 22:00:12,014 [bic.py] => bias_correction => Task 7, Epoch 167/170 => Loss 3.857, Train_accy 75.620, Test_accy 50.760
2022-11-28 22:00:16,001 [bic.py] => bias_correction => Task 7, Epoch 168/170 => Loss 3.866, Train_accy 75.620, Test_accy 50.640
2022-11-28 22:00:20,104 [bic.py] => bias_correction => Task 7, Epoch 169/170 => Loss 3.822, Train_accy 73.750, Test_accy 50.620
2022-11-28 22:00:24,482 [bic.py] => bias_correction => Task 7, Epoch 170/170 => Loss 3.914, Train_accy 74.380, Test_accy 50.710
2022-11-28 22:00:24,483 [base.py] => Reducing exemplars...(25 per classes)
2022-11-28 22:00:53,235 [base.py] => Constructing exemplars...(25 per classes)
2022-11-28 22:01:02,379 [bic.py] => Parameters of bias layer:
2022-11-28 22:01:02,379 [bic.py] => 0 => 1.000, 0.000
2022-11-28 22:01:02,379 [bic.py] => 1 => 0.976, -1.640
2022-11-28 22:01:02,379 [bic.py] => 2 => 0.847, -1.789
2022-11-28 22:01:02,379 [bic.py] => 3 => 0.728, -1.453
2022-11-28 22:01:02,379 [bic.py] => 4 => 0.739, -1.271
2022-11-28 22:01:02,379 [bic.py] => 5 => 0.788, -1.449
2022-11-28 22:01:02,379 [bic.py] => 6 => 0.727, -1.396
2022-11-28 22:01:02,380 [bic.py] => 7 => -0.032, -0.821
2022-11-28 22:01:04,736 [bic.py] => Exemplar size: 2000
2022-11-28 22:01:04,736 [trainer.py] => CNN: {'total': 50.71, '00-09': 63.4, '10-19': 50.6, '20-29': 62.6, '30-39': 50.1, '40-49': 59.6, '50-59': 58.2, '60-69': 61.2, '70-79': 0.0, 'old': 57.96, 'new': 0.0}
2022-11-28 22:01:04,736 [trainer.py] => NME: {'total': 55.1, '00-09': 55.5, '10-19': 41.3, '20-29': 57.0, '30-39': 47.0, '40-49': 60.8, '50-59': 50.1, '60-69': 64.0, '70-79': 65.1, 'old': 53.67, 'new': 65.1}
2022-11-28 22:01:04,736 [trainer.py] => CNN top1 curve: [88.7, 75.6, 72.3, 66.6, 64.42, 60.9, 58.66, 50.71]
2022-11-28 22:01:04,736 [trainer.py] => CNN top5 curve: [99.4, 95.6, 93.5, 91.42, 90.66, 87.9, 85.69, 74.16]
2022-11-28 22:01:04,736 [trainer.py] => NME top1 curve: [88.5, 75.85, 72.47, 66.72, 64.22, 60.88, 58.87, 55.1]
2022-11-28 22:01:04,736 [trainer.py] => NME top5 curve: [99.4, 95.95, 93.8, 91.2, 89.16, 86.13, 84.11, 81.74]

2022-11-28 22:01:04,737 [trainer.py] => All params: 469370
2022-11-28 22:01:04,737 [trainer.py] => Trainable params: 469370
2022-11-28 22:01:04,737 [bic.py] => Learning on 80-90
2022-11-28 22:01:04,776 [bic.py] => Stage1 dset: 6820, Stage2 dset: 180
2022-11-28 22:01:04,776 [bic.py] => Lambda: 0.889
2022-11-28 22:01:04,794 [bic.py] => Parameters of bias layer:
2022-11-28 22:01:04,794 [bic.py] => 0 => 1.000, 0.000
2022-11-28 22:01:04,794 [bic.py] => 1 => 0.976, -1.640
2022-11-28 22:01:04,794 [bic.py] => 2 => 0.847, -1.789
2022-11-28 22:01:04,794 [bic.py] => 3 => 0.728, -1.453
2022-11-28 22:01:04,794 [bic.py] => 4 => 0.739, -1.271
2022-11-28 22:01:04,794 [bic.py] => 5 => 0.788, -1.449
2022-11-28 22:01:04,794 [bic.py] => 6 => 0.727, -1.396
2022-11-28 22:01:04,795 [bic.py] => 7 => -0.032, -0.821
2022-11-28 22:01:04,795 [bic.py] => 8 => 1.000, 0.000
2022-11-28 22:01:14,205 [bic.py] => training => Task 8, Epoch 1/170 => Loss 3.060, Train_accy 71.280, Test_accy 34.010
2022-11-28 22:01:23,888 [bic.py] => training => Task 8, Epoch 2/170 => Loss 2.992, Train_accy 72.980, Test_accy 33.170
2022-11-28 22:01:32,572 [bic.py] => training => Task 8, Epoch 3/170 => Loss 2.979, Train_accy 75.750, Test_accy 36.660
2022-11-28 22:01:42,072 [bic.py] => training => Task 8, Epoch 4/170 => Loss 2.956, Train_accy 77.890, Test_accy 36.680
2022-11-28 22:01:51,245 [bic.py] => training => Task 8, Epoch 5/170 => Loss 2.967, Train_accy 77.550, Test_accy 33.810
2022-11-28 22:02:00,917 [bic.py] => training => Task 8, Epoch 6/170 => Loss 2.958, Train_accy 79.250, Test_accy 36.800
2022-11-28 22:02:09,855 [bic.py] => training => Task 8, Epoch 7/170 => Loss 2.946, Train_accy 80.600, Test_accy 36.680
2022-11-28 22:02:19,056 [bic.py] => training => Task 8, Epoch 8/170 => Loss 2.949, Train_accy 81.890, Test_accy 36.310
2022-11-28 22:02:28,663 [bic.py] => training => Task 8, Epoch 9/170 => Loss 2.946, Train_accy 80.340, Test_accy 38.160
2022-11-28 22:02:38,473 [bic.py] => training => Task 8, Epoch 10/170 => Loss 2.946, Train_accy 82.020, Test_accy 32.780
2022-11-28 22:02:47,875 [bic.py] => training => Task 8, Epoch 11/170 => Loss 2.947, Train_accy 83.400, Test_accy 38.210
2022-11-28 22:02:57,171 [bic.py] => training => Task 8, Epoch 12/170 => Loss 2.940, Train_accy 81.920, Test_accy 36.300
2022-11-28 22:03:06,788 [bic.py] => training => Task 8, Epoch 13/170 => Loss 2.939, Train_accy 83.860, Test_accy 39.480
2022-11-28 22:03:16,594 [bic.py] => training => Task 8, Epoch 14/170 => Loss 2.951, Train_accy 84.130, Test_accy 38.160
2022-11-28 22:03:26,116 [bic.py] => training => Task 8, Epoch 15/170 => Loss 2.938, Train_accy 83.280, Test_accy 38.830
2022-11-28 22:03:35,315 [bic.py] => training => Task 8, Epoch 16/170 => Loss 2.945, Train_accy 84.220, Test_accy 37.720
2022-11-28 22:03:44,468 [bic.py] => training => Task 8, Epoch 17/170 => Loss 2.937, Train_accy 78.620, Test_accy 37.510
2022-11-28 22:03:54,571 [bic.py] => training => Task 8, Epoch 18/170 => Loss 2.932, Train_accy 86.360, Test_accy 36.260
2022-11-28 22:04:03,564 [bic.py] => training => Task 8, Epoch 19/170 => Loss 2.930, Train_accy 84.470, Test_accy 39.770
2022-11-28 22:04:13,376 [bic.py] => training => Task 8, Epoch 20/170 => Loss 2.944, Train_accy 82.180, Test_accy 36.570
2022-11-28 22:04:23,430 [bic.py] => training => Task 8, Epoch 21/170 => Loss 2.935, Train_accy 84.160, Test_accy 37.260
2022-11-28 22:04:32,741 [bic.py] => training => Task 8, Epoch 22/170 => Loss 2.932, Train_accy 83.520, Test_accy 38.140
2022-11-28 22:04:42,239 [bic.py] => training => Task 8, Epoch 23/170 => Loss 2.934, Train_accy 85.820, Test_accy 38.660
2022-11-28 22:04:51,571 [bic.py] => training => Task 8, Epoch 24/170 => Loss 2.937, Train_accy 84.690, Test_accy 35.760
2022-11-28 22:05:01,189 [bic.py] => training => Task 8, Epoch 25/170 => Loss 2.933, Train_accy 86.410, Test_accy 39.960
2022-11-28 22:05:10,054 [bic.py] => training => Task 8, Epoch 26/170 => Loss 2.922, Train_accy 85.160, Test_accy 38.230
2022-11-28 22:05:19,358 [bic.py] => training => Task 8, Epoch 27/170 => Loss 2.940, Train_accy 85.280, Test_accy 37.590
2022-11-28 22:05:29,141 [bic.py] => training => Task 8, Epoch 28/170 => Loss 2.930, Train_accy 84.410, Test_accy 37.510
2022-11-28 22:05:38,436 [bic.py] => training => Task 8, Epoch 29/170 => Loss 2.932, Train_accy 84.380, Test_accy 36.240
2022-11-28 22:05:48,117 [bic.py] => training => Task 8, Epoch 30/170 => Loss 2.940, Train_accy 83.830, Test_accy 36.140
2022-11-28 22:05:57,177 [bic.py] => training => Task 8, Epoch 31/170 => Loss 2.929, Train_accy 85.780, Test_accy 35.790
2022-11-28 22:06:06,574 [bic.py] => training => Task 8, Epoch 32/170 => Loss 2.931, Train_accy 85.480, Test_accy 37.560
2022-11-28 22:06:15,546 [bic.py] => training => Task 8, Epoch 33/170 => Loss 2.931, Train_accy 86.940, Test_accy 36.580
2022-11-28 22:06:25,202 [bic.py] => training => Task 8, Epoch 34/170 => Loss 2.940, Train_accy 86.770, Test_accy 37.280
2022-11-28 22:06:34,579 [bic.py] => training => Task 8, Epoch 35/170 => Loss 2.933, Train_accy 84.750, Test_accy 35.930
2022-11-28 22:06:43,643 [bic.py] => training => Task 8, Epoch 36/170 => Loss 2.921, Train_accy 85.820, Test_accy 35.490
2022-11-28 22:06:53,754 [bic.py] => training => Task 8, Epoch 37/170 => Loss 2.925, Train_accy 88.390, Test_accy 38.580
2022-11-28 22:07:03,022 [bic.py] => training => Task 8, Epoch 38/170 => Loss 2.929, Train_accy 87.740, Test_accy 36.690
2022-11-28 22:07:12,305 [bic.py] => training => Task 8, Epoch 39/170 => Loss 2.924, Train_accy 88.050, Test_accy 38.520
2022-11-28 22:07:21,544 [bic.py] => training => Task 8, Epoch 40/170 => Loss 2.922, Train_accy 87.140, Test_accy 37.590
2022-11-28 22:07:31,340 [bic.py] => training => Task 8, Epoch 41/170 => Loss 2.930, Train_accy 88.640, Test_accy 37.840
2022-11-28 22:07:40,584 [bic.py] => training => Task 8, Epoch 42/170 => Loss 2.924, Train_accy 89.550, Test_accy 37.390
2022-11-28 22:07:49,994 [bic.py] => training => Task 8, Epoch 43/170 => Loss 2.929, Train_accy 86.260, Test_accy 36.490
2022-11-28 22:07:59,755 [bic.py] => training => Task 8, Epoch 44/170 => Loss 2.927, Train_accy 82.700, Test_accy 37.080
2022-11-28 22:08:09,474 [bic.py] => training => Task 8, Epoch 45/170 => Loss 2.926, Train_accy 89.910, Test_accy 39.890
2022-11-28 22:08:18,608 [bic.py] => training => Task 8, Epoch 46/170 => Loss 2.928, Train_accy 89.120, Test_accy 40.230
2022-11-28 22:08:28,339 [bic.py] => training => Task 8, Epoch 47/170 => Loss 2.922, Train_accy 87.620, Test_accy 38.190
2022-11-28 22:08:37,637 [bic.py] => training => Task 8, Epoch 48/170 => Loss 2.928, Train_accy 88.080, Test_accy 38.660
2022-11-28 22:08:47,178 [bic.py] => training => Task 8, Epoch 49/170 => Loss 2.927, Train_accy 89.120, Test_accy 37.880
2022-11-28 22:08:56,531 [bic.py] => training => Task 8, Epoch 50/170 => Loss 2.927, Train_accy 89.020, Test_accy 36.300
2022-11-28 22:09:05,995 [bic.py] => training => Task 8, Epoch 51/170 => Loss 2.925, Train_accy 90.250, Test_accy 37.590
2022-11-28 22:09:15,358 [bic.py] => training => Task 8, Epoch 52/170 => Loss 2.929, Train_accy 84.660, Test_accy 36.480
2022-11-28 22:09:25,033 [bic.py] => training => Task 8, Epoch 53/170 => Loss 2.926, Train_accy 88.580, Test_accy 37.790
2022-11-28 22:09:34,614 [bic.py] => training => Task 8, Epoch 54/170 => Loss 2.930, Train_accy 89.050, Test_accy 38.100
2022-11-28 22:09:43,588 [bic.py] => training => Task 8, Epoch 55/170 => Loss 2.932, Train_accy 84.690, Test_accy 36.270
2022-11-28 22:09:53,747 [bic.py] => training => Task 8, Epoch 56/170 => Loss 2.929, Train_accy 86.700, Test_accy 33.010
2022-11-28 22:10:02,911 [bic.py] => training => Task 8, Epoch 57/170 => Loss 2.925, Train_accy 87.840, Test_accy 39.570
2022-11-28 22:10:12,136 [bic.py] => training => Task 8, Epoch 58/170 => Loss 2.928, Train_accy 85.840, Test_accy 40.700
2022-11-28 22:10:21,335 [bic.py] => training => Task 8, Epoch 59/170 => Loss 2.924, Train_accy 90.700, Test_accy 36.790
2022-11-28 22:10:30,985 [bic.py] => training => Task 8, Epoch 60/170 => Loss 2.922, Train_accy 89.880, Test_accy 39.760
2022-11-28 22:10:40,186 [bic.py] => training => Task 8, Epoch 61/170 => Loss 2.887, Train_accy 94.630, Test_accy 42.790
2022-11-28 22:10:49,585 [bic.py] => training => Task 8, Epoch 62/170 => Loss 2.877, Train_accy 94.930, Test_accy 42.530
2022-11-28 22:10:59,016 [bic.py] => training => Task 8, Epoch 63/170 => Loss 2.875, Train_accy 95.290, Test_accy 42.340
2022-11-28 22:11:08,217 [bic.py] => training => Task 8, Epoch 64/170 => Loss 2.878, Train_accy 95.400, Test_accy 43.330
2022-11-28 22:11:17,682 [bic.py] => training => Task 8, Epoch 65/170 => Loss 2.874, Train_accy 95.400, Test_accy 42.380
2022-11-28 22:11:27,213 [bic.py] => training => Task 8, Epoch 66/170 => Loss 2.872, Train_accy 95.350, Test_accy 42.660
2022-11-28 22:11:36,755 [bic.py] => training => Task 8, Epoch 67/170 => Loss 2.878, Train_accy 95.400, Test_accy 42.770
2022-11-28 22:11:46,398 [bic.py] => training => Task 8, Epoch 68/170 => Loss 2.872, Train_accy 95.450, Test_accy 42.720
2022-11-28 22:11:56,104 [bic.py] => training => Task 8, Epoch 69/170 => Loss 2.879, Train_accy 95.630, Test_accy 43.420
2022-11-28 22:12:05,498 [bic.py] => training => Task 8, Epoch 70/170 => Loss 2.873, Train_accy 95.340, Test_accy 42.620
2022-11-28 22:12:14,990 [bic.py] => training => Task 8, Epoch 71/170 => Loss 2.869, Train_accy 95.590, Test_accy 42.620
2022-11-28 22:12:24,797 [bic.py] => training => Task 8, Epoch 72/170 => Loss 2.874, Train_accy 95.400, Test_accy 42.590
2022-11-28 22:12:34,476 [bic.py] => training => Task 8, Epoch 73/170 => Loss 2.869, Train_accy 95.570, Test_accy 42.420
2022-11-28 22:12:43,715 [bic.py] => training => Task 8, Epoch 74/170 => Loss 2.866, Train_accy 95.620, Test_accy 43.310
2022-11-28 22:12:53,329 [bic.py] => training => Task 8, Epoch 75/170 => Loss 2.861, Train_accy 95.720, Test_accy 43.610
2022-11-28 22:13:02,801 [bic.py] => training => Task 8, Epoch 76/170 => Loss 2.867, Train_accy 95.670, Test_accy 43.190
2022-11-28 22:13:12,486 [bic.py] => training => Task 8, Epoch 77/170 => Loss 2.864, Train_accy 95.820, Test_accy 43.100
2022-11-28 22:13:21,717 [bic.py] => training => Task 8, Epoch 78/170 => Loss 2.872, Train_accy 95.820, Test_accy 43.130
2022-11-28 22:13:31,215 [bic.py] => training => Task 8, Epoch 79/170 => Loss 2.869, Train_accy 95.760, Test_accy 43.300
2022-11-28 22:13:40,438 [bic.py] => training => Task 8, Epoch 80/170 => Loss 2.871, Train_accy 95.810, Test_accy 43.160
2022-11-28 22:13:49,430 [bic.py] => training => Task 8, Epoch 81/170 => Loss 2.869, Train_accy 95.910, Test_accy 42.990
2022-11-28 22:13:59,736 [bic.py] => training => Task 8, Epoch 82/170 => Loss 2.865, Train_accy 95.870, Test_accy 42.820
2022-11-28 22:14:09,094 [bic.py] => training => Task 8, Epoch 83/170 => Loss 2.870, Train_accy 95.890, Test_accy 43.780
2022-11-28 22:14:18,781 [bic.py] => training => Task 8, Epoch 84/170 => Loss 2.867, Train_accy 95.650, Test_accy 42.420
2022-11-28 22:14:27,898 [bic.py] => training => Task 8, Epoch 85/170 => Loss 2.866, Train_accy 95.700, Test_accy 43.470
2022-11-28 22:14:37,247 [bic.py] => training => Task 8, Epoch 86/170 => Loss 2.866, Train_accy 96.000, Test_accy 43.070
2022-11-28 22:14:46,323 [bic.py] => training => Task 8, Epoch 87/170 => Loss 2.870, Train_accy 95.820, Test_accy 42.980
2022-11-28 22:14:56,001 [bic.py] => training => Task 8, Epoch 88/170 => Loss 2.869, Train_accy 96.030, Test_accy 43.490
2022-11-28 22:15:05,002 [bic.py] => training => Task 8, Epoch 89/170 => Loss 2.869, Train_accy 96.010, Test_accy 43.370
2022-11-28 22:15:14,489 [bic.py] => training => Task 8, Epoch 90/170 => Loss 2.866, Train_accy 95.910, Test_accy 43.530
2022-11-28 22:15:23,962 [bic.py] => training => Task 8, Epoch 91/170 => Loss 2.868, Train_accy 96.070, Test_accy 43.630
2022-11-28 22:15:33,253 [bic.py] => training => Task 8, Epoch 92/170 => Loss 2.868, Train_accy 95.890, Test_accy 43.290
2022-11-28 22:15:42,948 [bic.py] => training => Task 8, Epoch 93/170 => Loss 2.866, Train_accy 95.980, Test_accy 42.830
2022-11-28 22:15:52,171 [bic.py] => training => Task 8, Epoch 94/170 => Loss 2.869, Train_accy 95.880, Test_accy 43.230
2022-11-28 22:16:01,083 [bic.py] => training => Task 8, Epoch 95/170 => Loss 2.865, Train_accy 95.810, Test_accy 42.630
2022-11-28 22:16:10,577 [bic.py] => training => Task 8, Epoch 96/170 => Loss 2.864, Train_accy 96.030, Test_accy 43.390
2022-11-28 22:16:19,891 [bic.py] => training => Task 8, Epoch 97/170 => Loss 2.866, Train_accy 95.970, Test_accy 43.120
2022-11-28 22:16:30,145 [bic.py] => training => Task 8, Epoch 98/170 => Loss 2.863, Train_accy 95.910, Test_accy 43.180
2022-11-28 22:16:39,420 [bic.py] => training => Task 8, Epoch 99/170 => Loss 2.862, Train_accy 95.980, Test_accy 42.980
2022-11-28 22:16:48,903 [bic.py] => training => Task 8, Epoch 100/170 => Loss 2.866, Train_accy 95.920, Test_accy 43.070
2022-11-28 22:16:58,452 [bic.py] => training => Task 8, Epoch 101/170 => Loss 2.863, Train_accy 95.920, Test_accy 43.710
2022-11-28 22:17:08,032 [bic.py] => training => Task 8, Epoch 102/170 => Loss 2.862, Train_accy 95.950, Test_accy 43.130
2022-11-28 22:17:17,375 [bic.py] => training => Task 8, Epoch 103/170 => Loss 2.866, Train_accy 96.110, Test_accy 43.340
2022-11-28 22:17:26,887 [bic.py] => training => Task 8, Epoch 104/170 => Loss 2.866, Train_accy 96.100, Test_accy 43.780
2022-11-28 22:17:36,212 [bic.py] => training => Task 8, Epoch 105/170 => Loss 2.868, Train_accy 96.010, Test_accy 43.070
2022-11-28 22:17:45,179 [bic.py] => training => Task 8, Epoch 106/170 => Loss 2.863, Train_accy 95.970, Test_accy 43.490
2022-11-28 22:17:54,596 [bic.py] => training => Task 8, Epoch 107/170 => Loss 2.860, Train_accy 96.040, Test_accy 43.200
2022-11-28 22:18:03,913 [bic.py] => training => Task 8, Epoch 108/170 => Loss 2.862, Train_accy 96.060, Test_accy 43.410
2022-11-28 22:18:13,342 [bic.py] => training => Task 8, Epoch 109/170 => Loss 2.862, Train_accy 95.920, Test_accy 42.660
2022-11-28 22:18:22,791 [bic.py] => training => Task 8, Epoch 110/170 => Loss 2.862, Train_accy 96.040, Test_accy 43.500
2022-11-28 22:18:32,047 [bic.py] => training => Task 8, Epoch 111/170 => Loss 2.860, Train_accy 95.810, Test_accy 43.300
2022-11-28 22:18:41,583 [bic.py] => training => Task 8, Epoch 112/170 => Loss 2.866, Train_accy 96.110, Test_accy 42.870
2022-11-28 22:18:51,303 [bic.py] => training => Task 8, Epoch 113/170 => Loss 2.865, Train_accy 96.070, Test_accy 42.770
2022-11-28 22:19:00,978 [bic.py] => training => Task 8, Epoch 114/170 => Loss 2.865, Train_accy 95.950, Test_accy 43.130
2022-11-28 22:19:09,901 [bic.py] => training => Task 8, Epoch 115/170 => Loss 2.862, Train_accy 95.980, Test_accy 43.110
2022-11-28 22:19:19,164 [bic.py] => training => Task 8, Epoch 116/170 => Loss 2.861, Train_accy 95.940, Test_accy 42.860
2022-11-28 22:19:28,674 [bic.py] => training => Task 8, Epoch 117/170 => Loss 2.864, Train_accy 96.100, Test_accy 43.410
2022-11-28 22:19:37,975 [bic.py] => training => Task 8, Epoch 118/170 => Loss 2.861, Train_accy 96.130, Test_accy 42.710
2022-11-28 22:19:47,503 [bic.py] => training => Task 8, Epoch 119/170 => Loss 2.864, Train_accy 95.940, Test_accy 43.630
2022-11-28 22:19:56,716 [bic.py] => training => Task 8, Epoch 120/170 => Loss 2.862, Train_accy 96.030, Test_accy 43.240
2022-11-28 22:20:05,615 [bic.py] => training => Task 8, Epoch 121/170 => Loss 2.860, Train_accy 96.090, Test_accy 44.130
2022-11-28 22:20:14,737 [bic.py] => training => Task 8, Epoch 122/170 => Loss 2.864, Train_accy 96.090, Test_accy 43.810
2022-11-28 22:20:24,453 [bic.py] => training => Task 8, Epoch 123/170 => Loss 2.862, Train_accy 95.910, Test_accy 42.490
2022-11-28 22:20:34,282 [bic.py] => training => Task 8, Epoch 124/170 => Loss 2.860, Train_accy 96.090, Test_accy 43.090
2022-11-28 22:20:43,227 [bic.py] => training => Task 8, Epoch 125/170 => Loss 2.858, Train_accy 95.980, Test_accy 43.110
2022-11-28 22:20:53,130 [bic.py] => training => Task 8, Epoch 126/170 => Loss 2.859, Train_accy 96.070, Test_accy 43.380
2022-11-28 22:21:02,244 [bic.py] => training => Task 8, Epoch 127/170 => Loss 2.858, Train_accy 96.030, Test_accy 43.820
2022-11-28 22:21:11,895 [bic.py] => training => Task 8, Epoch 128/170 => Loss 2.865, Train_accy 96.160, Test_accy 43.430
2022-11-28 22:21:21,585 [bic.py] => training => Task 8, Epoch 129/170 => Loss 2.860, Train_accy 95.970, Test_accy 43.620
2022-11-28 22:21:30,828 [bic.py] => training => Task 8, Epoch 130/170 => Loss 2.862, Train_accy 96.170, Test_accy 43.430
2022-11-28 22:21:39,819 [bic.py] => training => Task 8, Epoch 131/170 => Loss 2.857, Train_accy 95.940, Test_accy 43.160
2022-11-28 22:21:49,453 [bic.py] => training => Task 8, Epoch 132/170 => Loss 2.858, Train_accy 96.030, Test_accy 43.440
2022-11-28 22:21:58,752 [bic.py] => training => Task 8, Epoch 133/170 => Loss 2.861, Train_accy 96.160, Test_accy 43.620
2022-11-28 22:22:07,949 [bic.py] => training => Task 8, Epoch 134/170 => Loss 2.861, Train_accy 96.130, Test_accy 43.410
2022-11-28 22:22:17,607 [bic.py] => training => Task 8, Epoch 135/170 => Loss 2.861, Train_accy 96.070, Test_accy 43.160
2022-11-28 22:22:27,060 [bic.py] => training => Task 8, Epoch 136/170 => Loss 2.865, Train_accy 96.100, Test_accy 42.900
2022-11-28 22:22:36,270 [bic.py] => training => Task 8, Epoch 137/170 => Loss 2.857, Train_accy 96.010, Test_accy 43.130
2022-11-28 22:22:45,649 [bic.py] => training => Task 8, Epoch 138/170 => Loss 2.863, Train_accy 96.110, Test_accy 43.010
2022-11-28 22:22:54,812 [bic.py] => training => Task 8, Epoch 139/170 => Loss 2.865, Train_accy 96.090, Test_accy 43.960
2022-11-28 22:23:04,368 [bic.py] => training => Task 8, Epoch 140/170 => Loss 2.862, Train_accy 96.140, Test_accy 43.380
2022-11-28 22:23:13,555 [bic.py] => training => Task 8, Epoch 141/170 => Loss 2.857, Train_accy 96.100, Test_accy 43.240
2022-11-28 22:23:22,922 [bic.py] => training => Task 8, Epoch 142/170 => Loss 2.857, Train_accy 96.140, Test_accy 43.230
2022-11-28 22:23:32,485 [bic.py] => training => Task 8, Epoch 143/170 => Loss 2.858, Train_accy 96.030, Test_accy 42.930
2022-11-28 22:23:41,909 [bic.py] => training => Task 8, Epoch 144/170 => Loss 2.861, Train_accy 96.220, Test_accy 43.820
2022-11-28 22:23:51,437 [bic.py] => training => Task 8, Epoch 145/170 => Loss 2.853, Train_accy 96.100, Test_accy 43.460
2022-11-28 22:24:01,291 [bic.py] => training => Task 8, Epoch 146/170 => Loss 2.865, Train_accy 96.040, Test_accy 43.020
2022-11-28 22:24:10,894 [bic.py] => training => Task 8, Epoch 147/170 => Loss 2.862, Train_accy 96.040, Test_accy 43.800
2022-11-28 22:24:20,359 [bic.py] => training => Task 8, Epoch 148/170 => Loss 2.865, Train_accy 96.030, Test_accy 43.160
2022-11-28 22:24:30,006 [bic.py] => training => Task 8, Epoch 149/170 => Loss 2.863, Train_accy 95.970, Test_accy 43.280
2022-11-28 22:24:39,137 [bic.py] => training => Task 8, Epoch 150/170 => Loss 2.862, Train_accy 96.090, Test_accy 43.460
2022-11-28 22:24:48,317 [bic.py] => training => Task 8, Epoch 151/170 => Loss 2.860, Train_accy 96.060, Test_accy 43.800
2022-11-28 22:24:57,849 [bic.py] => training => Task 8, Epoch 152/170 => Loss 2.857, Train_accy 96.130, Test_accy 43.670
2022-11-28 22:25:06,956 [bic.py] => training => Task 8, Epoch 153/170 => Loss 2.858, Train_accy 95.940, Test_accy 43.360
2022-11-28 22:25:16,037 [bic.py] => training => Task 8, Epoch 154/170 => Loss 2.862, Train_accy 96.160, Test_accy 43.210
2022-11-28 22:25:25,822 [bic.py] => training => Task 8, Epoch 155/170 => Loss 2.864, Train_accy 96.040, Test_accy 43.520
2022-11-28 22:25:35,213 [bic.py] => training => Task 8, Epoch 156/170 => Loss 2.859, Train_accy 95.970, Test_accy 43.240
2022-11-28 22:25:44,328 [bic.py] => training => Task 8, Epoch 157/170 => Loss 2.861, Train_accy 96.070, Test_accy 43.740
2022-11-28 22:25:54,362 [bic.py] => training => Task 8, Epoch 158/170 => Loss 2.862, Train_accy 95.950, Test_accy 42.920
2022-11-28 22:26:03,765 [bic.py] => training => Task 8, Epoch 159/170 => Loss 2.862, Train_accy 96.160, Test_accy 43.270
2022-11-28 22:26:13,499 [bic.py] => training => Task 8, Epoch 160/170 => Loss 2.860, Train_accy 96.010, Test_accy 43.190
2022-11-28 22:26:22,649 [bic.py] => training => Task 8, Epoch 161/170 => Loss 2.870, Train_accy 96.100, Test_accy 44.140
2022-11-28 22:26:31,750 [bic.py] => training => Task 8, Epoch 162/170 => Loss 2.864, Train_accy 96.070, Test_accy 42.640
2022-11-28 22:26:41,074 [bic.py] => training => Task 8, Epoch 163/170 => Loss 2.861, Train_accy 96.090, Test_accy 43.660
2022-11-28 22:26:50,553 [bic.py] => training => Task 8, Epoch 164/170 => Loss 2.861, Train_accy 96.190, Test_accy 43.690
2022-11-28 22:27:00,514 [bic.py] => training => Task 8, Epoch 165/170 => Loss 2.857, Train_accy 96.090, Test_accy 42.970
2022-11-28 22:27:10,015 [bic.py] => training => Task 8, Epoch 166/170 => Loss 2.863, Train_accy 96.010, Test_accy 43.370
2022-11-28 22:27:19,139 [bic.py] => training => Task 8, Epoch 167/170 => Loss 2.862, Train_accy 95.950, Test_accy 44.020
2022-11-28 22:27:28,622 [bic.py] => training => Task 8, Epoch 168/170 => Loss 2.866, Train_accy 96.070, Test_accy 43.090
2022-11-28 22:27:37,766 [bic.py] => training => Task 8, Epoch 169/170 => Loss 2.861, Train_accy 95.850, Test_accy 43.500
2022-11-28 22:27:46,855 [bic.py] => training => Task 8, Epoch 170/170 => Loss 2.861, Train_accy 96.040, Test_accy 43.370
2022-11-28 22:27:51,181 [bic.py] => bias_correction => Task 8, Epoch 1/170 => Loss 4.087, Train_accy 66.670, Test_accy 45.540
2022-11-28 22:27:55,645 [bic.py] => bias_correction => Task 8, Epoch 2/170 => Loss 4.035, Train_accy 75.560, Test_accy 49.520
2022-11-28 22:28:00,134 [bic.py] => bias_correction => Task 8, Epoch 3/170 => Loss 3.982, Train_accy 75.000, Test_accy 47.890
2022-11-28 22:28:04,291 [bic.py] => bias_correction => Task 8, Epoch 4/170 => Loss 3.993, Train_accy 71.110, Test_accy 45.260
2022-11-28 22:28:08,803 [bic.py] => bias_correction => Task 8, Epoch 5/170 => Loss 3.985, Train_accy 71.670, Test_accy 44.670
2022-11-28 22:28:13,355 [bic.py] => bias_correction => Task 8, Epoch 6/170 => Loss 3.970, Train_accy 70.000, Test_accy 44.770
2022-11-28 22:28:17,652 [bic.py] => bias_correction => Task 8, Epoch 7/170 => Loss 3.970, Train_accy 69.440, Test_accy 44.540
2022-11-28 22:28:22,055 [bic.py] => bias_correction => Task 8, Epoch 8/170 => Loss 3.996, Train_accy 67.220, Test_accy 44.600
2022-11-28 22:28:26,321 [bic.py] => bias_correction => Task 8, Epoch 9/170 => Loss 3.986, Train_accy 68.890, Test_accy 44.570
2022-11-28 22:28:30,447 [bic.py] => bias_correction => Task 8, Epoch 10/170 => Loss 3.972, Train_accy 71.110, Test_accy 44.710
2022-11-28 22:28:35,200 [bic.py] => bias_correction => Task 8, Epoch 11/170 => Loss 4.007, Train_accy 71.670, Test_accy 44.610
2022-11-28 22:28:39,462 [bic.py] => bias_correction => Task 8, Epoch 12/170 => Loss 3.978, Train_accy 68.890, Test_accy 44.610
2022-11-28 22:28:44,174 [bic.py] => bias_correction => Task 8, Epoch 13/170 => Loss 4.004, Train_accy 68.890, Test_accy 44.830
2022-11-28 22:28:48,397 [bic.py] => bias_correction => Task 8, Epoch 14/170 => Loss 3.984, Train_accy 70.560, Test_accy 44.830
2022-11-28 22:28:52,470 [bic.py] => bias_correction => Task 8, Epoch 15/170 => Loss 3.998, Train_accy 70.000, Test_accy 44.690
2022-11-28 22:28:56,687 [bic.py] => bias_correction => Task 8, Epoch 16/170 => Loss 3.977, Train_accy 72.780, Test_accy 44.660
2022-11-28 22:29:00,775 [bic.py] => bias_correction => Task 8, Epoch 17/170 => Loss 3.992, Train_accy 69.440, Test_accy 44.540
2022-11-28 22:29:05,053 [bic.py] => bias_correction => Task 8, Epoch 18/170 => Loss 3.988, Train_accy 71.110, Test_accy 44.410
2022-11-28 22:29:09,312 [bic.py] => bias_correction => Task 8, Epoch 19/170 => Loss 4.003, Train_accy 71.110, Test_accy 44.410
2022-11-28 22:29:13,603 [bic.py] => bias_correction => Task 8, Epoch 20/170 => Loss 3.986, Train_accy 71.670, Test_accy 44.520
2022-11-28 22:29:17,914 [bic.py] => bias_correction => Task 8, Epoch 21/170 => Loss 4.004, Train_accy 68.890, Test_accy 44.360
2022-11-28 22:29:22,018 [bic.py] => bias_correction => Task 8, Epoch 22/170 => Loss 3.983, Train_accy 74.440, Test_accy 44.570
2022-11-28 22:29:26,435 [bic.py] => bias_correction => Task 8, Epoch 23/170 => Loss 3.963, Train_accy 70.000, Test_accy 44.370
2022-11-28 22:29:30,844 [bic.py] => bias_correction => Task 8, Epoch 24/170 => Loss 3.970, Train_accy 68.330, Test_accy 44.170
2022-11-28 22:29:35,056 [bic.py] => bias_correction => Task 8, Epoch 25/170 => Loss 3.982, Train_accy 70.560, Test_accy 44.100
2022-11-28 22:29:39,194 [bic.py] => bias_correction => Task 8, Epoch 26/170 => Loss 3.946, Train_accy 68.330, Test_accy 44.070
2022-11-28 22:29:43,261 [bic.py] => bias_correction => Task 8, Epoch 27/170 => Loss 3.969, Train_accy 72.780, Test_accy 44.390
2022-11-28 22:29:47,473 [bic.py] => bias_correction => Task 8, Epoch 28/170 => Loss 3.997, Train_accy 67.780, Test_accy 44.260
2022-11-28 22:29:51,938 [bic.py] => bias_correction => Task 8, Epoch 29/170 => Loss 3.994, Train_accy 67.220, Test_accy 44.030
2022-11-28 22:29:56,381 [bic.py] => bias_correction => Task 8, Epoch 30/170 => Loss 3.998, Train_accy 70.560, Test_accy 43.940
2022-11-28 22:30:00,531 [bic.py] => bias_correction => Task 8, Epoch 31/170 => Loss 3.979, Train_accy 68.890, Test_accy 44.070
2022-11-28 22:30:05,085 [bic.py] => bias_correction => Task 8, Epoch 32/170 => Loss 3.990, Train_accy 69.440, Test_accy 44.260
2022-11-28 22:30:09,399 [bic.py] => bias_correction => Task 8, Epoch 33/170 => Loss 3.983, Train_accy 70.000, Test_accy 44.220
2022-11-28 22:30:13,420 [bic.py] => bias_correction => Task 8, Epoch 34/170 => Loss 3.991, Train_accy 70.560, Test_accy 44.120
2022-11-28 22:30:17,781 [bic.py] => bias_correction => Task 8, Epoch 35/170 => Loss 3.992, Train_accy 68.330, Test_accy 44.190
2022-11-28 22:30:22,411 [bic.py] => bias_correction => Task 8, Epoch 36/170 => Loss 3.982, Train_accy 68.890, Test_accy 44.070
2022-11-28 22:30:26,907 [bic.py] => bias_correction => Task 8, Epoch 37/170 => Loss 4.006, Train_accy 68.330, Test_accy 44.020
2022-11-28 22:30:31,174 [bic.py] => bias_correction => Task 8, Epoch 38/170 => Loss 3.977, Train_accy 69.440, Test_accy 43.900
2022-11-28 22:30:35,213 [bic.py] => bias_correction => Task 8, Epoch 39/170 => Loss 3.990, Train_accy 69.440, Test_accy 43.820
2022-11-28 22:30:39,791 [bic.py] => bias_correction => Task 8, Epoch 40/170 => Loss 3.985, Train_accy 68.330, Test_accy 44.030
2022-11-28 22:30:44,163 [bic.py] => bias_correction => Task 8, Epoch 41/170 => Loss 3.987, Train_accy 65.560, Test_accy 44.190
2022-11-28 22:30:48,598 [bic.py] => bias_correction => Task 8, Epoch 42/170 => Loss 3.995, Train_accy 70.000, Test_accy 44.130
2022-11-28 22:30:53,066 [bic.py] => bias_correction => Task 8, Epoch 43/170 => Loss 3.969, Train_accy 68.330, Test_accy 44.220
2022-11-28 22:30:57,315 [bic.py] => bias_correction => Task 8, Epoch 44/170 => Loss 3.984, Train_accy 68.890, Test_accy 44.020
2022-11-28 22:31:01,442 [bic.py] => bias_correction => Task 8, Epoch 45/170 => Loss 3.975, Train_accy 68.330, Test_accy 44.090
2022-11-28 22:31:06,190 [bic.py] => bias_correction => Task 8, Epoch 46/170 => Loss 3.975, Train_accy 69.440, Test_accy 44.270
2022-11-28 22:31:10,683 [bic.py] => bias_correction => Task 8, Epoch 47/170 => Loss 3.982, Train_accy 67.220, Test_accy 43.760
2022-11-28 22:31:15,035 [bic.py] => bias_correction => Task 8, Epoch 48/170 => Loss 3.942, Train_accy 70.000, Test_accy 44.080
2022-11-28 22:31:19,577 [bic.py] => bias_correction => Task 8, Epoch 49/170 => Loss 4.016, Train_accy 72.780, Test_accy 43.930
2022-11-28 22:31:24,490 [bic.py] => bias_correction => Task 8, Epoch 50/170 => Loss 3.980, Train_accy 68.330, Test_accy 43.800
2022-11-28 22:31:28,593 [bic.py] => bias_correction => Task 8, Epoch 51/170 => Loss 3.971, Train_accy 72.780, Test_accy 44.070
2022-11-28 22:31:32,944 [bic.py] => bias_correction => Task 8, Epoch 52/170 => Loss 4.020, Train_accy 70.560, Test_accy 44.000
2022-11-28 22:31:37,510 [bic.py] => bias_correction => Task 8, Epoch 53/170 => Loss 3.976, Train_accy 69.440, Test_accy 44.000
2022-11-28 22:31:42,146 [bic.py] => bias_correction => Task 8, Epoch 54/170 => Loss 3.986, Train_accy 69.440, Test_accy 43.780
2022-11-28 22:31:46,390 [bic.py] => bias_correction => Task 8, Epoch 55/170 => Loss 3.992, Train_accy 68.890, Test_accy 43.660
2022-11-28 22:31:50,556 [bic.py] => bias_correction => Task 8, Epoch 56/170 => Loss 3.988, Train_accy 70.000, Test_accy 43.920
2022-11-28 22:31:54,976 [bic.py] => bias_correction => Task 8, Epoch 57/170 => Loss 3.995, Train_accy 68.890, Test_accy 44.060
2022-11-28 22:31:59,216 [bic.py] => bias_correction => Task 8, Epoch 58/170 => Loss 3.997, Train_accy 72.220, Test_accy 44.130
2022-11-28 22:32:03,654 [bic.py] => bias_correction => Task 8, Epoch 59/170 => Loss 3.973, Train_accy 71.670, Test_accy 44.340
2022-11-28 22:32:08,205 [bic.py] => bias_correction => Task 8, Epoch 60/170 => Loss 3.977, Train_accy 69.440, Test_accy 44.260
2022-11-28 22:32:12,996 [bic.py] => bias_correction => Task 8, Epoch 61/170 => Loss 3.989, Train_accy 71.110, Test_accy 44.420
2022-11-28 22:32:17,633 [bic.py] => bias_correction => Task 8, Epoch 62/170 => Loss 3.993, Train_accy 70.560, Test_accy 44.490
2022-11-28 22:32:21,948 [bic.py] => bias_correction => Task 8, Epoch 63/170 => Loss 3.998, Train_accy 69.440, Test_accy 44.230
2022-11-28 22:32:26,151 [bic.py] => bias_correction => Task 8, Epoch 64/170 => Loss 3.987, Train_accy 69.440, Test_accy 44.290
2022-11-28 22:32:30,354 [bic.py] => bias_correction => Task 8, Epoch 65/170 => Loss 3.968, Train_accy 68.330, Test_accy 44.480
2022-11-28 22:32:34,529 [bic.py] => bias_correction => Task 8, Epoch 66/170 => Loss 3.965, Train_accy 70.560, Test_accy 44.360
2022-11-28 22:32:38,684 [bic.py] => bias_correction => Task 8, Epoch 67/170 => Loss 4.000, Train_accy 70.560, Test_accy 44.130
2022-11-28 22:32:42,841 [bic.py] => bias_correction => Task 8, Epoch 68/170 => Loss 4.003, Train_accy 70.560, Test_accy 43.960
2022-11-28 22:32:47,205 [bic.py] => bias_correction => Task 8, Epoch 69/170 => Loss 4.008, Train_accy 71.670, Test_accy 43.820
2022-11-28 22:32:51,595 [bic.py] => bias_correction => Task 8, Epoch 70/170 => Loss 3.976, Train_accy 68.330, Test_accy 43.860
2022-11-28 22:32:55,925 [bic.py] => bias_correction => Task 8, Epoch 71/170 => Loss 3.973, Train_accy 70.000, Test_accy 43.940
2022-11-28 22:33:00,597 [bic.py] => bias_correction => Task 8, Epoch 72/170 => Loss 3.973, Train_accy 70.560, Test_accy 44.160
2022-11-28 22:33:05,063 [bic.py] => bias_correction => Task 8, Epoch 73/170 => Loss 3.971, Train_accy 71.670, Test_accy 44.310
2022-11-28 22:33:09,627 [bic.py] => bias_correction => Task 8, Epoch 74/170 => Loss 3.994, Train_accy 69.440, Test_accy 44.320
2022-11-28 22:33:13,846 [bic.py] => bias_correction => Task 8, Epoch 75/170 => Loss 3.979, Train_accy 68.330, Test_accy 44.020
2022-11-28 22:33:17,959 [bic.py] => bias_correction => Task 8, Epoch 76/170 => Loss 3.991, Train_accy 68.890, Test_accy 44.220
2022-11-28 22:33:22,098 [bic.py] => bias_correction => Task 8, Epoch 77/170 => Loss 3.993, Train_accy 69.440, Test_accy 44.220
2022-11-28 22:33:26,408 [bic.py] => bias_correction => Task 8, Epoch 78/170 => Loss 3.975, Train_accy 70.560, Test_accy 44.120
2022-11-28 22:33:30,681 [bic.py] => bias_correction => Task 8, Epoch 79/170 => Loss 3.981, Train_accy 71.110, Test_accy 44.240
2022-11-28 22:33:35,110 [bic.py] => bias_correction => Task 8, Epoch 80/170 => Loss 3.982, Train_accy 69.440, Test_accy 44.170
2022-11-28 22:33:39,859 [bic.py] => bias_correction => Task 8, Epoch 81/170 => Loss 3.991, Train_accy 67.780, Test_accy 44.200
2022-11-28 22:33:44,215 [bic.py] => bias_correction => Task 8, Epoch 82/170 => Loss 4.004, Train_accy 71.110, Test_accy 44.270
2022-11-28 22:33:48,371 [bic.py] => bias_correction => Task 8, Epoch 83/170 => Loss 4.003, Train_accy 68.330, Test_accy 44.000
2022-11-28 22:33:52,766 [bic.py] => bias_correction => Task 8, Epoch 84/170 => Loss 3.978, Train_accy 67.220, Test_accy 44.200
2022-11-28 22:33:57,416 [bic.py] => bias_correction => Task 8, Epoch 85/170 => Loss 3.990, Train_accy 71.670, Test_accy 44.320
2022-11-28 22:34:01,913 [bic.py] => bias_correction => Task 8, Epoch 86/170 => Loss 3.980, Train_accy 69.440, Test_accy 43.920
2022-11-28 22:34:06,197 [bic.py] => bias_correction => Task 8, Epoch 87/170 => Loss 3.971, Train_accy 68.890, Test_accy 43.940
2022-11-28 22:34:10,164 [bic.py] => bias_correction => Task 8, Epoch 88/170 => Loss 3.952, Train_accy 70.000, Test_accy 43.960
2022-11-28 22:34:14,414 [bic.py] => bias_correction => Task 8, Epoch 89/170 => Loss 3.973, Train_accy 68.330, Test_accy 44.160
2022-11-28 22:34:18,636 [bic.py] => bias_correction => Task 8, Epoch 90/170 => Loss 3.982, Train_accy 67.780, Test_accy 43.900
2022-11-28 22:34:23,000 [bic.py] => bias_correction => Task 8, Epoch 91/170 => Loss 3.972, Train_accy 69.440, Test_accy 44.120
2022-11-28 22:34:28,045 [bic.py] => bias_correction => Task 8, Epoch 92/170 => Loss 3.985, Train_accy 68.330, Test_accy 44.090
2022-11-28 22:34:32,265 [bic.py] => bias_correction => Task 8, Epoch 93/170 => Loss 3.973, Train_accy 68.890, Test_accy 44.230
2022-11-28 22:34:36,432 [bic.py] => bias_correction => Task 8, Epoch 94/170 => Loss 3.981, Train_accy 71.110, Test_accy 44.300
2022-11-28 22:34:40,917 [bic.py] => bias_correction => Task 8, Epoch 95/170 => Loss 3.969, Train_accy 69.440, Test_accy 44.320
2022-11-28 22:34:45,080 [bic.py] => bias_correction => Task 8, Epoch 96/170 => Loss 3.967, Train_accy 71.110, Test_accy 44.180
2022-11-28 22:34:49,397 [bic.py] => bias_correction => Task 8, Epoch 97/170 => Loss 3.946, Train_accy 71.670, Test_accy 44.280
2022-11-28 22:34:54,169 [bic.py] => bias_correction => Task 8, Epoch 98/170 => Loss 3.961, Train_accy 70.000, Test_accy 44.170
2022-11-28 22:34:58,310 [bic.py] => bias_correction => Task 8, Epoch 99/170 => Loss 3.983, Train_accy 70.560, Test_accy 44.000
2022-11-28 22:35:02,570 [bic.py] => bias_correction => Task 8, Epoch 100/170 => Loss 3.983, Train_accy 70.000, Test_accy 44.120
2022-11-28 22:35:07,041 [bic.py] => bias_correction => Task 8, Epoch 101/170 => Loss 3.958, Train_accy 68.890, Test_accy 44.010
2022-11-28 22:35:11,518 [bic.py] => bias_correction => Task 8, Epoch 102/170 => Loss 3.983, Train_accy 70.000, Test_accy 44.140
2022-11-28 22:35:16,093 [bic.py] => bias_correction => Task 8, Epoch 103/170 => Loss 3.978, Train_accy 69.440, Test_accy 44.060
2022-11-28 22:35:20,240 [bic.py] => bias_correction => Task 8, Epoch 104/170 => Loss 3.999, Train_accy 70.560, Test_accy 44.320
2022-11-28 22:35:25,024 [bic.py] => bias_correction => Task 8, Epoch 105/170 => Loss 3.986, Train_accy 71.110, Test_accy 44.040
2022-11-28 22:35:29,209 [bic.py] => bias_correction => Task 8, Epoch 106/170 => Loss 3.957, Train_accy 71.110, Test_accy 44.140
2022-11-28 22:35:33,524 [bic.py] => bias_correction => Task 8, Epoch 107/170 => Loss 4.018, Train_accy 70.000, Test_accy 44.320
2022-11-28 22:35:37,770 [bic.py] => bias_correction => Task 8, Epoch 108/170 => Loss 3.959, Train_accy 70.000, Test_accy 44.120
2022-11-28 22:35:42,174 [bic.py] => bias_correction => Task 8, Epoch 109/170 => Loss 3.978, Train_accy 69.440, Test_accy 44.170
2022-11-28 22:35:46,559 [bic.py] => bias_correction => Task 8, Epoch 110/170 => Loss 3.957, Train_accy 68.890, Test_accy 44.300
2022-11-28 22:35:50,953 [bic.py] => bias_correction => Task 8, Epoch 111/170 => Loss 3.982, Train_accy 69.440, Test_accy 44.310
2022-11-28 22:35:55,135 [bic.py] => bias_correction => Task 8, Epoch 112/170 => Loss 3.986, Train_accy 70.000, Test_accy 44.200
2022-11-28 22:35:59,497 [bic.py] => bias_correction => Task 8, Epoch 113/170 => Loss 3.985, Train_accy 70.560, Test_accy 44.290
2022-11-28 22:36:03,773 [bic.py] => bias_correction => Task 8, Epoch 114/170 => Loss 3.990, Train_accy 68.890, Test_accy 44.230
2022-11-28 22:36:08,030 [bic.py] => bias_correction => Task 8, Epoch 115/170 => Loss 3.995, Train_accy 70.560, Test_accy 44.210
2022-11-28 22:36:12,275 [bic.py] => bias_correction => Task 8, Epoch 116/170 => Loss 3.988, Train_accy 70.560, Test_accy 43.970
2022-11-28 22:36:16,328 [bic.py] => bias_correction => Task 8, Epoch 117/170 => Loss 3.979, Train_accy 68.330, Test_accy 44.140
2022-11-28 22:36:20,666 [bic.py] => bias_correction => Task 8, Epoch 118/170 => Loss 3.988, Train_accy 70.000, Test_accy 44.280
2022-11-28 22:36:24,983 [bic.py] => bias_correction => Task 8, Epoch 119/170 => Loss 3.968, Train_accy 69.440, Test_accy 44.340
2022-11-28 22:36:29,130 [bic.py] => bias_correction => Task 8, Epoch 120/170 => Loss 3.994, Train_accy 68.890, Test_accy 44.140
2022-11-28 22:36:33,373 [bic.py] => bias_correction => Task 8, Epoch 121/170 => Loss 3.990, Train_accy 68.330, Test_accy 44.030
2022-11-28 22:36:37,778 [bic.py] => bias_correction => Task 8, Epoch 122/170 => Loss 4.001, Train_accy 70.560, Test_accy 44.200
2022-11-28 22:36:42,148 [bic.py] => bias_correction => Task 8, Epoch 123/170 => Loss 3.970, Train_accy 70.560, Test_accy 44.340
2022-11-28 22:36:46,379 [bic.py] => bias_correction => Task 8, Epoch 124/170 => Loss 3.988, Train_accy 70.000, Test_accy 44.110
2022-11-28 22:36:50,557 [bic.py] => bias_correction => Task 8, Epoch 125/170 => Loss 3.987, Train_accy 69.440, Test_accy 44.000
2022-11-28 22:36:55,141 [bic.py] => bias_correction => Task 8, Epoch 126/170 => Loss 3.991, Train_accy 70.560, Test_accy 44.500
2022-11-28 22:36:59,458 [bic.py] => bias_correction => Task 8, Epoch 127/170 => Loss 3.977, Train_accy 70.000, Test_accy 44.160
2022-11-28 22:37:03,973 [bic.py] => bias_correction => Task 8, Epoch 128/170 => Loss 3.987, Train_accy 68.890, Test_accy 44.120
2022-11-28 22:37:08,332 [bic.py] => bias_correction => Task 8, Epoch 129/170 => Loss 3.961, Train_accy 70.000, Test_accy 44.170
2022-11-28 22:37:12,722 [bic.py] => bias_correction => Task 8, Epoch 130/170 => Loss 3.982, Train_accy 68.890, Test_accy 44.340
2022-11-28 22:37:16,912 [bic.py] => bias_correction => Task 8, Epoch 131/170 => Loss 3.990, Train_accy 70.000, Test_accy 44.290
2022-11-28 22:37:20,953 [bic.py] => bias_correction => Task 8, Epoch 132/170 => Loss 3.996, Train_accy 67.220, Test_accy 44.210
2022-11-28 22:37:25,311 [bic.py] => bias_correction => Task 8, Epoch 133/170 => Loss 3.978, Train_accy 71.670, Test_accy 44.370
2022-11-28 22:37:29,488 [bic.py] => bias_correction => Task 8, Epoch 134/170 => Loss 3.985, Train_accy 72.220, Test_accy 44.230
2022-11-28 22:37:33,766 [bic.py] => bias_correction => Task 8, Epoch 135/170 => Loss 3.994, Train_accy 68.890, Test_accy 44.100
2022-11-28 22:37:38,113 [bic.py] => bias_correction => Task 8, Epoch 136/170 => Loss 3.974, Train_accy 70.000, Test_accy 44.080
2022-11-28 22:37:42,692 [bic.py] => bias_correction => Task 8, Epoch 137/170 => Loss 3.989, Train_accy 70.560, Test_accy 44.130
2022-11-28 22:37:47,405 [bic.py] => bias_correction => Task 8, Epoch 138/170 => Loss 3.980, Train_accy 69.440, Test_accy 44.310
2022-11-28 22:37:51,710 [bic.py] => bias_correction => Task 8, Epoch 139/170 => Loss 3.993, Train_accy 66.670, Test_accy 44.200
2022-11-28 22:37:55,887 [bic.py] => bias_correction => Task 8, Epoch 140/170 => Loss 3.975, Train_accy 68.330, Test_accy 44.190
2022-11-28 22:38:00,090 [bic.py] => bias_correction => Task 8, Epoch 141/170 => Loss 3.983, Train_accy 70.560, Test_accy 44.460
2022-11-28 22:38:04,436 [bic.py] => bias_correction => Task 8, Epoch 142/170 => Loss 3.965, Train_accy 68.330, Test_accy 44.320
2022-11-28 22:38:08,874 [bic.py] => bias_correction => Task 8, Epoch 143/170 => Loss 3.998, Train_accy 71.110, Test_accy 44.300
2022-11-28 22:38:13,183 [bic.py] => bias_correction => Task 8, Epoch 144/170 => Loss 3.982, Train_accy 69.440, Test_accy 44.310
2022-11-28 22:38:17,619 [bic.py] => bias_correction => Task 8, Epoch 145/170 => Loss 4.007, Train_accy 70.000, Test_accy 44.330
2022-11-28 22:38:21,940 [bic.py] => bias_correction => Task 8, Epoch 146/170 => Loss 3.999, Train_accy 70.560, Test_accy 44.490
2022-11-28 22:38:26,296 [bic.py] => bias_correction => Task 8, Epoch 147/170 => Loss 3.968, Train_accy 66.670, Test_accy 44.500
2022-11-28 22:38:30,403 [bic.py] => bias_correction => Task 8, Epoch 148/170 => Loss 3.974, Train_accy 68.330, Test_accy 44.630
2022-11-28 22:38:34,565 [bic.py] => bias_correction => Task 8, Epoch 149/170 => Loss 3.969, Train_accy 68.890, Test_accy 44.740
2022-11-28 22:38:38,777 [bic.py] => bias_correction => Task 8, Epoch 150/170 => Loss 3.965, Train_accy 69.440, Test_accy 44.510
2022-11-28 22:38:43,255 [bic.py] => bias_correction => Task 8, Epoch 151/170 => Loss 3.960, Train_accy 69.440, Test_accy 44.510
2022-11-28 22:38:47,352 [bic.py] => bias_correction => Task 8, Epoch 152/170 => Loss 3.976, Train_accy 68.890, Test_accy 44.420
2022-11-28 22:38:51,591 [bic.py] => bias_correction => Task 8, Epoch 153/170 => Loss 3.991, Train_accy 69.440, Test_accy 44.220
2022-11-28 22:38:55,830 [bic.py] => bias_correction => Task 8, Epoch 154/170 => Loss 3.986, Train_accy 68.330, Test_accy 44.060
2022-11-28 22:38:59,936 [bic.py] => bias_correction => Task 8, Epoch 155/170 => Loss 3.968, Train_accy 72.780, Test_accy 44.070
2022-11-28 22:39:04,386 [bic.py] => bias_correction => Task 8, Epoch 156/170 => Loss 3.931, Train_accy 67.780, Test_accy 43.960
2022-11-28 22:39:08,586 [bic.py] => bias_correction => Task 8, Epoch 157/170 => Loss 3.989, Train_accy 67.780, Test_accy 44.010
2022-11-28 22:39:13,095 [bic.py] => bias_correction => Task 8, Epoch 158/170 => Loss 4.013, Train_accy 68.890, Test_accy 44.060
2022-11-28 22:39:17,309 [bic.py] => bias_correction => Task 8, Epoch 159/170 => Loss 3.971, Train_accy 69.440, Test_accy 43.870
2022-11-28 22:39:21,761 [bic.py] => bias_correction => Task 8, Epoch 160/170 => Loss 3.970, Train_accy 68.890, Test_accy 43.800
2022-11-28 22:39:26,122 [bic.py] => bias_correction => Task 8, Epoch 161/170 => Loss 3.980, Train_accy 70.000, Test_accy 44.110
2022-11-28 22:39:30,399 [bic.py] => bias_correction => Task 8, Epoch 162/170 => Loss 3.981, Train_accy 70.560, Test_accy 43.840
2022-11-28 22:39:34,838 [bic.py] => bias_correction => Task 8, Epoch 163/170 => Loss 3.971, Train_accy 68.890, Test_accy 43.880
2022-11-28 22:39:39,244 [bic.py] => bias_correction => Task 8, Epoch 164/170 => Loss 3.981, Train_accy 69.440, Test_accy 43.940
2022-11-28 22:39:43,428 [bic.py] => bias_correction => Task 8, Epoch 165/170 => Loss 3.960, Train_accy 71.670, Test_accy 44.290
2022-11-28 22:39:48,143 [bic.py] => bias_correction => Task 8, Epoch 166/170 => Loss 3.993, Train_accy 68.890, Test_accy 44.360
2022-11-28 22:39:52,843 [bic.py] => bias_correction => Task 8, Epoch 167/170 => Loss 3.960, Train_accy 71.110, Test_accy 44.440
2022-11-28 22:39:57,211 [bic.py] => bias_correction => Task 8, Epoch 168/170 => Loss 3.952, Train_accy 69.440, Test_accy 44.410
2022-11-28 22:40:01,783 [bic.py] => bias_correction => Task 8, Epoch 169/170 => Loss 4.002, Train_accy 69.440, Test_accy 44.560
2022-11-28 22:40:06,264 [bic.py] => bias_correction => Task 8, Epoch 170/170 => Loss 3.971, Train_accy 69.440, Test_accy 44.210
2022-11-28 22:40:06,267 [base.py] => Reducing exemplars...(22 per classes)
2022-11-28 22:40:39,569 [base.py] => Constructing exemplars...(22 per classes)
2022-11-28 22:40:48,658 [bic.py] => Parameters of bias layer:
2022-11-28 22:40:48,659 [bic.py] => 0 => 1.000, 0.000
2022-11-28 22:40:48,659 [bic.py] => 1 => 0.976, -1.640
2022-11-28 22:40:48,659 [bic.py] => 2 => 0.847, -1.789
2022-11-28 22:40:48,659 [bic.py] => 3 => 0.728, -1.453
2022-11-28 22:40:48,659 [bic.py] => 4 => 0.739, -1.271
2022-11-28 22:40:48,659 [bic.py] => 5 => 0.788, -1.449
2022-11-28 22:40:48,659 [bic.py] => 6 => 0.727, -1.396
2022-11-28 22:40:48,659 [bic.py] => 7 => -0.032, -0.821
2022-11-28 22:40:48,659 [bic.py] => 8 => 0.057, -0.685
2022-11-28 22:40:51,152 [bic.py] => Exemplar size: 1980
2022-11-28 22:40:51,152 [trainer.py] => CNN: {'total': 44.21, '00-09': 62.5, '10-19': 49.9, '20-29': 62.4, '30-39': 47.6, '40-49': 61.0, '50-59': 55.7, '60-69': 58.8, '70-79': 0.0, '80-89': 0.0, 'old': 49.74, 'new': 0.0}
2022-11-28 22:40:51,152 [trainer.py] => NME: {'total': 51.04, '00-09': 51.4, '10-19': 34.4, '20-29': 51.7, '30-39': 44.0, '40-49': 56.5, '50-59': 46.1, '60-69': 55.9, '70-79': 52.8, '80-89': 66.6, 'old': 49.1, 'new': 66.6}
2022-11-28 22:40:51,153 [trainer.py] => CNN top1 curve: [88.7, 75.6, 72.3, 66.6, 64.42, 60.9, 58.66, 50.71, 44.21]
2022-11-28 22:40:51,153 [trainer.py] => CNN top5 curve: [99.4, 95.6, 93.5, 91.42, 90.66, 87.9, 85.69, 74.16, 65.03]
2022-11-28 22:40:51,153 [trainer.py] => NME top1 curve: [88.5, 75.85, 72.47, 66.72, 64.22, 60.88, 58.87, 55.1, 51.04]
2022-11-28 22:40:51,153 [trainer.py] => NME top5 curve: [99.4, 95.95, 93.8, 91.2, 89.16, 86.13, 84.11, 81.74, 77.67]

2022-11-28 22:40:51,153 [trainer.py] => All params: 470022
2022-11-28 22:40:51,153 [trainer.py] => Trainable params: 470022
2022-11-28 22:40:51,154 [bic.py] => Learning on 90-100
2022-11-28 22:40:51,192 [bic.py] => Stage1 dset: 6780, Stage2 dset: 200
2022-11-28 22:40:51,192 [bic.py] => Lambda: 0.900
2022-11-28 22:40:51,213 [bic.py] => Parameters of bias layer:
2022-11-28 22:40:51,213 [bic.py] => 0 => 1.000, 0.000
2022-11-28 22:40:51,213 [bic.py] => 1 => 0.976, -1.640
2022-11-28 22:40:51,214 [bic.py] => 2 => 0.847, -1.789
2022-11-28 22:40:51,214 [bic.py] => 3 => 0.728, -1.453
2022-11-28 22:40:51,214 [bic.py] => 4 => 0.739, -1.271
2022-11-28 22:40:51,214 [bic.py] => 5 => 0.788, -1.449
2022-11-28 22:40:51,214 [bic.py] => 6 => 0.727, -1.396
2022-11-28 22:40:51,214 [bic.py] => 7 => -0.032, -0.821
2022-11-28 22:40:51,214 [bic.py] => 8 => 0.057, -0.685
2022-11-28 22:40:51,214 [bic.py] => 9 => 1.000, 0.000
2022-11-28 22:41:00,866 [bic.py] => training => Task 9, Epoch 1/170 => Loss 3.315, Train_accy 58.410, Test_accy 26.340
2022-11-28 22:41:11,094 [bic.py] => training => Task 9, Epoch 2/170 => Loss 3.273, Train_accy 65.090, Test_accy 29.270
2022-11-28 22:41:21,405 [bic.py] => training => Task 9, Epoch 3/170 => Loss 3.261, Train_accy 70.560, Test_accy 32.870
2022-11-28 22:41:31,775 [bic.py] => training => Task 9, Epoch 4/170 => Loss 3.239, Train_accy 71.650, Test_accy 32.190
2022-11-28 22:41:41,441 [bic.py] => training => Task 9, Epoch 5/170 => Loss 3.227, Train_accy 70.930, Test_accy 29.760
2022-11-28 22:41:51,369 [bic.py] => training => Task 9, Epoch 6/170 => Loss 3.229, Train_accy 71.210, Test_accy 30.870
2022-11-28 22:42:01,326 [bic.py] => training => Task 9, Epoch 7/170 => Loss 3.225, Train_accy 76.400, Test_accy 31.970
2022-11-28 22:42:10,549 [bic.py] => training => Task 9, Epoch 8/170 => Loss 3.212, Train_accy 75.280, Test_accy 33.880
2022-11-28 22:42:19,641 [bic.py] => training => Task 9, Epoch 9/170 => Loss 3.211, Train_accy 76.490, Test_accy 32.300
2022-11-28 22:42:29,441 [bic.py] => training => Task 9, Epoch 10/170 => Loss 3.205, Train_accy 78.200, Test_accy 31.380
2022-11-28 22:42:39,122 [bic.py] => training => Task 9, Epoch 11/170 => Loss 3.204, Train_accy 78.440, Test_accy 32.550
2022-11-28 22:42:48,521 [bic.py] => training => Task 9, Epoch 12/170 => Loss 3.203, Train_accy 78.020, Test_accy 33.730
2022-11-28 22:42:58,518 [bic.py] => training => Task 9, Epoch 13/170 => Loss 3.203, Train_accy 76.810, Test_accy 34.520
2022-11-28 22:43:07,712 [bic.py] => training => Task 9, Epoch 14/170 => Loss 3.202, Train_accy 78.110, Test_accy 31.480
2022-11-28 22:43:17,628 [bic.py] => training => Task 9, Epoch 15/170 => Loss 3.201, Train_accy 77.820, Test_accy 30.050
2022-11-28 22:43:27,284 [bic.py] => training => Task 9, Epoch 16/170 => Loss 3.200, Train_accy 79.230, Test_accy 31.470
2022-11-28 22:43:36,825 [bic.py] => training => Task 9, Epoch 17/170 => Loss 3.199, Train_accy 81.050, Test_accy 32.010
2022-11-28 22:43:46,782 [bic.py] => training => Task 9, Epoch 18/170 => Loss 3.194, Train_accy 79.630, Test_accy 33.390
2022-11-28 22:43:56,337 [bic.py] => training => Task 9, Epoch 19/170 => Loss 3.190, Train_accy 81.950, Test_accy 33.590
2022-11-28 22:44:06,450 [bic.py] => training => Task 9, Epoch 20/170 => Loss 3.197, Train_accy 82.020, Test_accy 33.050
2022-11-28 22:44:16,090 [bic.py] => training => Task 9, Epoch 21/170 => Loss 3.190, Train_accy 80.500, Test_accy 32.310
2022-11-28 22:44:25,863 [bic.py] => training => Task 9, Epoch 22/170 => Loss 3.201, Train_accy 78.980, Test_accy 34.170
2022-11-28 22:44:35,279 [bic.py] => training => Task 9, Epoch 23/170 => Loss 3.200, Train_accy 80.740, Test_accy 32.910
2022-11-28 22:44:45,464 [bic.py] => training => Task 9, Epoch 24/170 => Loss 3.195, Train_accy 81.090, Test_accy 33.530
2022-11-28 22:44:55,563 [bic.py] => training => Task 9, Epoch 25/170 => Loss 3.197, Train_accy 82.400, Test_accy 35.040
2022-11-28 22:45:04,920 [bic.py] => training => Task 9, Epoch 26/170 => Loss 3.194, Train_accy 82.600, Test_accy 33.170
2022-11-28 22:45:13,903 [bic.py] => training => Task 9, Epoch 27/170 => Loss 3.188, Train_accy 80.270, Test_accy 31.230
2022-11-28 22:45:24,270 [bic.py] => training => Task 9, Epoch 28/170 => Loss 3.190, Train_accy 82.420, Test_accy 31.540
2022-11-28 22:45:33,728 [bic.py] => training => Task 9, Epoch 29/170 => Loss 3.187, Train_accy 84.160, Test_accy 32.280
2022-11-28 22:45:43,149 [bic.py] => training => Task 9, Epoch 30/170 => Loss 3.185, Train_accy 83.610, Test_accy 32.030
2022-11-28 22:45:52,706 [bic.py] => training => Task 9, Epoch 31/170 => Loss 3.184, Train_accy 83.510, Test_accy 32.400
2022-11-28 22:46:03,048 [bic.py] => training => Task 9, Epoch 32/170 => Loss 3.185, Train_accy 85.070, Test_accy 33.350
2022-11-28 22:46:12,664 [bic.py] => training => Task 9, Epoch 33/170 => Loss 3.185, Train_accy 83.820, Test_accy 33.340
2022-11-28 22:46:22,211 [bic.py] => training => Task 9, Epoch 34/170 => Loss 3.181, Train_accy 81.920, Test_accy 35.140
2022-11-28 22:46:31,813 [bic.py] => training => Task 9, Epoch 35/170 => Loss 3.187, Train_accy 82.120, Test_accy 31.850
2022-11-28 22:46:41,214 [bic.py] => training => Task 9, Epoch 36/170 => Loss 3.195, Train_accy 83.580, Test_accy 33.880
2022-11-28 22:46:50,252 [bic.py] => training => Task 9, Epoch 37/170 => Loss 3.187, Train_accy 81.700, Test_accy 32.090
2022-11-28 22:47:00,227 [bic.py] => training => Task 9, Epoch 38/170 => Loss 3.184, Train_accy 84.310, Test_accy 33.750
2022-11-28 22:47:09,789 [bic.py] => training => Task 9, Epoch 39/170 => Loss 3.179, Train_accy 84.870, Test_accy 33.550
2022-11-28 22:47:19,269 [bic.py] => training => Task 9, Epoch 40/170 => Loss 3.173, Train_accy 84.030, Test_accy 33.870
2022-11-28 22:47:28,901 [bic.py] => training => Task 9, Epoch 41/170 => Loss 3.180, Train_accy 85.290, Test_accy 33.910
2022-11-28 22:47:38,115 [bic.py] => training => Task 9, Epoch 42/170 => Loss 3.184, Train_accy 85.680, Test_accy 33.180
2022-11-28 22:47:47,180 [bic.py] => training => Task 9, Epoch 43/170 => Loss 3.180, Train_accy 85.250, Test_accy 31.520
2022-11-28 22:47:57,562 [bic.py] => training => Task 9, Epoch 44/170 => Loss 3.183, Train_accy 85.040, Test_accy 32.000
2022-11-28 22:48:07,059 [bic.py] => training => Task 9, Epoch 45/170 => Loss 3.179, Train_accy 84.100, Test_accy 32.050
2022-11-28 22:48:16,784 [bic.py] => training => Task 9, Epoch 46/170 => Loss 3.171, Train_accy 85.030, Test_accy 32.480
2022-11-28 22:48:26,574 [bic.py] => training => Task 9, Epoch 47/170 => Loss 3.174, Train_accy 82.630, Test_accy 31.810
2022-11-28 22:48:35,980 [bic.py] => training => Task 9, Epoch 48/170 => Loss 3.176, Train_accy 86.220, Test_accy 32.730
2022-11-28 22:48:45,632 [bic.py] => training => Task 9, Epoch 49/170 => Loss 3.176, Train_accy 84.880, Test_accy 33.530
2022-11-28 22:48:56,014 [bic.py] => training => Task 9, Epoch 50/170 => Loss 3.181, Train_accy 86.120, Test_accy 33.690
2022-11-28 22:49:05,295 [bic.py] => training => Task 9, Epoch 51/170 => Loss 3.175, Train_accy 84.030, Test_accy 31.210
2022-11-28 22:49:15,497 [bic.py] => training => Task 9, Epoch 52/170 => Loss 3.183, Train_accy 85.930, Test_accy 33.420
2022-11-28 22:49:25,329 [bic.py] => training => Task 9, Epoch 53/170 => Loss 3.179, Train_accy 85.750, Test_accy 31.780
2022-11-28 22:49:35,004 [bic.py] => training => Task 9, Epoch 54/170 => Loss 3.178, Train_accy 83.570, Test_accy 32.570
2022-11-28 22:49:44,597 [bic.py] => training => Task 9, Epoch 55/170 => Loss 3.174, Train_accy 87.450, Test_accy 35.360
2022-11-28 22:49:54,535 [bic.py] => training => Task 9, Epoch 56/170 => Loss 3.175, Train_accy 86.420, Test_accy 33.020
2022-11-28 22:50:04,290 [bic.py] => training => Task 9, Epoch 57/170 => Loss 3.175, Train_accy 85.430, Test_accy 32.280
2022-11-28 22:50:13,726 [bic.py] => training => Task 9, Epoch 58/170 => Loss 3.177, Train_accy 82.650, Test_accy 33.080
2022-11-28 22:50:23,727 [bic.py] => training => Task 9, Epoch 59/170 => Loss 3.168, Train_accy 84.340, Test_accy 34.220
2022-11-28 22:50:33,313 [bic.py] => training => Task 9, Epoch 60/170 => Loss 3.182, Train_accy 83.830, Test_accy 29.770
2022-11-28 22:50:43,418 [bic.py] => training => Task 9, Epoch 61/170 => Loss 3.151, Train_accy 91.500, Test_accy 37.680
2022-11-28 22:50:53,056 [bic.py] => training => Task 9, Epoch 62/170 => Loss 3.134, Train_accy 92.060, Test_accy 37.990
2022-11-28 22:51:02,784 [bic.py] => training => Task 9, Epoch 63/170 => Loss 3.137, Train_accy 92.450, Test_accy 37.940
2022-11-28 22:51:12,966 [bic.py] => training => Task 9, Epoch 64/170 => Loss 3.137, Train_accy 92.480, Test_accy 39.160
2022-11-28 22:51:22,431 [bic.py] => training => Task 9, Epoch 65/170 => Loss 3.134, Train_accy 92.570, Test_accy 38.510
2022-11-28 22:51:31,998 [bic.py] => training => Task 9, Epoch 66/170 => Loss 3.130, Train_accy 92.710, Test_accy 38.060
2022-11-28 22:51:41,719 [bic.py] => training => Task 9, Epoch 67/170 => Loss 3.128, Train_accy 92.760, Test_accy 38.050
2022-11-28 22:51:51,323 [bic.py] => training => Task 9, Epoch 68/170 => Loss 3.129, Train_accy 92.770, Test_accy 38.340
2022-11-28 22:52:00,808 [bic.py] => training => Task 9, Epoch 69/170 => Loss 3.128, Train_accy 92.850, Test_accy 38.090
2022-11-28 22:52:10,358 [bic.py] => training => Task 9, Epoch 70/170 => Loss 3.130, Train_accy 92.770, Test_accy 38.630
2022-11-28 22:52:20,358 [bic.py] => training => Task 9, Epoch 71/170 => Loss 3.126, Train_accy 92.920, Test_accy 38.490
2022-11-28 22:52:30,282 [bic.py] => training => Task 9, Epoch 72/170 => Loss 3.117, Train_accy 92.950, Test_accy 38.270
2022-11-28 22:52:39,967 [bic.py] => training => Task 9, Epoch 73/170 => Loss 3.122, Train_accy 93.070, Test_accy 37.980
2022-11-28 22:52:49,709 [bic.py] => training => Task 9, Epoch 74/170 => Loss 3.128, Train_accy 92.760, Test_accy 38.030
2022-11-28 22:53:00,241 [bic.py] => training => Task 9, Epoch 75/170 => Loss 3.122, Train_accy 92.960, Test_accy 38.800
2022-11-28 22:53:09,645 [bic.py] => training => Task 9, Epoch 76/170 => Loss 3.130, Train_accy 93.020, Test_accy 37.980
2022-11-28 22:53:19,193 [bic.py] => training => Task 9, Epoch 77/170 => Loss 3.125, Train_accy 93.010, Test_accy 38.680
2022-11-28 22:53:28,696 [bic.py] => training => Task 9, Epoch 78/170 => Loss 3.122, Train_accy 92.880, Test_accy 38.470
2022-11-28 22:53:37,986 [bic.py] => training => Task 9, Epoch 79/170 => Loss 3.123, Train_accy 93.270, Test_accy 38.220
2022-11-28 22:53:47,754 [bic.py] => training => Task 9, Epoch 80/170 => Loss 3.129, Train_accy 93.420, Test_accy 39.020
2022-11-28 22:53:57,370 [bic.py] => training => Task 9, Epoch 81/170 => Loss 3.124, Train_accy 93.160, Test_accy 38.300
2022-11-28 22:54:06,869 [bic.py] => training => Task 9, Epoch 82/170 => Loss 3.124, Train_accy 93.300, Test_accy 38.250
2022-11-28 22:54:16,598 [bic.py] => training => Task 9, Epoch 83/170 => Loss 3.125, Train_accy 93.230, Test_accy 38.060
2022-11-28 22:54:25,913 [bic.py] => training => Task 9, Epoch 84/170 => Loss 3.119, Train_accy 93.160, Test_accy 38.100
2022-11-28 22:54:35,388 [bic.py] => training => Task 9, Epoch 85/170 => Loss 3.125, Train_accy 93.140, Test_accy 38.140
2022-11-28 22:54:45,966 [bic.py] => training => Task 9, Epoch 86/170 => Loss 3.118, Train_accy 93.260, Test_accy 38.260
2022-11-28 22:54:56,772 [bic.py] => training => Task 9, Epoch 87/170 => Loss 3.129, Train_accy 93.300, Test_accy 38.590
2022-11-28 22:55:06,389 [bic.py] => training => Task 9, Epoch 88/170 => Loss 3.116, Train_accy 93.260, Test_accy 38.650
2022-11-28 22:55:15,759 [bic.py] => training => Task 9, Epoch 89/170 => Loss 3.119, Train_accy 93.330, Test_accy 38.630
2022-11-28 22:55:25,477 [bic.py] => training => Task 9, Epoch 90/170 => Loss 3.120, Train_accy 93.290, Test_accy 38.460
2022-11-28 22:55:34,755 [bic.py] => training => Task 9, Epoch 91/170 => Loss 3.120, Train_accy 93.240, Test_accy 38.240
2022-11-28 22:55:44,394 [bic.py] => training => Task 9, Epoch 92/170 => Loss 3.118, Train_accy 93.500, Test_accy 38.140
2022-11-28 22:55:54,211 [bic.py] => training => Task 9, Epoch 93/170 => Loss 3.120, Train_accy 93.470, Test_accy 37.150
2022-11-28 22:56:03,804 [bic.py] => training => Task 9, Epoch 94/170 => Loss 3.119, Train_accy 93.350, Test_accy 38.620
2022-11-28 22:56:13,595 [bic.py] => training => Task 9, Epoch 95/170 => Loss 3.120, Train_accy 93.350, Test_accy 38.640
2022-11-28 22:56:23,824 [bic.py] => training => Task 9, Epoch 96/170 => Loss 3.122, Train_accy 93.470, Test_accy 38.820
2022-11-28 22:56:33,264 [bic.py] => training => Task 9, Epoch 97/170 => Loss 3.116, Train_accy 93.230, Test_accy 37.640
2022-11-28 22:56:43,152 [bic.py] => training => Task 9, Epoch 98/170 => Loss 3.122, Train_accy 93.390, Test_accy 38.740
2022-11-28 22:56:52,926 [bic.py] => training => Task 9, Epoch 99/170 => Loss 3.120, Train_accy 93.600, Test_accy 37.990
2022-11-28 22:57:02,694 [bic.py] => training => Task 9, Epoch 100/170 => Loss 3.120, Train_accy 93.480, Test_accy 38.940
2022-11-28 22:57:12,433 [bic.py] => training => Task 9, Epoch 101/170 => Loss 3.114, Train_accy 93.410, Test_accy 38.140
2022-11-28 22:57:22,411 [bic.py] => training => Task 9, Epoch 102/170 => Loss 3.117, Train_accy 93.450, Test_accy 38.400
2022-11-28 22:57:31,974 [bic.py] => training => Task 9, Epoch 103/170 => Loss 3.120, Train_accy 93.510, Test_accy 38.320
2022-11-28 22:57:41,106 [bic.py] => training => Task 9, Epoch 104/170 => Loss 3.115, Train_accy 93.600, Test_accy 38.580
2022-11-28 22:57:50,678 [bic.py] => training => Task 9, Epoch 105/170 => Loss 3.122, Train_accy 93.390, Test_accy 39.070
2022-11-28 22:58:00,844 [bic.py] => training => Task 9, Epoch 106/170 => Loss 3.113, Train_accy 93.480, Test_accy 38.470
2022-11-28 22:58:10,918 [bic.py] => training => Task 9, Epoch 107/170 => Loss 3.120, Train_accy 93.550, Test_accy 38.610
2022-11-28 22:58:20,182 [bic.py] => training => Task 9, Epoch 108/170 => Loss 3.124, Train_accy 93.450, Test_accy 38.760
2022-11-28 22:58:30,379 [bic.py] => training => Task 9, Epoch 109/170 => Loss 3.118, Train_accy 93.470, Test_accy 38.510
2022-11-28 22:58:39,807 [bic.py] => training => Task 9, Epoch 110/170 => Loss 3.117, Train_accy 93.380, Test_accy 38.630
2022-11-28 22:58:50,205 [bic.py] => training => Task 9, Epoch 111/170 => Loss 3.118, Train_accy 93.540, Test_accy 38.790
2022-11-28 22:59:00,393 [bic.py] => training => Task 9, Epoch 112/170 => Loss 3.121, Train_accy 93.350, Test_accy 38.060
2022-11-28 22:59:10,013 [bic.py] => training => Task 9, Epoch 113/170 => Loss 3.120, Train_accy 93.600, Test_accy 39.060
2022-11-28 22:59:19,369 [bic.py] => training => Task 9, Epoch 114/170 => Loss 3.119, Train_accy 93.670, Test_accy 38.540
2022-11-28 22:59:29,599 [bic.py] => training => Task 9, Epoch 115/170 => Loss 3.121, Train_accy 93.540, Test_accy 38.940
2022-11-28 22:59:39,008 [bic.py] => training => Task 9, Epoch 116/170 => Loss 3.110, Train_accy 93.530, Test_accy 39.000
2022-11-28 22:59:48,773 [bic.py] => training => Task 9, Epoch 117/170 => Loss 3.117, Train_accy 93.580, Test_accy 38.600
2022-11-28 22:59:58,783 [bic.py] => training => Task 9, Epoch 118/170 => Loss 3.118, Train_accy 93.550, Test_accy 38.150
2022-11-28 23:00:08,735 [bic.py] => training => Task 9, Epoch 119/170 => Loss 3.113, Train_accy 93.510, Test_accy 38.350
2022-11-28 23:00:18,063 [bic.py] => training => Task 9, Epoch 120/170 => Loss 3.114, Train_accy 93.660, Test_accy 38.420
2022-11-28 23:00:27,901 [bic.py] => training => Task 9, Epoch 121/170 => Loss 3.122, Train_accy 93.500, Test_accy 38.310
2022-11-28 23:00:37,586 [bic.py] => training => Task 9, Epoch 122/170 => Loss 3.122, Train_accy 93.550, Test_accy 38.690
2022-11-28 23:00:47,015 [bic.py] => training => Task 9, Epoch 123/170 => Loss 3.113, Train_accy 93.500, Test_accy 38.650
2022-11-28 23:00:56,605 [bic.py] => training => Task 9, Epoch 124/170 => Loss 3.117, Train_accy 93.540, Test_accy 38.320
2022-11-28 23:01:06,689 [bic.py] => training => Task 9, Epoch 125/170 => Loss 3.117, Train_accy 93.440, Test_accy 38.970
2022-11-28 23:01:16,261 [bic.py] => training => Task 9, Epoch 126/170 => Loss 3.119, Train_accy 93.630, Test_accy 38.340
2022-11-28 23:01:25,656 [bic.py] => training => Task 9, Epoch 127/170 => Loss 3.119, Train_accy 93.540, Test_accy 38.700
2022-11-28 23:01:34,994 [bic.py] => training => Task 9, Epoch 128/170 => Loss 3.119, Train_accy 93.510, Test_accy 38.790
2022-11-28 23:01:44,596 [bic.py] => training => Task 9, Epoch 129/170 => Loss 3.122, Train_accy 93.610, Test_accy 38.890
2022-11-28 23:01:54,086 [bic.py] => training => Task 9, Epoch 130/170 => Loss 3.118, Train_accy 93.570, Test_accy 38.400
2022-11-28 23:02:03,863 [bic.py] => training => Task 9, Epoch 131/170 => Loss 3.122, Train_accy 93.600, Test_accy 38.370
2022-11-28 23:02:13,148 [bic.py] => training => Task 9, Epoch 132/170 => Loss 3.113, Train_accy 93.570, Test_accy 38.540
2022-11-28 23:02:23,870 [bic.py] => training => Task 9, Epoch 133/170 => Loss 3.119, Train_accy 93.570, Test_accy 38.230
2022-11-28 23:02:33,558 [bic.py] => training => Task 9, Epoch 134/170 => Loss 3.111, Train_accy 93.610, Test_accy 38.820
2022-11-28 23:02:43,084 [bic.py] => training => Task 9, Epoch 135/170 => Loss 3.123, Train_accy 93.530, Test_accy 38.370
2022-11-28 23:02:53,510 [bic.py] => training => Task 9, Epoch 136/170 => Loss 3.118, Train_accy 93.360, Test_accy 37.820
2022-11-28 23:03:03,145 [bic.py] => training => Task 9, Epoch 137/170 => Loss 3.118, Train_accy 93.670, Test_accy 38.110
2022-11-28 23:03:12,366 [bic.py] => training => Task 9, Epoch 138/170 => Loss 3.121, Train_accy 93.530, Test_accy 38.860
2022-11-28 23:03:21,920 [bic.py] => training => Task 9, Epoch 139/170 => Loss 3.111, Train_accy 93.660, Test_accy 38.650
2022-11-28 23:03:31,578 [bic.py] => training => Task 9, Epoch 140/170 => Loss 3.118, Train_accy 93.690, Test_accy 38.900
2022-11-28 23:03:40,755 [bic.py] => training => Task 9, Epoch 141/170 => Loss 3.123, Train_accy 93.700, Test_accy 38.250
2022-11-28 23:03:50,575 [bic.py] => training => Task 9, Epoch 142/170 => Loss 3.117, Train_accy 93.610, Test_accy 38.930
2022-11-28 23:04:00,239 [bic.py] => training => Task 9, Epoch 143/170 => Loss 3.121, Train_accy 93.610, Test_accy 38.370
2022-11-28 23:04:09,962 [bic.py] => training => Task 9, Epoch 144/170 => Loss 3.119, Train_accy 93.540, Test_accy 38.440
2022-11-28 23:04:19,433 [bic.py] => training => Task 9, Epoch 145/170 => Loss 3.114, Train_accy 93.550, Test_accy 38.490
2022-11-28 23:04:29,062 [bic.py] => training => Task 9, Epoch 146/170 => Loss 3.119, Train_accy 93.570, Test_accy 38.260
2022-11-28 23:04:39,056 [bic.py] => training => Task 9, Epoch 147/170 => Loss 3.120, Train_accy 93.500, Test_accy 38.510
2022-11-28 23:04:48,523 [bic.py] => training => Task 9, Epoch 148/170 => Loss 3.123, Train_accy 93.570, Test_accy 38.910
2022-11-28 23:04:58,333 [bic.py] => training => Task 9, Epoch 149/170 => Loss 3.118, Train_accy 93.550, Test_accy 38.370
2022-11-28 23:05:07,938 [bic.py] => training => Task 9, Epoch 150/170 => Loss 3.113, Train_accy 93.670, Test_accy 38.280
2022-11-28 23:05:17,982 [bic.py] => training => Task 9, Epoch 151/170 => Loss 3.115, Train_accy 93.450, Test_accy 38.790
2022-11-28 23:05:27,379 [bic.py] => training => Task 9, Epoch 152/170 => Loss 3.127, Train_accy 93.570, Test_accy 38.960
2022-11-28 23:05:36,892 [bic.py] => training => Task 9, Epoch 153/170 => Loss 3.115, Train_accy 93.530, Test_accy 38.740
2022-11-28 23:05:46,578 [bic.py] => training => Task 9, Epoch 154/170 => Loss 3.117, Train_accy 93.580, Test_accy 38.770
2022-11-28 23:05:56,339 [bic.py] => training => Task 9, Epoch 155/170 => Loss 3.120, Train_accy 93.540, Test_accy 38.430
2022-11-28 23:06:05,681 [bic.py] => training => Task 9, Epoch 156/170 => Loss 3.111, Train_accy 93.550, Test_accy 38.720
2022-11-28 23:06:15,488 [bic.py] => training => Task 9, Epoch 157/170 => Loss 3.114, Train_accy 93.570, Test_accy 38.360
2022-11-28 23:06:25,146 [bic.py] => training => Task 9, Epoch 158/170 => Loss 3.117, Train_accy 93.660, Test_accy 38.590
2022-11-28 23:06:34,550 [bic.py] => training => Task 9, Epoch 159/170 => Loss 3.113, Train_accy 93.540, Test_accy 38.260
2022-11-28 23:06:43,886 [bic.py] => training => Task 9, Epoch 160/170 => Loss 3.117, Train_accy 93.440, Test_accy 38.640
2022-11-28 23:06:53,988 [bic.py] => training => Task 9, Epoch 161/170 => Loss 3.113, Train_accy 93.720, Test_accy 38.710
2022-11-28 23:07:03,916 [bic.py] => training => Task 9, Epoch 162/170 => Loss 3.120, Train_accy 93.390, Test_accy 38.170
2022-11-28 23:07:13,392 [bic.py] => training => Task 9, Epoch 163/170 => Loss 3.114, Train_accy 93.530, Test_accy 38.170
2022-11-28 23:07:23,295 [bic.py] => training => Task 9, Epoch 164/170 => Loss 3.118, Train_accy 93.440, Test_accy 38.570
2022-11-28 23:07:33,381 [bic.py] => training => Task 9, Epoch 165/170 => Loss 3.116, Train_accy 93.500, Test_accy 38.360
2022-11-28 23:07:42,532 [bic.py] => training => Task 9, Epoch 166/170 => Loss 3.117, Train_accy 93.530, Test_accy 38.910
2022-11-28 23:07:52,435 [bic.py] => training => Task 9, Epoch 167/170 => Loss 3.117, Train_accy 93.640, Test_accy 38.680
2022-11-28 23:08:02,207 [bic.py] => training => Task 9, Epoch 168/170 => Loss 3.116, Train_accy 93.570, Test_accy 38.850
2022-11-28 23:08:11,740 [bic.py] => training => Task 9, Epoch 169/170 => Loss 3.118, Train_accy 93.610, Test_accy 38.530
2022-11-28 23:08:21,068 [bic.py] => training => Task 9, Epoch 170/170 => Loss 3.117, Train_accy 93.600, Test_accy 38.330
2022-11-28 23:08:25,607 [bic.py] => bias_correction => Task 9, Epoch 1/170 => Loss 4.192, Train_accy 62.000, Test_accy 39.570
2022-11-28 23:08:29,957 [bic.py] => bias_correction => Task 9, Epoch 2/170 => Loss 4.177, Train_accy 63.500, Test_accy 42.850
2022-11-28 23:08:34,598 [bic.py] => bias_correction => Task 9, Epoch 3/170 => Loss 4.133, Train_accy 67.500, Test_accy 44.500
2022-11-28 23:08:39,595 [bic.py] => bias_correction => Task 9, Epoch 4/170 => Loss 4.135, Train_accy 67.500, Test_accy 42.490
2022-11-28 23:08:44,440 [bic.py] => bias_correction => Task 9, Epoch 5/170 => Loss 4.140, Train_accy 66.500, Test_accy 40.990
2022-11-28 23:08:48,972 [bic.py] => bias_correction => Task 9, Epoch 6/170 => Loss 4.123, Train_accy 66.000, Test_accy 40.620
2022-11-28 23:08:53,901 [bic.py] => bias_correction => Task 9, Epoch 7/170 => Loss 4.154, Train_accy 64.000, Test_accy 41.030
2022-11-28 23:08:58,675 [bic.py] => bias_correction => Task 9, Epoch 8/170 => Loss 4.146, Train_accy 68.500, Test_accy 42.430
2022-11-28 23:09:03,165 [bic.py] => bias_correction => Task 9, Epoch 9/170 => Loss 4.136, Train_accy 68.000, Test_accy 43.640
2022-11-28 23:09:07,930 [bic.py] => bias_correction => Task 9, Epoch 10/170 => Loss 4.119, Train_accy 64.500, Test_accy 43.970
2022-11-28 23:09:12,414 [bic.py] => bias_correction => Task 9, Epoch 11/170 => Loss 4.100, Train_accy 66.000, Test_accy 43.160
2022-11-28 23:09:16,791 [bic.py] => bias_correction => Task 9, Epoch 12/170 => Loss 4.135, Train_accy 67.500, Test_accy 42.970
2022-11-28 23:09:21,593 [bic.py] => bias_correction => Task 9, Epoch 13/170 => Loss 4.130, Train_accy 65.500, Test_accy 43.650
2022-11-28 23:09:26,058 [bic.py] => bias_correction => Task 9, Epoch 14/170 => Loss 4.123, Train_accy 67.500, Test_accy 43.810
2022-11-28 23:09:30,735 [bic.py] => bias_correction => Task 9, Epoch 15/170 => Loss 4.120, Train_accy 71.000, Test_accy 43.730
2022-11-28 23:09:35,585 [bic.py] => bias_correction => Task 9, Epoch 16/170 => Loss 4.114, Train_accy 71.500, Test_accy 43.450
2022-11-28 23:09:40,030 [bic.py] => bias_correction => Task 9, Epoch 17/170 => Loss 4.110, Train_accy 67.500, Test_accy 43.470
2022-11-28 23:09:44,767 [bic.py] => bias_correction => Task 9, Epoch 18/170 => Loss 4.109, Train_accy 67.500, Test_accy 43.760
2022-11-28 23:09:49,200 [bic.py] => bias_correction => Task 9, Epoch 19/170 => Loss 4.126, Train_accy 67.500, Test_accy 43.760
2022-11-28 23:09:54,155 [bic.py] => bias_correction => Task 9, Epoch 20/170 => Loss 4.129, Train_accy 67.000, Test_accy 43.670
2022-11-28 23:09:58,560 [bic.py] => bias_correction => Task 9, Epoch 21/170 => Loss 4.122, Train_accy 69.000, Test_accy 43.780
2022-11-28 23:10:03,520 [bic.py] => bias_correction => Task 9, Epoch 22/170 => Loss 4.106, Train_accy 66.500, Test_accy 43.800
2022-11-28 23:10:08,149 [bic.py] => bias_correction => Task 9, Epoch 23/170 => Loss 4.122, Train_accy 68.500, Test_accy 43.880
2022-11-28 23:10:12,649 [bic.py] => bias_correction => Task 9, Epoch 24/170 => Loss 4.125, Train_accy 67.500, Test_accy 44.060
2022-11-28 23:10:17,524 [bic.py] => bias_correction => Task 9, Epoch 25/170 => Loss 4.112, Train_accy 70.000, Test_accy 44.060
2022-11-28 23:10:22,080 [bic.py] => bias_correction => Task 9, Epoch 26/170 => Loss 4.113, Train_accy 70.000, Test_accy 44.170
2022-11-28 23:10:26,638 [bic.py] => bias_correction => Task 9, Epoch 27/170 => Loss 4.116, Train_accy 67.000, Test_accy 44.020
2022-11-28 23:10:31,055 [bic.py] => bias_correction => Task 9, Epoch 28/170 => Loss 4.118, Train_accy 67.000, Test_accy 43.940
2022-11-28 23:10:35,867 [bic.py] => bias_correction => Task 9, Epoch 29/170 => Loss 4.118, Train_accy 66.500, Test_accy 43.930
2022-11-28 23:10:40,425 [bic.py] => bias_correction => Task 9, Epoch 30/170 => Loss 4.115, Train_accy 67.500, Test_accy 43.990
2022-11-28 23:10:44,956 [bic.py] => bias_correction => Task 9, Epoch 31/170 => Loss 4.127, Train_accy 68.000, Test_accy 44.090
2022-11-28 23:10:49,828 [bic.py] => bias_correction => Task 9, Epoch 32/170 => Loss 4.096, Train_accy 67.000, Test_accy 44.020
2022-11-28 23:10:54,952 [bic.py] => bias_correction => Task 9, Epoch 33/170 => Loss 4.103, Train_accy 68.500, Test_accy 43.980
2022-11-28 23:10:59,787 [bic.py] => bias_correction => Task 9, Epoch 34/170 => Loss 4.108, Train_accy 69.500, Test_accy 44.050
2022-11-28 23:11:04,362 [bic.py] => bias_correction => Task 9, Epoch 35/170 => Loss 4.105, Train_accy 69.500, Test_accy 44.170
2022-11-28 23:11:08,988 [bic.py] => bias_correction => Task 9, Epoch 36/170 => Loss 4.120, Train_accy 67.500, Test_accy 44.090
2022-11-28 23:11:13,472 [bic.py] => bias_correction => Task 9, Epoch 37/170 => Loss 4.110, Train_accy 71.500, Test_accy 44.170
2022-11-28 23:11:18,540 [bic.py] => bias_correction => Task 9, Epoch 38/170 => Loss 4.098, Train_accy 69.000, Test_accy 44.080
2022-11-28 23:11:23,634 [bic.py] => bias_correction => Task 9, Epoch 39/170 => Loss 4.106, Train_accy 71.000, Test_accy 44.060
2022-11-28 23:11:28,149 [bic.py] => bias_correction => Task 9, Epoch 40/170 => Loss 4.112, Train_accy 67.500, Test_accy 43.930
2022-11-28 23:11:32,623 [bic.py] => bias_correction => Task 9, Epoch 41/170 => Loss 4.110, Train_accy 68.500, Test_accy 43.760
2022-11-28 23:11:37,311 [bic.py] => bias_correction => Task 9, Epoch 42/170 => Loss 4.115, Train_accy 67.000, Test_accy 43.690
2022-11-28 23:11:42,085 [bic.py] => bias_correction => Task 9, Epoch 43/170 => Loss 4.089, Train_accy 71.000, Test_accy 43.490
2022-11-28 23:11:46,968 [bic.py] => bias_correction => Task 9, Epoch 44/170 => Loss 4.108, Train_accy 66.500, Test_accy 43.470
2022-11-28 23:11:51,433 [bic.py] => bias_correction => Task 9, Epoch 45/170 => Loss 4.101, Train_accy 69.500, Test_accy 43.460
2022-11-28 23:11:56,289 [bic.py] => bias_correction => Task 9, Epoch 46/170 => Loss 4.128, Train_accy 69.000, Test_accy 43.650
2022-11-28 23:12:00,758 [bic.py] => bias_correction => Task 9, Epoch 47/170 => Loss 4.112, Train_accy 70.000, Test_accy 43.560
2022-11-28 23:12:05,243 [bic.py] => bias_correction => Task 9, Epoch 48/170 => Loss 4.130, Train_accy 67.000, Test_accy 43.620
2022-11-28 23:12:09,720 [bic.py] => bias_correction => Task 9, Epoch 49/170 => Loss 4.106, Train_accy 67.500, Test_accy 43.530
2022-11-28 23:12:14,358 [bic.py] => bias_correction => Task 9, Epoch 50/170 => Loss 4.102, Train_accy 68.000, Test_accy 43.760
2022-11-28 23:12:18,800 [bic.py] => bias_correction => Task 9, Epoch 51/170 => Loss 4.119, Train_accy 68.500, Test_accy 43.630
2022-11-28 23:12:23,668 [bic.py] => bias_correction => Task 9, Epoch 52/170 => Loss 4.107, Train_accy 67.000, Test_accy 43.630
2022-11-28 23:12:28,912 [bic.py] => bias_correction => Task 9, Epoch 53/170 => Loss 4.109, Train_accy 68.000, Test_accy 43.850
2022-11-28 23:12:33,967 [bic.py] => bias_correction => Task 9, Epoch 54/170 => Loss 4.116, Train_accy 69.500, Test_accy 44.130
2022-11-28 23:12:38,951 [bic.py] => bias_correction => Task 9, Epoch 55/170 => Loss 4.123, Train_accy 70.000, Test_accy 44.330
2022-11-28 23:12:43,197 [bic.py] => bias_correction => Task 9, Epoch 56/170 => Loss 4.102, Train_accy 69.500, Test_accy 44.260
2022-11-28 23:12:48,224 [bic.py] => bias_correction => Task 9, Epoch 57/170 => Loss 4.115, Train_accy 68.000, Test_accy 44.280
2022-11-28 23:12:52,516 [bic.py] => bias_correction => Task 9, Epoch 58/170 => Loss 4.117, Train_accy 69.000, Test_accy 44.090
2022-11-28 23:12:57,285 [bic.py] => bias_correction => Task 9, Epoch 59/170 => Loss 4.123, Train_accy 71.000, Test_accy 43.870
2022-11-28 23:13:01,978 [bic.py] => bias_correction => Task 9, Epoch 60/170 => Loss 4.104, Train_accy 69.000, Test_accy 43.910
2022-11-28 23:13:06,863 [bic.py] => bias_correction => Task 9, Epoch 61/170 => Loss 4.114, Train_accy 69.500, Test_accy 44.080
2022-11-28 23:13:11,295 [bic.py] => bias_correction => Task 9, Epoch 62/170 => Loss 4.132, Train_accy 70.000, Test_accy 44.130
2022-11-28 23:13:15,812 [bic.py] => bias_correction => Task 9, Epoch 63/170 => Loss 4.118, Train_accy 67.000, Test_accy 43.960
2022-11-28 23:13:20,306 [bic.py] => bias_correction => Task 9, Epoch 64/170 => Loss 4.109, Train_accy 67.000, Test_accy 44.090
2022-11-28 23:13:25,220 [bic.py] => bias_correction => Task 9, Epoch 65/170 => Loss 4.126, Train_accy 69.000, Test_accy 44.040
2022-11-28 23:13:30,082 [bic.py] => bias_correction => Task 9, Epoch 66/170 => Loss 4.115, Train_accy 68.500, Test_accy 43.950
2022-11-28 23:13:34,405 [bic.py] => bias_correction => Task 9, Epoch 67/170 => Loss 4.130, Train_accy 67.500, Test_accy 44.210
2022-11-28 23:13:38,977 [bic.py] => bias_correction => Task 9, Epoch 68/170 => Loss 4.093, Train_accy 70.000, Test_accy 44.370
2022-11-28 23:13:43,823 [bic.py] => bias_correction => Task 9, Epoch 69/170 => Loss 4.107, Train_accy 70.000, Test_accy 44.210
2022-11-28 23:13:48,516 [bic.py] => bias_correction => Task 9, Epoch 70/170 => Loss 4.104, Train_accy 68.000, Test_accy 44.130
2022-11-28 23:13:53,394 [bic.py] => bias_correction => Task 9, Epoch 71/170 => Loss 4.113, Train_accy 68.000, Test_accy 44.160
2022-11-28 23:13:58,353 [bic.py] => bias_correction => Task 9, Epoch 72/170 => Loss 4.103, Train_accy 67.500, Test_accy 43.940
2022-11-28 23:14:03,317 [bic.py] => bias_correction => Task 9, Epoch 73/170 => Loss 4.099, Train_accy 65.500, Test_accy 44.250
2022-11-28 23:14:08,274 [bic.py] => bias_correction => Task 9, Epoch 74/170 => Loss 4.098, Train_accy 68.000, Test_accy 44.090
2022-11-28 23:14:12,747 [bic.py] => bias_correction => Task 9, Epoch 75/170 => Loss 4.122, Train_accy 70.500, Test_accy 43.780
2022-11-28 23:14:17,823 [bic.py] => bias_correction => Task 9, Epoch 76/170 => Loss 4.122, Train_accy 69.000, Test_accy 43.560
2022-11-28 23:14:22,640 [bic.py] => bias_correction => Task 9, Epoch 77/170 => Loss 4.125, Train_accy 68.000, Test_accy 43.660
2022-11-28 23:14:27,344 [bic.py] => bias_correction => Task 9, Epoch 78/170 => Loss 4.103, Train_accy 67.000, Test_accy 43.880
2022-11-28 23:14:32,492 [bic.py] => bias_correction => Task 9, Epoch 79/170 => Loss 4.110, Train_accy 66.500, Test_accy 43.930
2022-11-28 23:14:37,081 [bic.py] => bias_correction => Task 9, Epoch 80/170 => Loss 4.122, Train_accy 68.500, Test_accy 44.000
2022-11-28 23:14:41,934 [bic.py] => bias_correction => Task 9, Epoch 81/170 => Loss 4.120, Train_accy 68.000, Test_accy 44.110
2022-11-28 23:14:46,443 [bic.py] => bias_correction => Task 9, Epoch 82/170 => Loss 4.131, Train_accy 67.000, Test_accy 43.930
2022-11-28 23:14:51,214 [bic.py] => bias_correction => Task 9, Epoch 83/170 => Loss 4.109, Train_accy 66.500, Test_accy 43.860
2022-11-28 23:14:55,695 [bic.py] => bias_correction => Task 9, Epoch 84/170 => Loss 4.096, Train_accy 67.000, Test_accy 43.420
2022-11-28 23:15:00,251 [bic.py] => bias_correction => Task 9, Epoch 85/170 => Loss 4.096, Train_accy 66.000, Test_accy 43.550
2022-11-28 23:15:04,653 [bic.py] => bias_correction => Task 9, Epoch 86/170 => Loss 4.111, Train_accy 67.000, Test_accy 43.660
2022-11-28 23:15:09,139 [bic.py] => bias_correction => Task 9, Epoch 87/170 => Loss 4.109, Train_accy 68.500, Test_accy 43.890
2022-11-28 23:15:13,799 [bic.py] => bias_correction => Task 9, Epoch 88/170 => Loss 4.110, Train_accy 67.500, Test_accy 43.810
2022-11-28 23:15:18,746 [bic.py] => bias_correction => Task 9, Epoch 89/170 => Loss 4.119, Train_accy 68.000, Test_accy 43.460
2022-11-28 23:15:23,987 [bic.py] => bias_correction => Task 9, Epoch 90/170 => Loss 4.103, Train_accy 67.000, Test_accy 43.550
2022-11-28 23:15:28,590 [bic.py] => bias_correction => Task 9, Epoch 91/170 => Loss 4.098, Train_accy 69.000, Test_accy 43.740
2022-11-28 23:15:33,182 [bic.py] => bias_correction => Task 9, Epoch 92/170 => Loss 4.120, Train_accy 68.000, Test_accy 43.730
2022-11-28 23:15:37,956 [bic.py] => bias_correction => Task 9, Epoch 93/170 => Loss 4.099, Train_accy 64.000, Test_accy 43.700
2022-11-28 23:15:42,590 [bic.py] => bias_correction => Task 9, Epoch 94/170 => Loss 4.117, Train_accy 68.500, Test_accy 43.650
2022-11-28 23:15:47,219 [bic.py] => bias_correction => Task 9, Epoch 95/170 => Loss 4.111, Train_accy 67.000, Test_accy 43.500
2022-11-28 23:15:51,757 [bic.py] => bias_correction => Task 9, Epoch 96/170 => Loss 4.104, Train_accy 66.500, Test_accy 43.330
2022-11-28 23:15:56,447 [bic.py] => bias_correction => Task 9, Epoch 97/170 => Loss 4.124, Train_accy 68.000, Test_accy 43.520
2022-11-28 23:16:00,744 [bic.py] => bias_correction => Task 9, Epoch 98/170 => Loss 4.106, Train_accy 67.500, Test_accy 43.360
2022-11-28 23:16:05,203 [bic.py] => bias_correction => Task 9, Epoch 99/170 => Loss 4.100, Train_accy 70.000, Test_accy 43.400
2022-11-28 23:16:09,675 [bic.py] => bias_correction => Task 9, Epoch 100/170 => Loss 4.100, Train_accy 65.500, Test_accy 43.500
2022-11-28 23:16:14,161 [bic.py] => bias_correction => Task 9, Epoch 101/170 => Loss 4.113, Train_accy 67.500, Test_accy 43.580
2022-11-28 23:16:18,753 [bic.py] => bias_correction => Task 9, Epoch 102/170 => Loss 4.111, Train_accy 67.000, Test_accy 43.520
2022-11-28 23:16:23,745 [bic.py] => bias_correction => Task 9, Epoch 103/170 => Loss 4.105, Train_accy 69.000, Test_accy 43.380
2022-11-28 23:16:28,320 [bic.py] => bias_correction => Task 9, Epoch 104/170 => Loss 4.108, Train_accy 66.500, Test_accy 43.480
2022-11-28 23:16:33,060 [bic.py] => bias_correction => Task 9, Epoch 105/170 => Loss 4.108, Train_accy 67.500, Test_accy 43.620
2022-11-28 23:16:37,834 [bic.py] => bias_correction => Task 9, Epoch 106/170 => Loss 4.104, Train_accy 65.500, Test_accy 43.660
2022-11-28 23:16:42,490 [bic.py] => bias_correction => Task 9, Epoch 107/170 => Loss 4.099, Train_accy 68.500, Test_accy 43.740
2022-11-28 23:16:47,338 [bic.py] => bias_correction => Task 9, Epoch 108/170 => Loss 4.120, Train_accy 66.000, Test_accy 43.990
2022-11-28 23:16:52,188 [bic.py] => bias_correction => Task 9, Epoch 109/170 => Loss 4.104, Train_accy 66.000, Test_accy 43.950
2022-11-28 23:16:56,932 [bic.py] => bias_correction => Task 9, Epoch 110/170 => Loss 4.115, Train_accy 68.000, Test_accy 43.690
2022-11-28 23:17:01,346 [bic.py] => bias_correction => Task 9, Epoch 111/170 => Loss 4.088, Train_accy 70.000, Test_accy 43.410
2022-11-28 23:17:06,194 [bic.py] => bias_correction => Task 9, Epoch 112/170 => Loss 4.106, Train_accy 67.000, Test_accy 43.470
2022-11-28 23:17:10,858 [bic.py] => bias_correction => Task 9, Epoch 113/170 => Loss 4.112, Train_accy 65.000, Test_accy 43.790
2022-11-28 23:17:15,437 [bic.py] => bias_correction => Task 9, Epoch 114/170 => Loss 4.114, Train_accy 69.500, Test_accy 43.640
2022-11-28 23:17:20,171 [bic.py] => bias_correction => Task 9, Epoch 115/170 => Loss 4.116, Train_accy 70.000, Test_accy 44.150
2022-11-28 23:17:25,313 [bic.py] => bias_correction => Task 9, Epoch 116/170 => Loss 4.106, Train_accy 69.500, Test_accy 44.110
2022-11-28 23:17:29,795 [bic.py] => bias_correction => Task 9, Epoch 117/170 => Loss 4.125, Train_accy 70.000, Test_accy 44.030
2022-11-28 23:17:34,380 [bic.py] => bias_correction => Task 9, Epoch 118/170 => Loss 4.128, Train_accy 70.000, Test_accy 44.010
2022-11-28 23:17:38,795 [bic.py] => bias_correction => Task 9, Epoch 119/170 => Loss 4.093, Train_accy 68.500, Test_accy 44.220
2022-11-28 23:17:43,784 [bic.py] => bias_correction => Task 9, Epoch 120/170 => Loss 4.101, Train_accy 68.000, Test_accy 44.200
2022-11-28 23:17:48,457 [bic.py] => bias_correction => Task 9, Epoch 121/170 => Loss 4.093, Train_accy 68.500, Test_accy 44.180
2022-11-28 23:17:52,986 [bic.py] => bias_correction => Task 9, Epoch 122/170 => Loss 4.118, Train_accy 66.500, Test_accy 44.110
2022-11-28 23:17:57,820 [bic.py] => bias_correction => Task 9, Epoch 123/170 => Loss 4.105, Train_accy 70.000, Test_accy 44.050
2022-11-28 23:18:02,595 [bic.py] => bias_correction => Task 9, Epoch 124/170 => Loss 4.109, Train_accy 68.500, Test_accy 44.100
2022-11-28 23:18:07,369 [bic.py] => bias_correction => Task 9, Epoch 125/170 => Loss 4.103, Train_accy 71.000, Test_accy 43.960
2022-11-28 23:18:12,501 [bic.py] => bias_correction => Task 9, Epoch 126/170 => Loss 4.099, Train_accy 69.000, Test_accy 43.950
2022-11-28 23:18:17,105 [bic.py] => bias_correction => Task 9, Epoch 127/170 => Loss 4.099, Train_accy 68.500, Test_accy 43.910
2022-11-28 23:18:21,739 [bic.py] => bias_correction => Task 9, Epoch 128/170 => Loss 4.111, Train_accy 67.000, Test_accy 43.820
2022-11-28 23:18:26,758 [bic.py] => bias_correction => Task 9, Epoch 129/170 => Loss 4.108, Train_accy 69.500, Test_accy 43.910
2022-11-28 23:18:31,777 [bic.py] => bias_correction => Task 9, Epoch 130/170 => Loss 4.093, Train_accy 68.000, Test_accy 43.920
2022-11-28 23:18:36,376 [bic.py] => bias_correction => Task 9, Epoch 131/170 => Loss 4.112, Train_accy 65.000, Test_accy 44.100
2022-11-28 23:18:40,681 [bic.py] => bias_correction => Task 9, Epoch 132/170 => Loss 4.088, Train_accy 68.500, Test_accy 43.860
2022-11-28 23:18:45,249 [bic.py] => bias_correction => Task 9, Epoch 133/170 => Loss 4.109, Train_accy 69.500, Test_accy 44.080
2022-11-28 23:18:50,254 [bic.py] => bias_correction => Task 9, Epoch 134/170 => Loss 4.120, Train_accy 69.500, Test_accy 44.110
2022-11-28 23:18:55,317 [bic.py] => bias_correction => Task 9, Epoch 135/170 => Loss 4.090, Train_accy 66.500, Test_accy 44.070
2022-11-28 23:18:59,927 [bic.py] => bias_correction => Task 9, Epoch 136/170 => Loss 4.094, Train_accy 68.500, Test_accy 44.240
2022-11-28 23:19:04,611 [bic.py] => bias_correction => Task 9, Epoch 137/170 => Loss 4.106, Train_accy 68.000, Test_accy 44.060
2022-11-28 23:19:09,143 [bic.py] => bias_correction => Task 9, Epoch 138/170 => Loss 4.114, Train_accy 68.500, Test_accy 44.230
2022-11-28 23:19:13,614 [bic.py] => bias_correction => Task 9, Epoch 139/170 => Loss 4.100, Train_accy 70.000, Test_accy 44.250
2022-11-28 23:19:18,023 [bic.py] => bias_correction => Task 9, Epoch 140/170 => Loss 4.122, Train_accy 70.500, Test_accy 44.190
2022-11-28 23:19:22,387 [bic.py] => bias_correction => Task 9, Epoch 141/170 => Loss 4.124, Train_accy 70.500, Test_accy 43.960
2022-11-28 23:19:27,004 [bic.py] => bias_correction => Task 9, Epoch 142/170 => Loss 4.112, Train_accy 67.500, Test_accy 43.940
2022-11-28 23:19:31,605 [bic.py] => bias_correction => Task 9, Epoch 143/170 => Loss 4.092, Train_accy 68.000, Test_accy 43.820
2022-11-28 23:19:35,812 [bic.py] => bias_correction => Task 9, Epoch 144/170 => Loss 4.119, Train_accy 69.000, Test_accy 44.030
2022-11-28 23:19:40,462 [bic.py] => bias_correction => Task 9, Epoch 145/170 => Loss 4.102, Train_accy 66.000, Test_accy 44.050
2022-11-28 23:19:44,996 [bic.py] => bias_correction => Task 9, Epoch 146/170 => Loss 4.120, Train_accy 68.500, Test_accy 43.660
2022-11-28 23:19:49,493 [bic.py] => bias_correction => Task 9, Epoch 147/170 => Loss 4.109, Train_accy 69.000, Test_accy 43.660
2022-11-28 23:19:54,772 [bic.py] => bias_correction => Task 9, Epoch 148/170 => Loss 4.121, Train_accy 68.000, Test_accy 44.000
2022-11-28 23:19:59,305 [bic.py] => bias_correction => Task 9, Epoch 149/170 => Loss 4.102, Train_accy 68.000, Test_accy 44.040
2022-11-28 23:20:04,255 [bic.py] => bias_correction => Task 9, Epoch 150/170 => Loss 4.093, Train_accy 69.500, Test_accy 44.370
2022-11-28 23:20:09,194 [bic.py] => bias_correction => Task 9, Epoch 151/170 => Loss 4.123, Train_accy 71.500, Test_accy 44.290
2022-11-28 23:20:14,195 [bic.py] => bias_correction => Task 9, Epoch 152/170 => Loss 4.111, Train_accy 68.500, Test_accy 44.240
2022-11-28 23:20:18,572 [bic.py] => bias_correction => Task 9, Epoch 153/170 => Loss 4.110, Train_accy 68.000, Test_accy 44.010
2022-11-28 23:20:23,622 [bic.py] => bias_correction => Task 9, Epoch 154/170 => Loss 4.123, Train_accy 68.500, Test_accy 44.110
2022-11-28 23:20:28,124 [bic.py] => bias_correction => Task 9, Epoch 155/170 => Loss 4.089, Train_accy 67.500, Test_accy 44.040
2022-11-28 23:20:32,522 [bic.py] => bias_correction => Task 9, Epoch 156/170 => Loss 4.112, Train_accy 68.000, Test_accy 43.920
2022-11-28 23:20:37,454 [bic.py] => bias_correction => Task 9, Epoch 157/170 => Loss 4.099, Train_accy 70.000, Test_accy 43.780
2022-11-28 23:20:42,270 [bic.py] => bias_correction => Task 9, Epoch 158/170 => Loss 4.083, Train_accy 69.000, Test_accy 43.940
2022-11-28 23:20:46,814 [bic.py] => bias_correction => Task 9, Epoch 159/170 => Loss 4.101, Train_accy 69.500, Test_accy 43.880
2022-11-28 23:20:51,351 [bic.py] => bias_correction => Task 9, Epoch 160/170 => Loss 4.111, Train_accy 70.000, Test_accy 43.690
2022-11-28 23:20:56,400 [bic.py] => bias_correction => Task 9, Epoch 161/170 => Loss 4.099, Train_accy 66.500, Test_accy 43.780
2022-11-28 23:21:01,429 [bic.py] => bias_correction => Task 9, Epoch 162/170 => Loss 4.094, Train_accy 66.000, Test_accy 43.700
2022-11-28 23:21:05,935 [bic.py] => bias_correction => Task 9, Epoch 163/170 => Loss 4.109, Train_accy 66.000, Test_accy 43.600
2022-11-28 23:21:10,765 [bic.py] => bias_correction => Task 9, Epoch 164/170 => Loss 4.127, Train_accy 67.000, Test_accy 43.660
2022-11-28 23:21:15,453 [bic.py] => bias_correction => Task 9, Epoch 165/170 => Loss 4.118, Train_accy 67.500, Test_accy 43.910
2022-11-28 23:21:20,535 [bic.py] => bias_correction => Task 9, Epoch 166/170 => Loss 4.105, Train_accy 68.500, Test_accy 44.150
2022-11-28 23:21:25,251 [bic.py] => bias_correction => Task 9, Epoch 167/170 => Loss 4.094, Train_accy 70.000, Test_accy 44.030
2022-11-28 23:21:30,025 [bic.py] => bias_correction => Task 9, Epoch 168/170 => Loss 4.116, Train_accy 69.500, Test_accy 44.110
2022-11-28 23:21:34,352 [bic.py] => bias_correction => Task 9, Epoch 169/170 => Loss 4.108, Train_accy 70.000, Test_accy 44.030
2022-11-28 23:21:38,591 [bic.py] => bias_correction => Task 9, Epoch 170/170 => Loss 4.106, Train_accy 68.000, Test_accy 44.040
2022-11-28 23:21:38,592 [base.py] => Reducing exemplars...(20 per classes)
2022-11-28 23:22:16,645 [base.py] => Constructing exemplars...(20 per classes)
2022-11-28 23:22:25,621 [bic.py] => Parameters of bias layer:
2022-11-28 23:22:25,622 [bic.py] => 0 => 1.000, 0.000
2022-11-28 23:22:25,622 [bic.py] => 1 => 0.976, -1.640
2022-11-28 23:22:25,622 [bic.py] => 2 => 0.847, -1.789
2022-11-28 23:22:25,622 [bic.py] => 3 => 0.728, -1.453
2022-11-28 23:22:25,622 [bic.py] => 4 => 0.739, -1.271
2022-11-28 23:22:25,622 [bic.py] => 5 => 0.788, -1.449
2022-11-28 23:22:25,622 [bic.py] => 6 => 0.727, -1.396
2022-11-28 23:22:25,622 [bic.py] => 7 => -0.032, -0.821
2022-11-28 23:22:25,622 [bic.py] => 8 => 0.057, -0.685
2022-11-28 23:22:25,622 [bic.py] => 9 => 0.690, -1.210
2022-11-28 23:22:28,275 [bic.py] => Exemplar size: 2000
2022-11-28 23:22:28,275 [trainer.py] => CNN: {'total': 44.04, '00-09': 60.0, '10-19': 46.2, '20-29': 59.7, '30-39': 45.1, '40-49': 57.4, '50-59': 50.7, '60-69': 55.2, '70-79': 0.0, '80-89': 0.0, '90-99': 66.1, 'old': 41.59, 'new': 66.1}
2022-11-28 23:22:28,275 [trainer.py] => NME: {'total': 48.1, '00-09': 48.4, '10-19': 31.3, '20-29': 49.6, '30-39': 40.9, '40-49': 55.5, '50-59': 41.0, '60-69': 54.3, '70-79': 45.6, '80-89': 51.2, '90-99': 63.2, 'old': 46.42, 'new': 63.2}
2022-11-28 23:22:28,275 [trainer.py] => CNN top1 curve: [88.7, 75.6, 72.3, 66.6, 64.42, 60.9, 58.66, 50.71, 44.21, 44.04]
2022-11-28 23:22:28,275 [trainer.py] => CNN top5 curve: [99.4, 95.6, 93.5, 91.42, 90.66, 87.9, 85.69, 74.16, 65.03, 65.62]
2022-11-28 23:22:28,275 [trainer.py] => NME top1 curve: [88.5, 75.85, 72.47, 66.72, 64.22, 60.88, 58.87, 55.1, 51.04, 48.1]
2022-11-28 23:22:28,275 [trainer.py] => NME top5 curve: [99.4, 95.95, 93.8, 91.2, 89.16, 86.13, 84.11, 81.74, 77.67, 74.3]

